<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - coverage.info - libtorch/include/c10/core/TensorImpl.h</title>
  <link rel="stylesheet" type="text/css" href="../../../../gcov.css">
</head>

<body>

          <table width="100%" border=0 cellspacing=0 cellpadding=0>
            <tr><td class="title">LCOV - code coverage report</td></tr>
            <tr><td class="ruler"><img src="../../../../glass.png" width=3 height=3 alt=""></td></tr>

            <tr>
              <td width="100%">
                <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="10%" class="headerValue"><a href="../../../../index.html">top level</a> - <a href="index.html">libtorch/include/c10/core</a> - TensorImpl.h<span style="font-size: 80%;"> (source / <a href="TensorImpl.h.func-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="5%"></td>
            <td width="5%" class="headerCovTableHead">Coverage</td>
            <td width="5%" class="headerCovTableHead" title="Covered + Uncovered code">Total</td>
            <td width="5%" class="headerCovTableHead" title="Exercised code only">Hit</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">coverage.info</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntryMed">85.7&nbsp;%</td>
            <td class="headerCovTableEntry">35</td>
            <td class="headerCovTableEntry">30</td>
          </tr>
          <tr>
            <td class="headerItem">Test Date:</td>
            <td class="headerValue">2024-04-30 13:17:26</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntryHi">100.0&nbsp;%</td>
            <td class="headerCovTableEntry">12</td>
            <td class="headerCovTableEntry">12</td>
          </tr>
                  <tr><td><img src="../../../../glass.png" width=3 height=3 alt=""></td></tr>
                </table>
              </td>
            </tr>

            <tr><td class="ruler"><img src="../../../../glass.png" width=3 height=3 alt=""></td></tr>
          </table>

          <table cellpadding=0 cellspacing=0 border=0>
            <tr>
              <td><br></td>
            </tr>
            <tr>
              <td>
<pre class="sourceHeading">            Line data    Source code</pre>
<pre class="source">
<span id="L1"><span class="lineNum">       1</span>              : #pragma once</span>
<span id="L2"><span class="lineNum">       2</span>              : </span>
<span id="L3"><span class="lineNum">       3</span>              : #include &lt;c10/core/DispatchKeySet.h&gt;</span>
<span id="L4"><span class="lineNum">       4</span>              : #include &lt;c10/core/InferenceMode.h&gt;</span>
<span id="L5"><span class="lineNum">       5</span>              : #include &lt;c10/core/MemoryFormat.h&gt;</span>
<span id="L6"><span class="lineNum">       6</span>              : #include &lt;c10/core/ScalarTypeToTypeMeta.h&gt;</span>
<span id="L7"><span class="lineNum">       7</span>              : #include &lt;c10/core/Storage.h&gt;</span>
<span id="L8"><span class="lineNum">       8</span>              : #include &lt;c10/core/SymBool.h&gt;</span>
<span id="L9"><span class="lineNum">       9</span>              : #include &lt;c10/core/SymIntArrayRef.h&gt;</span>
<span id="L10"><span class="lineNum">      10</span>              : #include &lt;c10/core/WrapDimMinimal.h&gt;</span>
<span id="L11"><span class="lineNum">      11</span>              : #include &lt;c10/core/impl/PyObjectSlot.h&gt;</span>
<span id="L12"><span class="lineNum">      12</span>              : #include &lt;c10/core/impl/SizesAndStrides.h&gt;</span>
<span id="L13"><span class="lineNum">      13</span>              : #include &lt;c10/macros/Macros.h&gt;</span>
<span id="L14"><span class="lineNum">      14</span>              : #include &lt;c10/util/DimVector.h&gt;</span>
<span id="L15"><span class="lineNum">      15</span>              : #include &lt;c10/util/Exception.h&gt;</span>
<span id="L16"><span class="lineNum">      16</span>              : #include &lt;c10/util/Flags.h&gt;</span>
<span id="L17"><span class="lineNum">      17</span>              : #include &lt;c10/util/Optional.h&gt;</span>
<span id="L18"><span class="lineNum">      18</span>              : #include &lt;c10/util/accumulate.h&gt;</span>
<span id="L19"><span class="lineNum">      19</span>              : #include &lt;c10/util/intrusive_ptr.h&gt;</span>
<span id="L20"><span class="lineNum">      20</span>              : #include &lt;c10/util/irange.h&gt;</span>
<span id="L21"><span class="lineNum">      21</span>              : #include &lt;c10/util/safe_numerics.h&gt;</span>
<span id="L22"><span class="lineNum">      22</span>              : #include &lt;c10/util/typeid.h&gt;</span>
<span id="L23"><span class="lineNum">      23</span>              : </span>
<span id="L24"><span class="lineNum">      24</span>              : #include &lt;algorithm&gt;</span>
<span id="L25"><span class="lineNum">      25</span>              : #include &lt;atomic&gt;</span>
<span id="L26"><span class="lineNum">      26</span>              : #include &lt;limits&gt;</span>
<span id="L27"><span class="lineNum">      27</span>              : #include &lt;memory&gt;</span>
<span id="L28"><span class="lineNum">      28</span>              : #include &lt;type_traits&gt;</span>
<span id="L29"><span class="lineNum">      29</span>              : #include &lt;utility&gt;</span>
<span id="L30"><span class="lineNum">      30</span>              : </span>
<span id="L31"><span class="lineNum">      31</span>              : // A global boolean variable to control whether we free memory when a Tensor</span>
<span id="L32"><span class="lineNum">      32</span>              : // is shrunk to a smaller size. As a result, a Tensor is always going to</span>
<span id="L33"><span class="lineNum">      33</span>              : // keep the memory allocated for its maximum capacity reshaped to so far.</span>
<span id="L34"><span class="lineNum">      34</span>              : //</span>
<span id="L35"><span class="lineNum">      35</span>              : // This parameter is respected &quot;upper-case&quot; methods which call Resize()</span>
<span id="L36"><span class="lineNum">      36</span>              : // (e.g., CopyFrom, ResizeLike); it is NOT respected by Tensor::resize_</span>
<span id="L37"><span class="lineNum">      37</span>              : // or ShrinkTo, both of which guarantee to never to free memory.</span>
<span id="L38"><span class="lineNum">      38</span>              : C10_DECLARE_bool(caffe2_keep_on_shrink);</span>
<span id="L39"><span class="lineNum">      39</span>              : </span>
<span id="L40"><span class="lineNum">      40</span>              : // Since we can have high variance in blob memory allocated across different</span>
<span id="L41"><span class="lineNum">      41</span>              : // inputs in the same run, we will shrink the blob only if the memory gain</span>
<span id="L42"><span class="lineNum">      42</span>              : // is larger than this flag in bytes.  This only applies to functions which</span>
<span id="L43"><span class="lineNum">      43</span>              : // respect caffe2_keep_on_shrink.</span>
<span id="L44"><span class="lineNum">      44</span>              : C10_DECLARE_int64(caffe2_max_keep_on_shrink_memory);</span>
<span id="L45"><span class="lineNum">      45</span>              : </span>
<span id="L46"><span class="lineNum">      46</span>              : C10_CLANG_DIAGNOSTIC_PUSH()</span>
<span id="L47"><span class="lineNum">      47</span>              : #if C10_CLANG_HAS_WARNING(&quot;-Wimplicit-int-float-conversion&quot;)</span>
<span id="L48"><span class="lineNum">      48</span>              : C10_CLANG_DIAGNOSTIC_IGNORE(&quot;-Wimplicit-int-float-conversion&quot;)</span>
<span id="L49"><span class="lineNum">      49</span>              : #endif</span>
<span id="L50"><span class="lineNum">      50</span>              : </span>
<span id="L51"><span class="lineNum">      51</span>              : namespace at {</span>
<span id="L52"><span class="lineNum">      52</span>              : class Tensor;</span>
<span id="L53"><span class="lineNum">      53</span>              : class TensorBase;</span>
<span id="L54"><span class="lineNum">      54</span>              : } // namespace at</span>
<span id="L55"><span class="lineNum">      55</span>              : </span>
<span id="L56"><span class="lineNum">      56</span>              : namespace c10 {</span>
<span id="L57"><span class="lineNum">      57</span>              : </span>
<span id="L58"><span class="lineNum">      58</span>              : /**</span>
<span id="L59"><span class="lineNum">      59</span>              :  * A utility function to convert vector&lt;int&gt; to vector&lt;int64_t&gt;.</span>
<span id="L60"><span class="lineNum">      60</span>              :  */</span>
<span id="L61"><span class="lineNum">      61</span>              : inline std::vector&lt;int64_t&gt; ToVectorint64_t(const ArrayRef&lt;int&gt;&amp; src) {</span>
<span id="L62"><span class="lineNum">      62</span>              :   return std::vector&lt;int64_t&gt;(src.begin(), src.end());</span>
<span id="L63"><span class="lineNum">      63</span>              : }</span>
<span id="L64"><span class="lineNum">      64</span>              : </span>
<span id="L65"><span class="lineNum">      65</span>              : /**</span>
<span id="L66"><span class="lineNum">      66</span>              :  * Return product of all dimensions starting from k</span>
<span id="L67"><span class="lineNum">      67</span>              :  */</span>
<span id="L68"><span class="lineNum">      68</span>              : inline int64_t size_from_dim_(int k, IntArrayRef dims) {</span>
<span id="L69"><span class="lineNum">      69</span>              :   int64_t r = 1;</span>
<span id="L70"><span class="lineNum">      70</span>              :   for (const auto i : c10::irange(k, dims.size())) {</span>
<span id="L71"><span class="lineNum">      71</span>              :     r *= dims[i];</span>
<span id="L72"><span class="lineNum">      72</span>              :   }</span>
<span id="L73"><span class="lineNum">      73</span>              :   return r;</span>
<span id="L74"><span class="lineNum">      74</span>              : }</span>
<span id="L75"><span class="lineNum">      75</span>              : </span>
<span id="L76"><span class="lineNum">      76</span>              : // Product of all dims up to k (not including dims[k])</span>
<span id="L77"><span class="lineNum">      77</span>              : inline int64_t size_to_dim_(int k, IntArrayRef dims) {</span>
<span id="L78"><span class="lineNum">      78</span>              :   TORCH_CHECK((unsigned)k &lt;= dims.size());</span>
<span id="L79"><span class="lineNum">      79</span>              :   int64_t r = 1;</span>
<span id="L80"><span class="lineNum">      80</span>              :   for (const auto i : c10::irange(k)) {</span>
<span id="L81"><span class="lineNum">      81</span>              :     r *= dims[i];</span>
<span id="L82"><span class="lineNum">      82</span>              :   }</span>
<span id="L83"><span class="lineNum">      83</span>              :   return r;</span>
<span id="L84"><span class="lineNum">      84</span>              : }</span>
<span id="L85"><span class="lineNum">      85</span>              : </span>
<span id="L86"><span class="lineNum">      86</span>              : // Product of all dims between k and l (not including dims[k] and dims[l])</span>
<span id="L87"><span class="lineNum">      87</span>              : inline int64_t size_between_dim_(int k, int l, IntArrayRef dims) {</span>
<span id="L88"><span class="lineNum">      88</span>              :   TORCH_CHECK((unsigned)l &lt; dims.size() &amp;&amp; (unsigned)k &lt; dims.size());</span>
<span id="L89"><span class="lineNum">      89</span>              :   int64_t r = 1;</span>
<span id="L90"><span class="lineNum">      90</span>              :   if (k &lt; l) {</span>
<span id="L91"><span class="lineNum">      91</span>              :     for (int i = k + 1; i &lt; l; ++i) {</span>
<span id="L92"><span class="lineNum">      92</span>              :       r *= dims[i];</span>
<span id="L93"><span class="lineNum">      93</span>              :     }</span>
<span id="L94"><span class="lineNum">      94</span>              :   } else {</span>
<span id="L95"><span class="lineNum">      95</span>              :     for (int i = l + 1; i &lt; k; ++i) {</span>
<span id="L96"><span class="lineNum">      96</span>              :       r *= dims[i];</span>
<span id="L97"><span class="lineNum">      97</span>              :     }</span>
<span id="L98"><span class="lineNum">      98</span>              :   }</span>
<span id="L99"><span class="lineNum">      99</span>              :   return r;</span>
<span id="L100"><span class="lineNum">     100</span>              : }</span>
<span id="L101"><span class="lineNum">     101</span>              : </span>
<span id="L102"><span class="lineNum">     102</span>              : // Wrap around axis_index if it is negative, s.t., -1 is the last dim</span>
<span id="L103"><span class="lineNum">     103</span>              : inline int canonical_axis_index_(int axis_index, int ndims) {</span>
<span id="L104"><span class="lineNum">     104</span>              :   TORCH_CHECK(axis_index &gt;= -ndims);</span>
<span id="L105"><span class="lineNum">     105</span>              :   TORCH_CHECK(axis_index &lt; ndims);</span>
<span id="L106"><span class="lineNum">     106</span>              :   if (axis_index &lt; 0) {</span>
<span id="L107"><span class="lineNum">     107</span>              :     return axis_index + ndims;</span>
<span id="L108"><span class="lineNum">     108</span>              :   }</span>
<span id="L109"><span class="lineNum">     109</span>              :   return axis_index;</span>
<span id="L110"><span class="lineNum">     110</span>              : }</span>
<span id="L111"><span class="lineNum">     111</span>              : </span>
<span id="L112"><span class="lineNum">     112</span>              : using PlacementDtor = void (*)(void*, size_t);</span>
<span id="L113"><span class="lineNum">     113</span>              : </span>
<span id="L114"><span class="lineNum">     114</span>              : /*</span>
<span id="L115"><span class="lineNum">     115</span>              :  * A Context that will call extra placement deleter during</span>
<span id="L116"><span class="lineNum">     116</span>              :  * deconstruction.</span>
<span id="L117"><span class="lineNum">     117</span>              :  *</span>
<span id="L118"><span class="lineNum">     118</span>              :  * Accept a already constructed DataPtr and store it as member</span>
<span id="L119"><span class="lineNum">     119</span>              :  * during destruction, we'll call extra deleter on the underlying</span>
<span id="L120"><span class="lineNum">     120</span>              :  * data pointer before the DataPtr is destructed.</span>
<span id="L121"><span class="lineNum">     121</span>              :  * `data_ptr_` owns the memory.</span>
<span id="L122"><span class="lineNum">     122</span>              :  */</span>
<span id="L123"><span class="lineNum">     123</span>              : struct C10_API PlacementDeleteContext {</span>
<span id="L124"><span class="lineNum">     124</span>              :   DataPtr data_ptr_;</span>
<span id="L125"><span class="lineNum">     125</span>              :   PlacementDtor placement_dtor_;</span>
<span id="L126"><span class="lineNum">     126</span>              :   size_t size_;</span>
<span id="L127"><span class="lineNum">     127</span>              :   PlacementDeleteContext(</span>
<span id="L128"><span class="lineNum">     128</span>              :       DataPtr&amp;&amp; data_ptr,</span>
<span id="L129"><span class="lineNum">     129</span>              :       PlacementDtor placement_dtor,</span>
<span id="L130"><span class="lineNum">     130</span>              :       size_t size)</span>
<span id="L131"><span class="lineNum">     131</span>              :       : data_ptr_(std::move(data_ptr)),</span>
<span id="L132"><span class="lineNum">     132</span>              :         placement_dtor_(placement_dtor),</span>
<span id="L133"><span class="lineNum">     133</span>              :         size_(size) {}</span>
<span id="L134"><span class="lineNum">     134</span>              :   static DataPtr makeDataPtr(</span>
<span id="L135"><span class="lineNum">     135</span>              :       DataPtr&amp;&amp; data_ptr,</span>
<span id="L136"><span class="lineNum">     136</span>              :       PlacementDtor placement_dtor,</span>
<span id="L137"><span class="lineNum">     137</span>              :       size_t size,</span>
<span id="L138"><span class="lineNum">     138</span>              :       Device device);</span>
<span id="L139"><span class="lineNum">     139</span>              :   ~PlacementDeleteContext() {</span>
<span id="L140"><span class="lineNum">     140</span>              :     placement_dtor_(data_ptr_.get(), size_);</span>
<span id="L141"><span class="lineNum">     141</span>              :     // original memory will be freed when data_ptr_ is destructed</span>
<span id="L142"><span class="lineNum">     142</span>              :   }</span>
<span id="L143"><span class="lineNum">     143</span>              : };</span>
<span id="L144"><span class="lineNum">     144</span>              : </span>
<span id="L145"><span class="lineNum">     145</span>              : struct C10_API AutogradMetaInterface {</span>
<span id="L146"><span class="lineNum">     146</span>              :   virtual void set_requires_grad(</span>
<span id="L147"><span class="lineNum">     147</span>              :       bool requires_grad,</span>
<span id="L148"><span class="lineNum">     148</span>              :       at::TensorImpl* self_impl) = 0;</span>
<span id="L149"><span class="lineNum">     149</span>              :   virtual bool requires_grad() const = 0;</span>
<span id="L150"><span class="lineNum">     150</span>              :   virtual at::Tensor&amp; mutable_grad() = 0;</span>
<span id="L151"><span class="lineNum">     151</span>              :   virtual const at::Tensor&amp; grad() const = 0;</span>
<span id="L152"><span class="lineNum">     152</span>              :   virtual const at::Tensor&amp; fw_grad(uint64_t level, const at::TensorBase&amp; self)</span>
<span id="L153"><span class="lineNum">     153</span>              :       const = 0;</span>
<span id="L154"><span class="lineNum">     154</span>              :   virtual void set_fw_grad(</span>
<span id="L155"><span class="lineNum">     155</span>              :       const at::TensorBase&amp; new_grad,</span>
<span id="L156"><span class="lineNum">     156</span>              :       const at::TensorBase&amp; self,</span>
<span id="L157"><span class="lineNum">     157</span>              :       uint64_t level,</span>
<span id="L158"><span class="lineNum">     158</span>              :       bool is_inplace_op) = 0;</span>
<span id="L159"><span class="lineNum">     159</span>              :   virtual ~AutogradMetaInterface();</span>
<span id="L160"><span class="lineNum">     160</span>              : };</span>
<span id="L161"><span class="lineNum">     161</span>              : </span>
<span id="L162"><span class="lineNum">     162</span>              : namespace impl {</span>
<span id="L163"><span class="lineNum">     163</span>              : </span>
<span id="L164"><span class="lineNum">     164</span>              : // Unfortunately, the definition of AutogradMeta lives in a separate</span>
<span id="L165"><span class="lineNum">     165</span>              : // compilation unit than TensorImpl (libtorch.so versus libc10.so)</span>
<span id="L166"><span class="lineNum">     166</span>              : // which means that we cannot construct an AutogradMeta from TensorImpl,</span>
<span id="L167"><span class="lineNum">     167</span>              : // not even from the cpp file.  So we have to indirect it through a factory</span>
<span id="L168"><span class="lineNum">     168</span>              : // function which will be initialized when we load libtorch.so.</span>
<span id="L169"><span class="lineNum">     169</span>              : </span>
<span id="L170"><span class="lineNum">     170</span>              : struct C10_API AutogradMetaFactory {</span>
<span id="L171"><span class="lineNum">     171</span>              :   virtual ~AutogradMetaFactory() = default;</span>
<span id="L172"><span class="lineNum">     172</span>              :   virtual std::unique_ptr&lt;AutogradMetaInterface&gt; make() const = 0;</span>
<span id="L173"><span class="lineNum">     173</span>              :   // This method is the dumbest method.  But I don't have access</span>
<span id="L174"><span class="lineNum">     174</span>              :   // to Tensor (not TensorImpl) which is undefined in this header.</span>
<span id="L175"><span class="lineNum">     175</span>              :   virtual const at::Tensor&amp; undefined_tensor() const = 0;</span>
<span id="L176"><span class="lineNum">     176</span>              : };</span>
<span id="L177"><span class="lineNum">     177</span>              : </span>
<span id="L178"><span class="lineNum">     178</span>              : C10_API void SetAutogradMetaFactory(AutogradMetaFactory* factory);</span>
<span id="L179"><span class="lineNum">     179</span>              : C10_API AutogradMetaFactory* GetAutogradMetaFactory();</span>
<span id="L180"><span class="lineNum">     180</span>              : </span>
<span id="L181"><span class="lineNum">     181</span>              : struct C10_API AutogradMetaFactoryRegisterer {</span>
<span id="L182"><span class="lineNum">     182</span>              :   explicit AutogradMetaFactoryRegisterer(AutogradMetaFactory* factory) {</span>
<span id="L183"><span class="lineNum">     183</span>              :     SetAutogradMetaFactory(factory);</span>
<span id="L184"><span class="lineNum">     184</span>              :   }</span>
<span id="L185"><span class="lineNum">     185</span>              : };</span>
<span id="L186"><span class="lineNum">     186</span>              : </span>
<span id="L187"><span class="lineNum">     187</span>              : } // namespace impl</span>
<span id="L188"><span class="lineNum">     188</span>              : </span>
<span id="L189"><span class="lineNum">     189</span>              : struct C10_API NamedTensorMetaInterface {</span>
<span id="L190"><span class="lineNum">     190</span>              :   virtual ~NamedTensorMetaInterface() = default;</span>
<span id="L191"><span class="lineNum">     191</span>              :   virtual std::unique_ptr&lt;NamedTensorMetaInterface&gt; clone() const {</span>
<span id="L192"><span class="lineNum">     192</span>              :     TORCH_INTERNAL_ASSERT(</span>
<span id="L193"><span class="lineNum">     193</span>              :         false, &quot;Not implemented: NamedTensorMetaInterface::clone&quot;);</span>
<span id="L194"><span class="lineNum">     194</span>              :   };</span>
<span id="L195"><span class="lineNum">     195</span>              :   virtual int64_t slow_dim() const {</span>
<span id="L196"><span class="lineNum">     196</span>              :     TORCH_INTERNAL_ASSERT(</span>
<span id="L197"><span class="lineNum">     197</span>              :         false, &quot;Not implemented: NamedTensorMetaInterface::slow_dim&quot;);</span>
<span id="L198"><span class="lineNum">     198</span>              :   };</span>
<span id="L199"><span class="lineNum">     199</span>              : };</span>
<span id="L200"><span class="lineNum">     200</span>              : </span>
<span id="L201"><span class="lineNum">     201</span>              : // For ease of copy pasting</span>
<span id="L202"><span class="lineNum">     202</span>              : #if 0</span>
<span id="L203"><span class="lineNum">     203</span>              : is_contiguous</span>
<span id="L204"><span class="lineNum">     204</span>              : is_channels_last_contiguous</span>
<span id="L205"><span class="lineNum">     205</span>              : is_channels_last_3d_contiguous</span>
<span id="L206"><span class="lineNum">     206</span>              : is_channels_last</span>
<span id="L207"><span class="lineNum">     207</span>              : is_channels_last_3d</span>
<span id="L208"><span class="lineNum">     208</span>              : is_non_overlapping_and_dense</span>
<span id="L209"><span class="lineNum">     209</span>              : #endif</span>
<span id="L210"><span class="lineNum">     210</span>              : </span>
<span id="L211"><span class="lineNum">     211</span>              : /**</span>
<span id="L212"><span class="lineNum">     212</span>              :  * This structure is intended to hold additional metadata of the specific device</span>
<span id="L213"><span class="lineNum">     213</span>              :  * backend.</span>
<span id="L214"><span class="lineNum">     214</span>              :  **/</span>
<span id="L215"><span class="lineNum">     215</span>              : struct C10_API BackendMeta : intrusive_ptr_target {</span>
<span id="L216"><span class="lineNum">     216</span>              :   ~BackendMeta() override = default;</span>
<span id="L217"><span class="lineNum">     217</span>              :   virtual intrusive_ptr&lt;BackendMeta&gt; clone(</span>
<span id="L218"><span class="lineNum">     218</span>              :       const intrusive_ptr&lt;BackendMeta&gt;&amp; ptr) const {</span>
<span id="L219"><span class="lineNum">     219</span>              :     return ptr;</span>
<span id="L220"><span class="lineNum">     220</span>              :   }</span>
<span id="L221"><span class="lineNum">     221</span>              : };</span>
<span id="L222"><span class="lineNum">     222</span>              : </span>
<span id="L223"><span class="lineNum">     223</span>              : struct C10_API SymbolicShapeMeta {</span>
<span id="L224"><span class="lineNum">     224</span>              :   SymDimVector sizes_ = {0};</span>
<span id="L225"><span class="lineNum">     225</span>              :   SymDimVector strides_ = {1};</span>
<span id="L226"><span class="lineNum">     226</span>              :   SymInt numel_ = 1;</span>
<span id="L227"><span class="lineNum">     227</span>              :   SymInt storage_offset_ = 0;</span>
<span id="L228"><span class="lineNum">     228</span>              :   SymBool is_contiguous_{true};</span>
<span id="L229"><span class="lineNum">     229</span>              :   SymBool is_channels_last_contiguous_{false};</span>
<span id="L230"><span class="lineNum">     230</span>              :   SymBool is_channels_last_3d_contiguous_{false};</span>
<span id="L231"><span class="lineNum">     231</span>              :   SymBool is_channels_last_{false};</span>
<span id="L232"><span class="lineNum">     232</span>              :   SymBool is_channels_last_3d_{false};</span>
<span id="L233"><span class="lineNum">     233</span>              :   SymBool is_non_overlapping_and_dense_{true};</span>
<span id="L234"><span class="lineNum">     234</span>              : };</span>
<span id="L235"><span class="lineNum">     235</span>              : </span>
<span id="L236"><span class="lineNum">     236</span>              : struct C10_API ExtraMeta {</span>
<span id="L237"><span class="lineNum">     237</span>              :   std::unique_ptr&lt;c10::SymbolicShapeMeta&gt; symbolic_shape_meta_ = nullptr;</span>
<span id="L238"><span class="lineNum">     238</span>              :   std::unique_ptr&lt;c10::NamedTensorMetaInterface&gt; named_tensor_meta_ = nullptr;</span>
<span id="L239"><span class="lineNum">     239</span>              :   intrusive_ptr&lt;c10::BackendMeta&gt; backend_meta_ = nullptr;</span>
<span id="L240"><span class="lineNum">     240</span>              :   c10::optional&lt;std::string&gt; custom_data_ptr_error_msg_ = c10::nullopt;</span>
<span id="L241"><span class="lineNum">     241</span>              : </span>
<span id="L242"><span class="lineNum">     242</span>              :   ExtraMeta() = default;</span>
<span id="L243"><span class="lineNum">     243</span>              :   ExtraMeta(const ExtraMeta&amp; other) {</span>
<span id="L244"><span class="lineNum">     244</span>              :     if (other.symbolic_shape_meta_) {</span>
<span id="L245"><span class="lineNum">     245</span>              :       symbolic_shape_meta_ =</span>
<span id="L246"><span class="lineNum">     246</span>              :           std::make_unique&lt;c10::SymbolicShapeMeta&gt;(*other.symbolic_shape_meta_);</span>
<span id="L247"><span class="lineNum">     247</span>              :     }</span>
<span id="L248"><span class="lineNum">     248</span>              :     if (other.named_tensor_meta_) {</span>
<span id="L249"><span class="lineNum">     249</span>              :       named_tensor_meta_ = other.named_tensor_meta_-&gt;clone();</span>
<span id="L250"><span class="lineNum">     250</span>              :     }</span>
<span id="L251"><span class="lineNum">     251</span>              :     if (other.backend_meta_) {</span>
<span id="L252"><span class="lineNum">     252</span>              :       backend_meta_ = other.backend_meta_-&gt;clone(other.backend_meta_);</span>
<span id="L253"><span class="lineNum">     253</span>              :     }</span>
<span id="L254"><span class="lineNum">     254</span>              :     if (other.custom_data_ptr_error_msg_) {</span>
<span id="L255"><span class="lineNum">     255</span>              :       custom_data_ptr_error_msg_ = other.custom_data_ptr_error_msg_;</span>
<span id="L256"><span class="lineNum">     256</span>              :     }</span>
<span id="L257"><span class="lineNum">     257</span>              :   }</span>
<span id="L258"><span class="lineNum">     258</span>              : </span>
<span id="L259"><span class="lineNum">     259</span>              :   ExtraMeta(</span>
<span id="L260"><span class="lineNum">     260</span>              :       std::unique_ptr&lt;c10::SymbolicShapeMeta&gt; symbolic_shape_meta,</span>
<span id="L261"><span class="lineNum">     261</span>              :       std::unique_ptr&lt;c10::NamedTensorMetaInterface&gt; named_tensor_meta,</span>
<span id="L262"><span class="lineNum">     262</span>              :       intrusive_ptr&lt;c10::BackendMeta&gt; backend_meta,</span>
<span id="L263"><span class="lineNum">     263</span>              :       c10::optional&lt;std::string&gt; custom_data_ptr_error_msg = c10::nullopt)</span>
<span id="L264"><span class="lineNum">     264</span>              :       : symbolic_shape_meta_(std::move(symbolic_shape_meta)),</span>
<span id="L265"><span class="lineNum">     265</span>              :         named_tensor_meta_(std::move(named_tensor_meta)),</span>
<span id="L266"><span class="lineNum">     266</span>              :         backend_meta_(std::move(backend_meta)),</span>
<span id="L267"><span class="lineNum">     267</span>              :         custom_data_ptr_error_msg_(std::move(custom_data_ptr_error_msg)) {}</span>
<span id="L268"><span class="lineNum">     268</span>              : </span>
<span id="L269"><span class="lineNum">     269</span>              :   std::unique_ptr&lt;ExtraMeta&gt; clone() const {</span>
<span id="L270"><span class="lineNum">     270</span>              :     return std::make_unique&lt;ExtraMeta&gt;(*this);</span>
<span id="L271"><span class="lineNum">     271</span>              :   }</span>
<span id="L272"><span class="lineNum">     272</span>              : };</span>
<span id="L273"><span class="lineNum">     273</span>              : </span>
<span id="L274"><span class="lineNum">     274</span>              : // NOTE [ Version Counter Sharing ]</span>
<span id="L275"><span class="lineNum">     275</span>              : //</span>
<span id="L276"><span class="lineNum">     276</span>              : // Every Tensor has a version counter. Version counters are incremented whenever</span>
<span id="L277"><span class="lineNum">     277</span>              : // the data or size of a tensor changes through in-place Variable operations.</span>
<span id="L278"><span class="lineNum">     278</span>              : // Version counters are used to detect modifications to saved variables which</span>
<span id="L279"><span class="lineNum">     279</span>              : // would result in incorrect gradient calculations. Version counters may be</span>
<span id="L280"><span class="lineNum">     280</span>              : // shared between Variables:</span>
<span id="L281"><span class="lineNum">     281</span>              : //</span>
<span id="L282"><span class="lineNum">     282</span>              : // 1. A view shares the version counter of the base Variable,</span>
<span id="L283"><span class="lineNum">     283</span>              : // 2. `x.detach()` shares the version counter of `x`,</span>
<span id="L284"><span class="lineNum">     284</span>              : // 3. Unpacked saved variables share the version counter of the source.</span>
<span id="L285"><span class="lineNum">     285</span>              : //</span>
<span id="L286"><span class="lineNum">     286</span>              : // Version counters are not shared in these scenarios:</span>
<span id="L287"><span class="lineNum">     287</span>              : //</span>
<span id="L288"><span class="lineNum">     288</span>              : // 1. When we replace a `Variable`'s underlying `Tensor` by calling</span>
<span id="L289"><span class="lineNum">     289</span>              : // `set_data(...)`,</span>
<span id="L290"><span class="lineNum">     290</span>              : // 2. `x.data` does not share the version counter of `x`. (See discussion at</span>
<span id="L291"><span class="lineNum">     291</span>              : // https://github.com/pytorch/pytorch/issues/5396)</span>
<span id="L292"><span class="lineNum">     292</span>              : //</span>
<span id="L293"><span class="lineNum">     293</span>              : // Question: Why do we put the version counter in TensorImpl instead of</span>
<span id="L294"><span class="lineNum">     294</span>              : // AutogradMeta?</span>
<span id="L295"><span class="lineNum">     295</span>              : //</span>
<span id="L296"><span class="lineNum">     296</span>              : // Answer: After the Variable/Tensor merge, a tensor will not have AutogradMeta</span>
<span id="L297"><span class="lineNum">     297</span>              : // when its `requires_grad_` is false, but when we use this tensor in the</span>
<span id="L298"><span class="lineNum">     298</span>              : // forward pass of a function that requires saving this tensor for backward, we</span>
<span id="L299"><span class="lineNum">     299</span>              : // need to keep track of this tensor's version to make sure it's always valid in</span>
<span id="L300"><span class="lineNum">     300</span>              : // the autograd graph.</span>
<span id="L301"><span class="lineNum">     301</span>              : //</span>
<span id="L302"><span class="lineNum">     302</span>              : // To achieve this goal, we put the version counter in TensorImpl instead of</span>
<span id="L303"><span class="lineNum">     303</span>              : // AutogradMeta, and have it always be available. This allows us to have the</span>
<span id="L304"><span class="lineNum">     304</span>              : // optimization of not carrying AutogradMeta when a tensor doesn't require</span>
<span id="L305"><span class="lineNum">     305</span>              : // gradient.</span>
<span id="L306"><span class="lineNum">     306</span>              : //</span>
<span id="L307"><span class="lineNum">     307</span>              : // A hypothetical alternative way to achieve this goal is to initialize</span>
<span id="L308"><span class="lineNum">     308</span>              : // AutogradMeta and create the version counter for the non-requires-grad tensor</span>
<span id="L309"><span class="lineNum">     309</span>              : // only when it's saved for backward. However, since saving a tensor for</span>
<span id="L310"><span class="lineNum">     310</span>              : // backward happens in the forward pass, and our invariant is that forward pass</span>
<span id="L311"><span class="lineNum">     311</span>              : // needs to be thread-safe, lazy-initializing AutogradMeta when saving a tensor</span>
<span id="L312"><span class="lineNum">     312</span>              : // can introduce race conditions when we are running the forward pass in</span>
<span id="L313"><span class="lineNum">     313</span>              : // multi-thread scenarios, thus making the forward pass not thread-safe anymore,</span>
<span id="L314"><span class="lineNum">     314</span>              : // which breaks the invariant.</span>
<span id="L315"><span class="lineNum">     315</span>              : struct C10_API VariableVersion {</span>
<span id="L316"><span class="lineNum">     316</span>              :  private:</span>
<span id="L317"><span class="lineNum">     317</span>              :   struct VersionCounter : intrusive_ptr_target {</span>
<span id="L318"><span class="lineNum">     318</span> <span class="tlaGNC tlaBgGNC">      378768 :     VersionCounter(uint32_t version) : version_(version) {}</span></span>
<span id="L319"><span class="lineNum">     319</span>              :     std::atomic&lt;uint32_t&gt; version_;</span>
<span id="L320"><span class="lineNum">     320</span>              :   };</span>
<span id="L321"><span class="lineNum">     321</span>              :   c10::intrusive_ptr&lt;VersionCounter&gt; version_counter_;</span>
<span id="L322"><span class="lineNum">     322</span>              : </span>
<span id="L323"><span class="lineNum">     323</span>              :  public:</span>
<span id="L324"><span class="lineNum">     324</span>              :   // Note [Disabled VariableVersion]</span>
<span id="L325"><span class="lineNum">     325</span>              :   // VariableVersion struct has an intrusive_ptr pointing VersionCounter struct</span>
<span id="L326"><span class="lineNum">     326</span>              :   // with an atomic variable. Thus `VariableVersion(/*version=*/0)` is not as</span>
<span id="L327"><span class="lineNum">     327</span>              :   // cheap as we expected. In some cases constructing a VariableVersion with</span>
<span id="L328"><span class="lineNum">     328</span>              :   // version 0 is not necessary so we add a cheap constructor which</span>
<span id="L329"><span class="lineNum">     329</span>              :   // doesn't allocate the intrusive_ptr.</span>
<span id="L330"><span class="lineNum">     330</span>              :   // Example use cases are:</span>
<span id="L331"><span class="lineNum">     331</span>              :   //  - Inference tensors don't track version counter, so they'll just always</span>
<span id="L332"><span class="lineNum">     332</span>              :   //    have disabled VariableVersion.</span>
<span id="L333"><span class="lineNum">     333</span>              :   //  - In SavedVariable class we override version_counter_ inside its</span>
<span id="L334"><span class="lineNum">     334</span>              :   //  constructor</span>
<span id="L335"><span class="lineNum">     335</span>              :   //    so that we can use the cheap constructor there.</span>
<span id="L336"><span class="lineNum">     336</span>              :   enum Disabled { DISABLED };</span>
<span id="L337"><span class="lineNum">     337</span>              :   // It's okay to return true even for inference tensor which</span>
<span id="L338"><span class="lineNum">     338</span>              :   // doesn't have version counter enabled.</span>
<span id="L339"><span class="lineNum">     339</span>              :   // We want to be permissive here since in many cases (e.g. make_variable)</span>
<span id="L340"><span class="lineNum">     340</span>              :   // we can std::move a TensorImpl if there's no other uses which saves us</span>
<span id="L341"><span class="lineNum">     341</span>              :   // an additional TensorImpl allocation.</span>
<span id="L342"><span class="lineNum">     342</span> <span class="tlaGNC">       40076 :   bool unique() const {</span></span>
<span id="L343"><span class="lineNum">     343</span> <span class="tlaGNC">       40076 :     return version_counter_ ? 1 == version_counter_.use_count() : true;</span></span>
<span id="L344"><span class="lineNum">     344</span>              :   }</span>
<span id="L345"><span class="lineNum">     345</span>              :   // NOTE: As of C++11 and 14, default-constructing a std::atomic variable</span>
<span id="L346"><span class="lineNum">     346</span>              :   // leaves it in a persistently undefined state. See</span>
<span id="L347"><span class="lineNum">     347</span>              :   // https://cplusplus.github.io/LWG/issue2334.</span>
<span id="L348"><span class="lineNum">     348</span> <span class="tlaGNC">      378768 :   VariableVersion(uint32_t version)</span></span>
<span id="L349"><span class="lineNum">     349</span> <span class="tlaGNC">      378768 :       : version_counter_(c10::make_intrusive&lt;VersionCounter&gt;(version)) {}</span></span>
<span id="L350"><span class="lineNum">     350</span>              :   VariableVersion(Disabled = DISABLED) {}</span>
<span id="L351"><span class="lineNum">     351</span>              : </span>
<span id="L352"><span class="lineNum">     352</span>              :   bool enabled() const {</span>
<span id="L353"><span class="lineNum">     353</span>              :     return version_counter_;</span>
<span id="L354"><span class="lineNum">     354</span>              :   }</span>
<span id="L355"><span class="lineNum">     355</span>              : </span>
<span id="L356"><span class="lineNum">     356</span>              :   // Note [Inplace update inference tensor]</span>
<span id="L357"><span class="lineNum">     357</span>              :   // 1. Inplace update to inference tensor is forbidden in normal mode.</span>
<span id="L358"><span class="lineNum">     358</span>              :   //   For example:</span>
<span id="L359"><span class="lineNum">     359</span>              :   //     inference_tensor.copy_(normal_tensor_requires_grad)</span>
<span id="L360"><span class="lineNum">     360</span>              :   //   This inplace makes inference_tensor have requires_grad=True and</span>
<span id="L361"><span class="lineNum">     361</span>              :   //   have a grad_fn.  This is bad because views of `inference_tensor`</span>
<span id="L362"><span class="lineNum">     362</span>              :   //   created in InferenceMode won't be able to know the grad_fn since</span>
<span id="L363"><span class="lineNum">     363</span>              :   //   their ViewMeta were not recorded. To match NoGradMode behavior</span>
<span id="L364"><span class="lineNum">     364</span>              :   //   that &quot;inplace update to a view created in NoGradMode raise an error&quot;,</span>
<span id="L365"><span class="lineNum">     365</span>              :   //   we just ban inplace update to inference tensor since we can't tell</span>
<span id="L366"><span class="lineNum">     366</span>              :   //   if an inference tensor is a view created in InferenceMode.</span>
<span id="L367"><span class="lineNum">     367</span>              :   //</span>
<span id="L368"><span class="lineNum">     368</span>              :   //   Note that views of normal tensor created in InferenceMode has proper</span>
<span id="L369"><span class="lineNum">     369</span>              :   //   ViewMeta so that they're aware of the grad_fn correctly.</span>
<span id="L370"><span class="lineNum">     370</span>              :   //</span>
<span id="L371"><span class="lineNum">     371</span>              :   // 2. Inplace update to inference tensor in inference tensor doesn't bump</span>
<span id="L372"><span class="lineNum">     372</span>              :   //    version counter.</span>
<span id="L373"><span class="lineNum">     373</span>              :   //    * It either doesn't call bump() by skipping ADInplaceOrView kernel,</span>
<span id="L374"><span class="lineNum">     374</span>              :   //      - e.g. inference_tensor.add_(1)</span>
<span id="L375"><span class="lineNum">     375</span>              :   //    * or bump() is a no-op for inference tensor.</span>
<span id="L376"><span class="lineNum">     376</span>              :   //      - e.g. inference_tensor.add_(normal_tensor)</span>
<span id="L377"><span class="lineNum">     377</span>              :   void bump() {</span>
<span id="L378"><span class="lineNum">     378</span>              :     // TODO: Replace the link to the documentation once it's available.</span>
<span id="L379"><span class="lineNum">     379</span>              :     TORCH_CHECK(</span>
<span id="L380"><span class="lineNum">     380</span>              :         version_counter_ || InferenceMode::is_enabled(),</span>
<span id="L381"><span class="lineNum">     381</span>              :         &quot;Inplace update to inference tensor outside InferenceMode is not allowed.&quot;</span>
<span id="L382"><span class="lineNum">     382</span>              :         &quot;You can make a clone to get a normal tensor before doing inplace update.&quot;</span>
<span id="L383"><span class="lineNum">     383</span>              :         &quot;See https://github.com/pytorch/rfcs/pull/17 for more details.&quot;);</span>
<span id="L384"><span class="lineNum">     384</span>              :     if (version_counter_) {</span>
<span id="L385"><span class="lineNum">     385</span>              :       ++version_counter_-&gt;version_;</span>
<span id="L386"><span class="lineNum">     386</span>              :     }</span>
<span id="L387"><span class="lineNum">     387</span>              :   }</span>
<span id="L388"><span class="lineNum">     388</span>              : </span>
<span id="L389"><span class="lineNum">     389</span>              :   void set_version(int64_t i) {</span>
<span id="L390"><span class="lineNum">     390</span>              :     TORCH_CHECK(</span>
<span id="L391"><span class="lineNum">     391</span>              :         version_counter_,</span>
<span id="L392"><span class="lineNum">     392</span>              :         &quot;Tried to call torch.autograd._unsafe_set_version() on a tensor &quot;</span>
<span id="L393"><span class="lineNum">     393</span>              :         &quot;that does not have a version counter. Was it created in inference mode?&quot;);</span>
<span id="L394"><span class="lineNum">     394</span>              :     TORCH_CHECK(i &gt;= 0, &quot;Cannot set a version_counter to a value below 0: &quot;, i);</span>
<span id="L395"><span class="lineNum">     395</span>              :     version_counter_-&gt;version_ = i;</span>
<span id="L396"><span class="lineNum">     396</span>              :   }</span>
<span id="L397"><span class="lineNum">     397</span>              : </span>
<span id="L398"><span class="lineNum">     398</span>              :   // Inference tensor doesn't have version counter so it shouldn't be</span>
<span id="L399"><span class="lineNum">     399</span>              :   // accessed.</span>
<span id="L400"><span class="lineNum">     400</span>              :   uint32_t current_version() const {</span>
<span id="L401"><span class="lineNum">     401</span>              :     TORCH_CHECK(</span>
<span id="L402"><span class="lineNum">     402</span>              :         version_counter_, &quot;Inference tensors do not track version counter.&quot;);</span>
<span id="L403"><span class="lineNum">     403</span>              :     return version_counter_-&gt;version_;</span>
<span id="L404"><span class="lineNum">     404</span>              :   }</span>
<span id="L405"><span class="lineNum">     405</span>              : };</span>
<span id="L406"><span class="lineNum">     406</span>              : </span>
<span id="L407"><span class="lineNum">     407</span>              : // Forward declaration of TensorImpl needed for forward declaration of</span>
<span id="L408"><span class="lineNum">     408</span>              : // C10_TensorImpl_Size_Check_Dummy_Class</span>
<span id="L409"><span class="lineNum">     409</span>              : struct C10_API TensorImpl;</span>
<span id="L410"><span class="lineNum">     410</span>              : </span>
<span id="L411"><span class="lineNum">     411</span>              : /**</span>
<span id="L412"><span class="lineNum">     412</span>              :  * NOTE: Some TensorImpl methods are small and not overridden in the</span>
<span id="L413"><span class="lineNum">     413</span>              :  * PyTorch codebase itself, but may theoretically need to be</span>
<span id="L414"><span class="lineNum">     414</span>              :  * overridden by third-party TensorImpl subclasses. This macro allows</span>
<span id="L415"><span class="lineNum">     415</span>              :  * users that need maximum performance and don't need these extension</span>
<span id="L416"><span class="lineNum">     416</span>              :  * points to disable them with a build-time flag. (In particular,</span>
<span id="L417"><span class="lineNum">     417</span>              :  * XLA's XLATensorImpl currently overrides these methods, so we can't</span>
<span id="L418"><span class="lineNum">     418</span>              :  * enable this flag by default.)</span>
<span id="L419"><span class="lineNum">     419</span>              :  */</span>
<span id="L420"><span class="lineNum">     420</span>              : #ifdef C10_DISABLE_TENSORIMPL_EXTENSIBILITY</span>
<span id="L421"><span class="lineNum">     421</span>              : #define TENSORIMPL_MAYBE_VIRTUAL</span>
<span id="L422"><span class="lineNum">     422</span>              : #else</span>
<span id="L423"><span class="lineNum">     423</span>              : #define TENSORIMPL_MAYBE_VIRTUAL virtual</span>
<span id="L424"><span class="lineNum">     424</span>              : #endif</span>
<span id="L425"><span class="lineNum">     425</span>              : </span>
<span id="L426"><span class="lineNum">     426</span>              : /**</span>
<span id="L427"><span class="lineNum">     427</span>              :  * The low-level representation of a tensor, which contains a pointer</span>
<span id="L428"><span class="lineNum">     428</span>              :  * to a storage (which contains the actual data) and metadata (e.g., sizes and</span>
<span id="L429"><span class="lineNum">     429</span>              :  * strides) describing this particular view of the data as a tensor.</span>
<span id="L430"><span class="lineNum">     430</span>              :  *</span>
<span id="L431"><span class="lineNum">     431</span>              :  * Some basic characteristics about our in-memory representation of</span>
<span id="L432"><span class="lineNum">     432</span>              :  * tensors:</span>
<span id="L433"><span class="lineNum">     433</span>              :  *</span>
<span id="L434"><span class="lineNum">     434</span>              :  *  - It contains a pointer to a storage struct (Storage/StorageImpl)</span>
<span id="L435"><span class="lineNum">     435</span>              :  *    which contains the pointer to the actual data and records the</span>
<span id="L436"><span class="lineNum">     436</span>              :  *    data type and device of the view.  This allows multiple tensors</span>
<span id="L437"><span class="lineNum">     437</span>              :  *    to alias the same underlying data, which allows to efficiently</span>
<span id="L438"><span class="lineNum">     438</span>              :  *    implement differing *views* on a tensor.</span>
<span id="L439"><span class="lineNum">     439</span>              :  *</span>
<span id="L440"><span class="lineNum">     440</span>              :  *  - The tensor struct itself records view-specific metadata about</span>
<span id="L441"><span class="lineNum">     441</span>              :  *    the tensor, e.g., sizes, strides and offset into storage.</span>
<span id="L442"><span class="lineNum">     442</span>              :  *    Each view of a storage can have a different size or offset.</span>
<span id="L443"><span class="lineNum">     443</span>              :  *</span>
<span id="L444"><span class="lineNum">     444</span>              :  *  - This class is intrusively refcounted.  It is refcounted so that</span>
<span id="L445"><span class="lineNum">     445</span>              :  *    we can support prompt deallocation of large tensors; it is</span>
<span id="L446"><span class="lineNum">     446</span>              :  *    intrusively refcounted so that we can still perform reference</span>
<span id="L447"><span class="lineNum">     447</span>              :  *    counted operations on raw pointers, which is often more convenient</span>
<span id="L448"><span class="lineNum">     448</span>              :  *    when passing tensors across language boundaries.</span>
<span id="L449"><span class="lineNum">     449</span>              :  *</span>
<span id="L450"><span class="lineNum">     450</span>              :  *  - For backwards-compatibility reasons, a tensor may be in an</span>
<span id="L451"><span class="lineNum">     451</span>              :  *    uninitialized state.  A tensor may be uninitialized in the following</span>
<span id="L452"><span class="lineNum">     452</span>              :  *    two ways:</span>
<span id="L453"><span class="lineNum">     453</span>              :  *</span>
<span id="L454"><span class="lineNum">     454</span>              :  *      - A tensor may be DTYPE UNINITIALIZED.  A tensor of this</span>
<span id="L455"><span class="lineNum">     455</span>              :  *        form has an uninitialized dtype.  This situation most</span>
<span id="L456"><span class="lineNum">     456</span>              :  *        frequently arises when a user writes Tensor x(CPU).  The dtype</span>
<span id="L457"><span class="lineNum">     457</span>              :  *        is subsequently initialized when mutable_data&lt;T&gt;() is</span>
<span id="L458"><span class="lineNum">     458</span>              :  *        invoked for the first time.</span>
<span id="L459"><span class="lineNum">     459</span>              :  *</span>
<span id="L460"><span class="lineNum">     460</span>              :  *      - A tensor may be STORAGE UNINITIALIZED.  A tensor of this form</span>
<span id="L461"><span class="lineNum">     461</span>              :  *        has non-zero size, but has a storage with a null data pointer.</span>
<span id="L462"><span class="lineNum">     462</span>              :  *        This situation most frequently arises when a user calls</span>
<span id="L463"><span class="lineNum">     463</span>              :  *        Resize() or FreeMemory().  This is because Caffe2 historically</span>
<span id="L464"><span class="lineNum">     464</span>              :  *        does lazy allocation: allocation of data doesn't occur until</span>
<span id="L465"><span class="lineNum">     465</span>              :  *        mutable_data&lt;T&gt;() is invoked.  A tensor with zero size is</span>
<span id="L466"><span class="lineNum">     466</span>              :  *        always storage initialized, because no allocation is necessary</span>
<span id="L467"><span class="lineNum">     467</span>              :  *        in this case.</span>
<span id="L468"><span class="lineNum">     468</span>              :  *</span>
<span id="L469"><span class="lineNum">     469</span>              :  *    All combinations of these two uninitialized states are possible.</span>
<span id="L470"><span class="lineNum">     470</span>              :  *    Consider the following transcript in idiomatic Caffe2 API:</span>
<span id="L471"><span class="lineNum">     471</span>              :  *</span>
<span id="L472"><span class="lineNum">     472</span>              :  *      Tensor x(CPU); // x is storage-initialized, dtype-UNINITIALIZED</span>
<span id="L473"><span class="lineNum">     473</span>              :  *      x.Resize(4); // x is storage-UNINITIALIZED, dtype-UNINITIALIZED</span>
<span id="L474"><span class="lineNum">     474</span>              :  *      x.mutable_data&lt;float&gt;(); // x is storage-initialized, dtype-initialized</span>
<span id="L475"><span class="lineNum">     475</span>              :  *      x.FreeMemory(); // x is storage-UNINITIALIZED, dtype-initialized.</span>
<span id="L476"><span class="lineNum">     476</span>              :  *</span>
<span id="L477"><span class="lineNum">     477</span>              :  *    All other fields on tensor are always initialized.  In particular,</span>
<span id="L478"><span class="lineNum">     478</span>              :  *    size is always valid. (Historically, a tensor declared as Tensor x(CPU)</span>
<span id="L479"><span class="lineNum">     479</span>              :  *    also had uninitialized size, encoded as numel == -1, but we have now</span>
<span id="L480"><span class="lineNum">     480</span>              :  *    decided to default to zero size, resulting in numel == 0).</span>
<span id="L481"><span class="lineNum">     481</span>              :  *</span>
<span id="L482"><span class="lineNum">     482</span>              :  *    Uninitialized storages MUST be uniquely owned, to keep our model</span>
<span id="L483"><span class="lineNum">     483</span>              :  *    simple.  Thus, we will reject operations which could cause an</span>
<span id="L484"><span class="lineNum">     484</span>              :  *    uninitialized storage to become shared (or a shared storage to</span>
<span id="L485"><span class="lineNum">     485</span>              :  *    become uninitialized, e.g., from FreeMemory).</span>
<span id="L486"><span class="lineNum">     486</span>              :  *</span>
<span id="L487"><span class="lineNum">     487</span>              :  *    In practice, tensors which are storage-UNINITIALIZED and</span>
<span id="L488"><span class="lineNum">     488</span>              :  *    dtype-UNINITIALIZED are *extremely* ephemeral: essentially,</span>
<span id="L489"><span class="lineNum">     489</span>              :  *    after you do a Resize(), you basically always call mutable_data()</span>
<span id="L490"><span class="lineNum">     490</span>              :  *    immediately afterwards.  Most functions are not designed to</span>
<span id="L491"><span class="lineNum">     491</span>              :  *    work if given a storage-UNINITIALIZED, dtype-UNINITIALIZED tensor.</span>
<span id="L492"><span class="lineNum">     492</span>              :  *</span>
<span id="L493"><span class="lineNum">     493</span>              :  *    We intend to eliminate all uninitialized states, so that every</span>
<span id="L494"><span class="lineNum">     494</span>              :  *    tensor is fully initialized in all fields.  Please do not write new code</span>
<span id="L495"><span class="lineNum">     495</span>              :  *    that depends on these uninitialized states.</span>
<span id="L496"><span class="lineNum">     496</span>              :  */</span>
<span id="L497"><span class="lineNum">     497</span>              : struct C10_API TensorImpl : public c10::intrusive_ptr_target {</span>
<span id="L498"><span class="lineNum">     498</span>              :   TensorImpl() = delete;</span>
<span id="L499"><span class="lineNum">     499</span>              :   ~TensorImpl() override;</span>
<span id="L500"><span class="lineNum">     500</span>              :   // Note [Enum ImplType]</span>
<span id="L501"><span class="lineNum">     501</span>              :   // This enum is temporary. In the followup refactor we should</span>
<span id="L502"><span class="lineNum">     502</span>              :   // think about how to specialize TensorImpl creation for view</span>
<span id="L503"><span class="lineNum">     503</span>              :   // tensors. Currently we only special case its key_set_ but</span>
<span id="L504"><span class="lineNum">     504</span>              :   // there's also potential to share version_counter_ directly</span>
<span id="L505"><span class="lineNum">     505</span>              :   // without creating first and then override in as_view.</span>
<span id="L506"><span class="lineNum">     506</span>              :   enum ImplType { VIEW };</span>
<span id="L507"><span class="lineNum">     507</span>              : </span>
<span id="L508"><span class="lineNum">     508</span>              :   /**</span>
<span id="L509"><span class="lineNum">     509</span>              :    * Construct a 1-dim 0-size tensor backed by the given storage.</span>
<span id="L510"><span class="lineNum">     510</span>              :    */</span>
<span id="L511"><span class="lineNum">     511</span>              :   TensorImpl(</span>
<span id="L512"><span class="lineNum">     512</span>              :       Storage&amp;&amp; storage,</span>
<span id="L513"><span class="lineNum">     513</span>              :       DispatchKeySet,</span>
<span id="L514"><span class="lineNum">     514</span>              :       const caffe2::TypeMeta data_type);</span>
<span id="L515"><span class="lineNum">     515</span>              : </span>
<span id="L516"><span class="lineNum">     516</span>              :   // See Note [Enum ImplType]</span>
<span id="L517"><span class="lineNum">     517</span>              :   TensorImpl(</span>
<span id="L518"><span class="lineNum">     518</span>              :       ImplType,</span>
<span id="L519"><span class="lineNum">     519</span>              :       Storage&amp;&amp; storage,</span>
<span id="L520"><span class="lineNum">     520</span>              :       DispatchKeySet,</span>
<span id="L521"><span class="lineNum">     521</span>              :       const caffe2::TypeMeta data_type);</span>
<span id="L522"><span class="lineNum">     522</span>              : </span>
<span id="L523"><span class="lineNum">     523</span>              :   /**</span>
<span id="L524"><span class="lineNum">     524</span>              :    * Construct a 1-dim 0 size tensor that doesn't have a storage.</span>
<span id="L525"><span class="lineNum">     525</span>              :    */</span>
<span id="L526"><span class="lineNum">     526</span>              :   TensorImpl(</span>
<span id="L527"><span class="lineNum">     527</span>              :       DispatchKeySet,</span>
<span id="L528"><span class="lineNum">     528</span>              :       const caffe2::TypeMeta data_type,</span>
<span id="L529"><span class="lineNum">     529</span>              :       c10::optional&lt;c10::Device&gt; device_opt);</span>
<span id="L530"><span class="lineNum">     530</span>              : </span>
<span id="L531"><span class="lineNum">     531</span>              :   // Legacy constructors so I don't have to go update call sites.</span>
<span id="L532"><span class="lineNum">     532</span>              :   // TODO: When Variable is added, delete these constructors</span>
<span id="L533"><span class="lineNum">     533</span>              :   TensorImpl(</span>
<span id="L534"><span class="lineNum">     534</span>              :       Storage&amp;&amp; storage,</span>
<span id="L535"><span class="lineNum">     535</span>              :       DispatchKey dispatch_key,</span>
<span id="L536"><span class="lineNum">     536</span>              :       const caffe2::TypeMeta data_type)</span>
<span id="L537"><span class="lineNum">     537</span>              :       : TensorImpl(</span>
<span id="L538"><span class="lineNum">     538</span>              :             std::move(storage),</span>
<span id="L539"><span class="lineNum">     539</span>              :             DispatchKeySet(dispatch_key),</span>
<span id="L540"><span class="lineNum">     540</span>              :             data_type) {}</span>
<span id="L541"><span class="lineNum">     541</span>              :   TensorImpl(</span>
<span id="L542"><span class="lineNum">     542</span>              :       DispatchKey dispatch_key,</span>
<span id="L543"><span class="lineNum">     543</span>              :       const caffe2::TypeMeta data_type,</span>
<span id="L544"><span class="lineNum">     544</span>              :       c10::optional&lt;c10::Device&gt; device_opt)</span>
<span id="L545"><span class="lineNum">     545</span>              :       : TensorImpl(DispatchKeySet(dispatch_key), data_type, device_opt) {}</span>
<span id="L546"><span class="lineNum">     546</span>              : </span>
<span id="L547"><span class="lineNum">     547</span>              :  private:</span>
<span id="L548"><span class="lineNum">     548</span>              :   // This constructor is private, because the data_type is redundant with</span>
<span id="L549"><span class="lineNum">     549</span>              :   // storage.  Still, we pass it in separately because it's easier to write</span>
<span id="L550"><span class="lineNum">     550</span>              :   // the initializer list if we're not worried about storage being moved out</span>
<span id="L551"><span class="lineNum">     551</span>              :   // from under us.</span>
<span id="L552"><span class="lineNum">     552</span>              :   TensorImpl(</span>
<span id="L553"><span class="lineNum">     553</span>              :       Storage&amp;&amp; storage,</span>
<span id="L554"><span class="lineNum">     554</span>              :       DispatchKeySet,</span>
<span id="L555"><span class="lineNum">     555</span>              :       const caffe2::TypeMeta data_type,</span>
<span id="L556"><span class="lineNum">     556</span>              :       c10::optional&lt;c10::Device&gt;);</span>
<span id="L557"><span class="lineNum">     557</span>              : </span>
<span id="L558"><span class="lineNum">     558</span>              :  public:</span>
<span id="L559"><span class="lineNum">     559</span>              :   TensorImpl(const TensorImpl&amp;) = delete;</span>
<span id="L560"><span class="lineNum">     560</span>              :   TensorImpl&amp; operator=(const TensorImpl&amp;) = delete;</span>
<span id="L561"><span class="lineNum">     561</span>              :   TensorImpl(TensorImpl&amp;&amp;) = delete;</span>
<span id="L562"><span class="lineNum">     562</span>              :   TensorImpl&amp; operator=(TensorImpl&amp;&amp;) = delete;</span>
<span id="L563"><span class="lineNum">     563</span>              : </span>
<span id="L564"><span class="lineNum">     564</span>              :   /**</span>
<span id="L565"><span class="lineNum">     565</span>              :    * Release (decref) storage, and any other external allocations.  This</span>
<span id="L566"><span class="lineNum">     566</span>              :    * override is for `intrusive_ptr_target` and is used to implement weak</span>
<span id="L567"><span class="lineNum">     567</span>              :    * tensors.</span>
<span id="L568"><span class="lineNum">     568</span>              :    */</span>
<span id="L569"><span class="lineNum">     569</span>              :   void release_resources() override;</span>
<span id="L570"><span class="lineNum">     570</span>              : </span>
<span id="L571"><span class="lineNum">     571</span>              :  public:</span>
<span id="L572"><span class="lineNum">     572</span>              :   /**</span>
<span id="L573"><span class="lineNum">     573</span>              :    * Return the DispatchKeySet corresponding to this Tensor, specifying</span>
<span id="L574"><span class="lineNum">     574</span>              :    * all of the DispatchKeys that this Tensor identifies as.  This is the</span>
<span id="L575"><span class="lineNum">     575</span>              :    * information used to dispatch operations on this tensor.</span>
<span id="L576"><span class="lineNum">     576</span>              :    */</span>
<span id="L577"><span class="lineNum">     577</span>              :   DispatchKeySet key_set() const {</span>
<span id="L578"><span class="lineNum">     578</span>              :     return key_set_;</span>
<span id="L579"><span class="lineNum">     579</span>              :   }</span>
<span id="L580"><span class="lineNum">     580</span>              : </span>
<span id="L581"><span class="lineNum">     581</span>              :   // NOTE: The general recipe for customizable methods is that the fastpath</span>
<span id="L582"><span class="lineNum">     582</span>              :   // function (e.g., sizes()) does an unlikely policy test, and if doesn't</span>
<span id="L583"><span class="lineNum">     583</span>              :   // trigger, it does the fast path implementation with no checks and going</span>
<span id="L584"><span class="lineNum">     584</span>              :   // directly to on-TensorImpl fields.  In particular, you never need to</span>
<span id="L585"><span class="lineNum">     585</span>              :   // check ExtraMeta if the policy doesn't trigger, as non-trivial ExtraMeta</span>
<span id="L586"><span class="lineNum">     586</span>              :   // implies the policy will always match.</span>
<span id="L587"><span class="lineNum">     587</span>              :   //</span>
<span id="L588"><span class="lineNum">     588</span>              :   // The default implementations of methods are &quot;safe&quot;: they do extra tests</span>
<span id="L589"><span class="lineNum">     589</span>              :   // to make sure the internal state is consistent no matter if you are</span>
<span id="L590"><span class="lineNum">     590</span>              :   // doing symbolic shapes or not.  If you don't want the tests, directly</span>
<span id="L591"><span class="lineNum">     591</span>              :   // override the custom method (e.g., custom_sizes()) to do your preferred</span>
<span id="L592"><span class="lineNum">     592</span>              :   // behavior.</span>
<span id="L593"><span class="lineNum">     593</span>              : </span>
<span id="L594"><span class="lineNum">     594</span>              :  public:</span>
<span id="L595"><span class="lineNum">     595</span>              :   /**</span>
<span id="L596"><span class="lineNum">     596</span>              :    * Return a reference to the sizes of this tensor.  This reference remains</span>
<span id="L597"><span class="lineNum">     597</span>              :    * valid as long as the tensor is live and not resized.</span>
<span id="L598"><span class="lineNum">     598</span>              :    */</span>
<span id="L599"><span class="lineNum">     599</span> <span class="tlaGNC">       88706 :   IntArrayRef sizes() const {</span></span>
<span id="L600"><span class="lineNum">     600</span> <span class="tlaGNC">       88706 :     if (C10_UNLIKELY(matches_policy(SizesStridesPolicy::CustomSizes))) {</span></span>
<span id="L601"><span class="lineNum">     601</span> <span class="tlaUNC tlaBgUNC">           0 :       return sizes_custom();</span></span>
<span id="L602"><span class="lineNum">     602</span>              :     }</span>
<span id="L603"><span class="lineNum">     603</span> <span class="tlaGNC tlaBgGNC">       88706 :     return sizes_and_strides_.sizes_arrayref();</span></span>
<span id="L604"><span class="lineNum">     604</span>              :   }</span>
<span id="L605"><span class="lineNum">     605</span>              : </span>
<span id="L606"><span class="lineNum">     606</span>              :   SymIntArrayRef sym_sizes() const {</span>
<span id="L607"><span class="lineNum">     607</span>              :     if (C10_UNLIKELY(matches_policy(SizesStridesPolicy::CustomSizes))) {</span>
<span id="L608"><span class="lineNum">     608</span>              :       return sym_sizes_custom();</span>
<span id="L609"><span class="lineNum">     609</span>              :     }</span>
<span id="L610"><span class="lineNum">     610</span>              :     // Sizes guaranteed to be non-negative, so unchecked cast is OK</span>
<span id="L611"><span class="lineNum">     611</span>              :     return c10::fromIntArrayRefKnownNonNegative(</span>
<span id="L612"><span class="lineNum">     612</span>              :         sizes_and_strides_.sizes_arrayref());</span>
<span id="L613"><span class="lineNum">     613</span>              :   }</span>
<span id="L614"><span class="lineNum">     614</span>              : </span>
<span id="L615"><span class="lineNum">     615</span>              :   IntArrayRef sizes_default() const {</span>
<span id="L616"><span class="lineNum">     616</span>              :     // TODO: force backtrace to be printed on this error</span>
<span id="L617"><span class="lineNum">     617</span>              :     TORCH_CHECK(</span>
<span id="L618"><span class="lineNum">     618</span>              :         !has_symbolic_sizes_strides_,</span>
<span id="L619"><span class="lineNum">     619</span>              :         &quot;Cannot call sizes() on tensor with symbolic sizes/strides&quot;);</span>
<span id="L620"><span class="lineNum">     620</span>              :     return sizes_and_strides_.sizes_arrayref();</span>
<span id="L621"><span class="lineNum">     621</span>              :   }</span>
<span id="L622"><span class="lineNum">     622</span>              : </span>
<span id="L623"><span class="lineNum">     623</span>              :   SymIntArrayRef sym_sizes_default() const {</span>
<span id="L624"><span class="lineNum">     624</span>              :     if (has_symbolic_sizes_strides_) {</span>
<span id="L625"><span class="lineNum">     625</span>              :       return symbolic_shape_meta().sizes_;</span>
<span id="L626"><span class="lineNum">     626</span>              :     } else {</span>
<span id="L627"><span class="lineNum">     627</span>              :       // Sizes guaranteed to be non-negative, so unchecked cast is OK</span>
<span id="L628"><span class="lineNum">     628</span>              :       return c10::fromIntArrayRefKnownNonNegative(sizes_default());</span>
<span id="L629"><span class="lineNum">     629</span>              :     }</span>
<span id="L630"><span class="lineNum">     630</span>              :   }</span>
<span id="L631"><span class="lineNum">     631</span>              : </span>
<span id="L632"><span class="lineNum">     632</span>              :   // From https://stackoverflow.com/a/3057522/23845</span>
<span id="L633"><span class="lineNum">     633</span>              :   // TODO: does C++14 have a stdlib template for this?</span>
<span id="L634"><span class="lineNum">     634</span>              :   template &lt;typename T&gt;</span>
<span id="L635"><span class="lineNum">     635</span>              :   struct identity {</span>
<span id="L636"><span class="lineNum">     636</span>              :     typedef T type;</span>
<span id="L637"><span class="lineNum">     637</span>              :   };</span>
<span id="L638"><span class="lineNum">     638</span>              : </span>
<span id="L639"><span class="lineNum">     639</span>              :   template &lt;typename T&gt;</span>
<span id="L640"><span class="lineNum">     640</span>              :   ArrayRef&lt;T&gt; generic_sizes() {</span>
<span id="L641"><span class="lineNum">     641</span>              :     return _generic_sizes(identity&lt;T&gt;());</span>
<span id="L642"><span class="lineNum">     642</span>              :   }</span>
<span id="L643"><span class="lineNum">     643</span>              : </span>
<span id="L644"><span class="lineNum">     644</span>              :   ArrayRef&lt;int64_t&gt; _generic_sizes(identity&lt;int64_t&gt;) {</span>
<span id="L645"><span class="lineNum">     645</span>              :     return sizes();</span>
<span id="L646"><span class="lineNum">     646</span>              :   }</span>
<span id="L647"><span class="lineNum">     647</span>              :   ArrayRef&lt;c10::SymInt&gt; _generic_sizes(identity&lt;c10::SymInt&gt;) {</span>
<span id="L648"><span class="lineNum">     648</span>              :     return sym_sizes();</span>
<span id="L649"><span class="lineNum">     649</span>              :   }</span>
<span id="L650"><span class="lineNum">     650</span>              : </span>
<span id="L651"><span class="lineNum">     651</span>              :   template &lt;typename T&gt;</span>
<span id="L652"><span class="lineNum">     652</span>              :   ArrayRef&lt;T&gt; generic_strides() {</span>
<span id="L653"><span class="lineNum">     653</span>              :     return _generic_strides(identity&lt;T&gt;());</span>
<span id="L654"><span class="lineNum">     654</span>              :   }</span>
<span id="L655"><span class="lineNum">     655</span>              : </span>
<span id="L656"><span class="lineNum">     656</span>              :   ArrayRef&lt;int64_t&gt; _generic_strides(identity&lt;int64_t&gt;) {</span>
<span id="L657"><span class="lineNum">     657</span>              :     return strides();</span>
<span id="L658"><span class="lineNum">     658</span>              :   }</span>
<span id="L659"><span class="lineNum">     659</span>              :   ArrayRef&lt;c10::SymInt&gt; _generic_strides(identity&lt;c10::SymInt&gt;) {</span>
<span id="L660"><span class="lineNum">     660</span>              :     return sym_strides();</span>
<span id="L661"><span class="lineNum">     661</span>              :   }</span>
<span id="L662"><span class="lineNum">     662</span>              : </span>
<span id="L663"><span class="lineNum">     663</span>              :   template &lt;typename T&gt;</span>
<span id="L664"><span class="lineNum">     664</span>              :   T generic_storage_offset() {</span>
<span id="L665"><span class="lineNum">     665</span>              :     return _generic_storage_offset(identity&lt;T&gt;());</span>
<span id="L666"><span class="lineNum">     666</span>              :   }</span>
<span id="L667"><span class="lineNum">     667</span>              : </span>
<span id="L668"><span class="lineNum">     668</span>              :   int64_t _generic_storage_offset(identity&lt;int64_t&gt;) {</span>
<span id="L669"><span class="lineNum">     669</span>              :     return storage_offset();</span>
<span id="L670"><span class="lineNum">     670</span>              :   }</span>
<span id="L671"><span class="lineNum">     671</span>              :   c10::SymInt _generic_storage_offset(identity&lt;c10::SymInt&gt;) {</span>
<span id="L672"><span class="lineNum">     672</span>              :     return sym_storage_offset();</span>
<span id="L673"><span class="lineNum">     673</span>              :   }</span>
<span id="L674"><span class="lineNum">     674</span>              : </span>
<span id="L675"><span class="lineNum">     675</span>              :   /**</span>
<span id="L676"><span class="lineNum">     676</span>              :    * The number of elements in a tensor.</span>
<span id="L677"><span class="lineNum">     677</span>              :    *</span>
<span id="L678"><span class="lineNum">     678</span>              :    * WARNING: Previously, if you were using the Caffe2 API, you could</span>
<span id="L679"><span class="lineNum">     679</span>              :    * test numel() == -1 to see if a tensor was uninitialized.  This</span>
<span id="L680"><span class="lineNum">     680</span>              :    * is no longer true; numel always accurately reports the product</span>
<span id="L681"><span class="lineNum">     681</span>              :    * of sizes of a tensor.</span>
<span id="L682"><span class="lineNum">     682</span>              :    */</span>
<span id="L683"><span class="lineNum">     683</span> <span class="tlaGNC">         500 :   int64_t numel() const {</span></span>
<span id="L684"><span class="lineNum">     684</span> <span class="tlaGNC">         500 :     if (C10_UNLIKELY(matches_policy(SizesStridesPolicy::CustomSizes))) {</span></span>
<span id="L685"><span class="lineNum">     685</span> <span class="tlaUNC tlaBgUNC">           0 :       return numel_custom();</span></span>
<span id="L686"><span class="lineNum">     686</span>              :     }</span>
<span id="L687"><span class="lineNum">     687</span> <span class="tlaGNC tlaBgGNC">         500 :     return numel_;</span></span>
<span id="L688"><span class="lineNum">     688</span>              :   }</span>
<span id="L689"><span class="lineNum">     689</span>              : </span>
<span id="L690"><span class="lineNum">     690</span>              :   c10::SymInt sym_numel() const {</span>
<span id="L691"><span class="lineNum">     691</span>              :     if (C10_UNLIKELY(matches_policy(SizesStridesPolicy::CustomSizes))) {</span>
<span id="L692"><span class="lineNum">     692</span>              :       return sym_numel_custom();</span>
<span id="L693"><span class="lineNum">     693</span>              :     }</span>
<span id="L694"><span class="lineNum">     694</span>              :     return c10::SymInt(SymInt::UNCHECKED, numel_);</span>
<span id="L695"><span class="lineNum">     695</span>              :   }</span>
<span id="L696"><span class="lineNum">     696</span>              : </span>
<span id="L697"><span class="lineNum">     697</span>              :   int64_t numel_default() const {</span>
<span id="L698"><span class="lineNum">     698</span>              :     TORCH_CHECK(</span>
<span id="L699"><span class="lineNum">     699</span>              :         !has_symbolic_sizes_strides_,</span>
<span id="L700"><span class="lineNum">     700</span>              :         &quot;Cannot call numel() on tensor with symbolic sizes/strides&quot;);</span>
<span id="L701"><span class="lineNum">     701</span>              :     return numel_;</span>
<span id="L702"><span class="lineNum">     702</span>              :   }</span>
<span id="L703"><span class="lineNum">     703</span>              : </span>
<span id="L704"><span class="lineNum">     704</span>              :   c10::SymInt sym_numel_default() const {</span>
<span id="L705"><span class="lineNum">     705</span>              :     if (has_symbolic_sizes_strides_) {</span>
<span id="L706"><span class="lineNum">     706</span>              :       return symbolic_shape_meta().numel_;</span>
<span id="L707"><span class="lineNum">     707</span>              :     } else {</span>
<span id="L708"><span class="lineNum">     708</span>              :       return c10::SymInt(SymInt::UNCHECKED, numel_);</span>
<span id="L709"><span class="lineNum">     709</span>              :     }</span>
<span id="L710"><span class="lineNum">     710</span>              :   }</span>
<span id="L711"><span class="lineNum">     711</span>              : </span>
<span id="L712"><span class="lineNum">     712</span>              :   /**</span>
<span id="L713"><span class="lineNum">     713</span>              :    * Return the number of dimensions of this tensor.  Note that 0-dimension</span>
<span id="L714"><span class="lineNum">     714</span>              :    * represents a Tensor that is a Scalar, e.g., one that has a single element.</span>
<span id="L715"><span class="lineNum">     715</span>              :    */</span>
<span id="L716"><span class="lineNum">     716</span> <span class="tlaGNC">    15317888 :   int64_t dim() const {</span></span>
<span id="L717"><span class="lineNum">     717</span> <span class="tlaGNC">    15317888 :     if (C10_UNLIKELY(matches_policy(SizesStridesPolicy::CustomSizes))) {</span></span>
<span id="L718"><span class="lineNum">     718</span> <span class="tlaUNC tlaBgUNC">           0 :       return dim_custom();</span></span>
<span id="L719"><span class="lineNum">     719</span>              :     }</span>
<span id="L720"><span class="lineNum">     720</span> <span class="tlaGNC tlaBgGNC">    15317888 :     return sizes_and_strides_.size();</span></span>
<span id="L721"><span class="lineNum">     721</span>              :   }</span>
<span id="L722"><span class="lineNum">     722</span>              : </span>
<span id="L723"><span class="lineNum">     723</span>              :   int64_t dim_default() const {</span>
<span id="L724"><span class="lineNum">     724</span>              :     if (has_symbolic_sizes_strides_) {</span>
<span id="L725"><span class="lineNum">     725</span>              :       return symbolic_shape_meta().sizes_.size();</span>
<span id="L726"><span class="lineNum">     726</span>              :     } else {</span>
<span id="L727"><span class="lineNum">     727</span>              :       return sizes_and_strides_.size();</span>
<span id="L728"><span class="lineNum">     728</span>              :     }</span>
<span id="L729"><span class="lineNum">     729</span>              :   }</span>
<span id="L730"><span class="lineNum">     730</span>              : </span>
<span id="L731"><span class="lineNum">     731</span>              :   /**</span>
<span id="L732"><span class="lineNum">     732</span>              :    * Return the offset in number of elements into the storage that this</span>
<span id="L733"><span class="lineNum">     733</span>              :    * tensor points to.  Most tensors have storage_offset() == 0, but,</span>
<span id="L734"><span class="lineNum">     734</span>              :    * for example, an index into a tensor will have a non-zero storage_offset().</span>
<span id="L735"><span class="lineNum">     735</span>              :    *</span>
<span id="L736"><span class="lineNum">     736</span>              :    * WARNING: This is NOT computed in bytes.</span>
<span id="L737"><span class="lineNum">     737</span>              :    */</span>
<span id="L738"><span class="lineNum">     738</span>              :   int64_t storage_offset() const {</span>
<span id="L739"><span class="lineNum">     739</span>              :     // TODO: maybe this should be toggled by strides</span>
<span id="L740"><span class="lineNum">     740</span>              :     if (C10_UNLIKELY(matches_policy(SizesStridesPolicy::CustomSizes))) {</span>
<span id="L741"><span class="lineNum">     741</span>              :       return storage_offset_custom();</span>
<span id="L742"><span class="lineNum">     742</span>              :     }</span>
<span id="L743"><span class="lineNum">     743</span>              :     return storage_offset_;</span>
<span id="L744"><span class="lineNum">     744</span>              :   }</span>
<span id="L745"><span class="lineNum">     745</span>              : </span>
<span id="L746"><span class="lineNum">     746</span>              :   c10::SymInt sym_storage_offset() const {</span>
<span id="L747"><span class="lineNum">     747</span>              :     if (C10_UNLIKELY(matches_policy(SizesStridesPolicy::CustomSizes))) {</span>
<span id="L748"><span class="lineNum">     748</span>              :       return sym_storage_offset_custom();</span>
<span id="L749"><span class="lineNum">     749</span>              :     }</span>
<span id="L750"><span class="lineNum">     750</span>              :     return c10::SymInt(SymInt::UNCHECKED, storage_offset_);</span>
<span id="L751"><span class="lineNum">     751</span>              :   }</span>
<span id="L752"><span class="lineNum">     752</span>              : </span>
<span id="L753"><span class="lineNum">     753</span>              :   int64_t storage_offset_default() const {</span>
<span id="L754"><span class="lineNum">     754</span>              :     TORCH_CHECK(</span>
<span id="L755"><span class="lineNum">     755</span>              :         !has_symbolic_sizes_strides_,</span>
<span id="L756"><span class="lineNum">     756</span>              :         &quot;Cannot call storage_offset() on tensor with symbolic sizes/strides&quot;);</span>
<span id="L757"><span class="lineNum">     757</span>              :     return storage_offset_;</span>
<span id="L758"><span class="lineNum">     758</span>              :   }</span>
<span id="L759"><span class="lineNum">     759</span>              : </span>
<span id="L760"><span class="lineNum">     760</span>              :   c10::SymInt sym_storage_offset_default() const {</span>
<span id="L761"><span class="lineNum">     761</span>              :     if (has_symbolic_sizes_strides_) {</span>
<span id="L762"><span class="lineNum">     762</span>              :       return symbolic_shape_meta().storage_offset_;</span>
<span id="L763"><span class="lineNum">     763</span>              :     } else {</span>
<span id="L764"><span class="lineNum">     764</span>              :       return c10::SymInt(SymInt::UNCHECKED, storage_offset_);</span>
<span id="L765"><span class="lineNum">     765</span>              :     }</span>
<span id="L766"><span class="lineNum">     766</span>              :   }</span>
<span id="L767"><span class="lineNum">     767</span>              : </span>
<span id="L768"><span class="lineNum">     768</span>              :   /**</span>
<span id="L769"><span class="lineNum">     769</span>              :    * Return a reference to the strides of this tensor.  This reference remains</span>
<span id="L770"><span class="lineNum">     770</span>              :    * valid as long as the tensor is live and not restrided.</span>
<span id="L771"><span class="lineNum">     771</span>              :    */</span>
<span id="L772"><span class="lineNum">     772</span> <span class="tlaGNC">          80 :   IntArrayRef strides() const {</span></span>
<span id="L773"><span class="lineNum">     773</span> <span class="tlaGNC">          80 :     if (C10_UNLIKELY(matches_policy(SizesStridesPolicy::CustomStrides))) {</span></span>
<span id="L774"><span class="lineNum">     774</span> <span class="tlaUNC tlaBgUNC">           0 :       return strides_custom();</span></span>
<span id="L775"><span class="lineNum">     775</span>              :     }</span>
<span id="L776"><span class="lineNum">     776</span> <span class="tlaGNC tlaBgGNC">          80 :     return sizes_and_strides_.strides_arrayref();</span></span>
<span id="L777"><span class="lineNum">     777</span>              :   }</span>
<span id="L778"><span class="lineNum">     778</span>              : </span>
<span id="L779"><span class="lineNum">     779</span>              :   c10::SymIntArrayRef sym_strides() const {</span>
<span id="L780"><span class="lineNum">     780</span>              :     if (C10_UNLIKELY(matches_policy(SizesStridesPolicy::CustomStrides))) {</span>
<span id="L781"><span class="lineNum">     781</span>              :       return sym_strides_custom();</span>
<span id="L782"><span class="lineNum">     782</span>              :     }</span>
<span id="L783"><span class="lineNum">     783</span>              :     return c10::fromIntArrayRefKnownNonNegative(strides_default());</span>
<span id="L784"><span class="lineNum">     784</span>              :   }</span>
<span id="L785"><span class="lineNum">     785</span>              : </span>
<span id="L786"><span class="lineNum">     786</span>              :   IntArrayRef strides_default() const {</span>
<span id="L787"><span class="lineNum">     787</span>              :     TORCH_CHECK(</span>
<span id="L788"><span class="lineNum">     788</span>              :         !has_symbolic_sizes_strides_,</span>
<span id="L789"><span class="lineNum">     789</span>              :         &quot;Cannot call strides() on tensor with symbolic sizes/strides&quot;);</span>
<span id="L790"><span class="lineNum">     790</span>              :     return sizes_and_strides_.strides_arrayref();</span>
<span id="L791"><span class="lineNum">     791</span>              :   }</span>
<span id="L792"><span class="lineNum">     792</span>              : </span>
<span id="L793"><span class="lineNum">     793</span>              :   c10::SymIntArrayRef sym_strides_default() const {</span>
<span id="L794"><span class="lineNum">     794</span>              :     if (has_symbolic_sizes_strides_) {</span>
<span id="L795"><span class="lineNum">     795</span>              :       return symbolic_shape_meta().strides_;</span>
<span id="L796"><span class="lineNum">     796</span>              :     } else {</span>
<span id="L797"><span class="lineNum">     797</span>              :       return c10::fromIntArrayRefKnownNonNegative(strides_default());</span>
<span id="L798"><span class="lineNum">     798</span>              :     }</span>
<span id="L799"><span class="lineNum">     799</span>              :   }</span>
<span id="L800"><span class="lineNum">     800</span>              : </span>
<span id="L801"><span class="lineNum">     801</span>              :   /**</span>
<span id="L802"><span class="lineNum">     802</span>              :    * Whether or not a tensor is laid out in contiguous memory.</span>
<span id="L803"><span class="lineNum">     803</span>              :    *</span>
<span id="L804"><span class="lineNum">     804</span>              :    * Tensors with non-trivial strides are not contiguous.  See</span>
<span id="L805"><span class="lineNum">     805</span>              :    * compute_contiguous() for the exact definition of whether or not</span>
<span id="L806"><span class="lineNum">     806</span>              :    * a tensor is contiguous or not.</span>
<span id="L807"><span class="lineNum">     807</span>              :    */</span>
<span id="L808"><span class="lineNum">     808</span>              :   bool is_contiguous(</span>
<span id="L809"><span class="lineNum">     809</span>              :       at::MemoryFormat memory_format = at::MemoryFormat::Contiguous) const {</span>
<span id="L810"><span class="lineNum">     810</span>              :     if (C10_UNLIKELY(matches_policy(SizesStridesPolicy::CustomStrides))) {</span>
<span id="L811"><span class="lineNum">     811</span>              :       return is_contiguous_custom(memory_format);</span>
<span id="L812"><span class="lineNum">     812</span>              :     }</span>
<span id="L813"><span class="lineNum">     813</span>              :     return is_contiguous_default(memory_format);</span>
<span id="L814"><span class="lineNum">     814</span>              :   }</span>
<span id="L815"><span class="lineNum">     815</span>              : </span>
<span id="L816"><span class="lineNum">     816</span>              :   // These are factored into separate functions in case subclasses</span>
<span id="L817"><span class="lineNum">     817</span>              :   // want to use them</span>
<span id="L818"><span class="lineNum">     818</span>              :   bool is_contiguous_default(at::MemoryFormat memory_format) const {</span>
<span id="L819"><span class="lineNum">     819</span>              :     if (has_symbolic_sizes_strides_) {</span>
<span id="L820"><span class="lineNum">     820</span>              :       if (memory_format == at::MemoryFormat::ChannelsLast) {</span>
<span id="L821"><span class="lineNum">     821</span>              :         return symbolic_shape_meta().is_channels_last_contiguous_.guard_bool(</span>
<span id="L822"><span class="lineNum">     822</span>              :             __FILE__, __LINE__);</span>
<span id="L823"><span class="lineNum">     823</span>              :       } else if (memory_format == at::MemoryFormat::ChannelsLast3d) {</span>
<span id="L824"><span class="lineNum">     824</span>              :         return symbolic_shape_meta().is_channels_last_3d_contiguous_.guard_bool(</span>
<span id="L825"><span class="lineNum">     825</span>              :             __FILE__, __LINE__);</span>
<span id="L826"><span class="lineNum">     826</span>              :       }</span>
<span id="L827"><span class="lineNum">     827</span>              :       return symbolic_shape_meta().is_contiguous_.guard_bool(</span>
<span id="L828"><span class="lineNum">     828</span>              :           __FILE__, __LINE__);</span>
<span id="L829"><span class="lineNum">     829</span>              :     }</span>
<span id="L830"><span class="lineNum">     830</span>              : </span>
<span id="L831"><span class="lineNum">     831</span>              :     if (memory_format == at::MemoryFormat::ChannelsLast) {</span>
<span id="L832"><span class="lineNum">     832</span>              :       return is_channels_last_contiguous_;</span>
<span id="L833"><span class="lineNum">     833</span>              :     } else if (memory_format == at::MemoryFormat::ChannelsLast3d) {</span>
<span id="L834"><span class="lineNum">     834</span>              :       return is_channels_last_3d_contiguous_;</span>
<span id="L835"><span class="lineNum">     835</span>              :     }</span>
<span id="L836"><span class="lineNum">     836</span>              :     return is_contiguous_;</span>
<span id="L837"><span class="lineNum">     837</span>              :   }</span>
<span id="L838"><span class="lineNum">     838</span>              : </span>
<span id="L839"><span class="lineNum">     839</span>              :   bool is_strides_like_default(at::MemoryFormat memory_format) const {</span>
<span id="L840"><span class="lineNum">     840</span>              :     if (has_symbolic_sizes_strides_) {</span>
<span id="L841"><span class="lineNum">     841</span>              :       if (memory_format == at::MemoryFormat::ChannelsLast) {</span>
<span id="L842"><span class="lineNum">     842</span>              :         return symbolic_shape_meta().is_channels_last_.guard_bool(</span>
<span id="L843"><span class="lineNum">     843</span>              :             __FILE__, __LINE__);</span>
<span id="L844"><span class="lineNum">     844</span>              :       } else if (memory_format == at::MemoryFormat::ChannelsLast3d) {</span>
<span id="L845"><span class="lineNum">     845</span>              :         return symbolic_shape_meta().is_channels_last_3d_.guard_bool(</span>
<span id="L846"><span class="lineNum">     846</span>              :             __FILE__, __LINE__);</span>
<span id="L847"><span class="lineNum">     847</span>              :       } else {</span>
<span id="L848"><span class="lineNum">     848</span>              :         return false;</span>
<span id="L849"><span class="lineNum">     849</span>              :       }</span>
<span id="L850"><span class="lineNum">     850</span>              :     }</span>
<span id="L851"><span class="lineNum">     851</span>              : </span>
<span id="L852"><span class="lineNum">     852</span>              :     if (memory_format == at::MemoryFormat::ChannelsLast) {</span>
<span id="L853"><span class="lineNum">     853</span>              :       return is_channels_last_;</span>
<span id="L854"><span class="lineNum">     854</span>              :     } else if (memory_format == at::MemoryFormat::ChannelsLast3d) {</span>
<span id="L855"><span class="lineNum">     855</span>              :       return is_channels_last_3d_;</span>
<span id="L856"><span class="lineNum">     856</span>              :     } else {</span>
<span id="L857"><span class="lineNum">     857</span>              :       return false;</span>
<span id="L858"><span class="lineNum">     858</span>              :     }</span>
<span id="L859"><span class="lineNum">     859</span>              :   }</span>
<span id="L860"><span class="lineNum">     860</span>              : </span>
<span id="L861"><span class="lineNum">     861</span>              :   bool is_non_overlapping_and_dense_default() const {</span>
<span id="L862"><span class="lineNum">     862</span>              :     if (has_symbolic_sizes_strides_) {</span>
<span id="L863"><span class="lineNum">     863</span>              :       return symbolic_shape_meta().is_non_overlapping_and_dense_.guard_bool(</span>
<span id="L864"><span class="lineNum">     864</span>              :           __FILE__, __LINE__);</span>
<span id="L865"><span class="lineNum">     865</span>              :     } else {</span>
<span id="L866"><span class="lineNum">     866</span>              :       return is_non_overlapping_and_dense_;</span>
<span id="L867"><span class="lineNum">     867</span>              :     }</span>
<span id="L868"><span class="lineNum">     868</span>              :   }</span>
<span id="L869"><span class="lineNum">     869</span>              : </span>
<span id="L870"><span class="lineNum">     870</span>              :   // NB: these dim accessor functions don't have _default(), as you can use</span>
<span id="L871"><span class="lineNum">     871</span>              :   // sizes_default/strides_default</span>
<span id="L872"><span class="lineNum">     872</span>              :   /**</span>
<span id="L873"><span class="lineNum">     873</span>              :    * Return the size of a tensor at some dimension, wrapping the dimension if</span>
<span id="L874"><span class="lineNum">     874</span>              :    * necessary.</span>
<span id="L875"><span class="lineNum">     875</span>              :    *</span>
<span id="L876"><span class="lineNum">     876</span>              :    * NOTE: if you know wrapping is unnecessary, do sizes()[d] instead; it will</span>
<span id="L877"><span class="lineNum">     877</span>              :    * be faster</span>
<span id="L878"><span class="lineNum">     878</span>              :    */</span>
<span id="L879"><span class="lineNum">     879</span> <span class="tlaGNC">    15310736 :   int64_t size(int64_t d) const {</span></span>
<span id="L880"><span class="lineNum">     880</span> <span class="tlaGNC">    15310736 :     if (C10_UNLIKELY(matches_policy(SizesStridesPolicy::CustomSizes))) {</span></span>
<span id="L881"><span class="lineNum">     881</span> <span class="tlaUNC tlaBgUNC">           0 :       return size_custom(d);</span></span>
<span id="L882"><span class="lineNum">     882</span>              :     }</span>
<span id="L883"><span class="lineNum">     883</span> <span class="tlaGNC tlaBgGNC">    15310736 :     d = maybe_wrap_dim(d, dim(), /*wrap_scalar=*/false);</span></span>
<span id="L884"><span class="lineNum">     884</span> <span class="tlaGNC">    15310736 :     return sizes_and_strides_.size_at_unchecked(d);</span></span>
<span id="L885"><span class="lineNum">     885</span>              :   }</span>
<span id="L886"><span class="lineNum">     886</span>              : </span>
<span id="L887"><span class="lineNum">     887</span>              :   c10::SymInt sym_size(int64_t d) const {</span>
<span id="L888"><span class="lineNum">     888</span>              :     if (C10_UNLIKELY(matches_policy(SizesStridesPolicy::CustomSizes))) {</span>
<span id="L889"><span class="lineNum">     889</span>              :       return sym_size_custom(d);</span>
<span id="L890"><span class="lineNum">     890</span>              :     }</span>
<span id="L891"><span class="lineNum">     891</span>              :     d = maybe_wrap_dim(d, dim(), /*wrap_scalar=*/false);</span>
<span id="L892"><span class="lineNum">     892</span>              :     const auto sizes = this-&gt;sym_sizes();</span>
<span id="L893"><span class="lineNum">     893</span>              :     return sizes[d];</span>
<span id="L894"><span class="lineNum">     894</span>              :   }</span>
<span id="L895"><span class="lineNum">     895</span>              : </span>
<span id="L896"><span class="lineNum">     896</span>              :   /**</span>
<span id="L897"><span class="lineNum">     897</span>              :    * Return the stride of a tensor at some dimension, wrapping the dimension</span>
<span id="L898"><span class="lineNum">     898</span>              :    * if necessary.</span>
<span id="L899"><span class="lineNum">     899</span>              :    *</span>
<span id="L900"><span class="lineNum">     900</span>              :    * NOTE: if you know wrapping is unnecessary, do sizes()[d] instead; it will</span>
<span id="L901"><span class="lineNum">     901</span>              :    * be faster</span>
<span id="L902"><span class="lineNum">     902</span>              :    */</span>
<span id="L903"><span class="lineNum">     903</span>              :   int64_t stride(int64_t d) const {</span>
<span id="L904"><span class="lineNum">     904</span>              :     d = maybe_wrap_dim(d, dim(), false);</span>
<span id="L905"><span class="lineNum">     905</span>              :     if (C10_UNLIKELY(matches_policy(SizesStridesPolicy::CustomStrides))) {</span>
<span id="L906"><span class="lineNum">     906</span>              :       // TODO: provide stride_custom, symmetrically with size_custom.</span>
<span id="L907"><span class="lineNum">     907</span>              :       // There is presently no user for it; only NestedTensor is using</span>
<span id="L908"><span class="lineNum">     908</span>              :       // size_custom overrideability</span>
<span id="L909"><span class="lineNum">     909</span>              :       return strides_custom()[d]; // unchecked (maybe_wrap_dim enforces bounds)</span>
<span id="L910"><span class="lineNum">     910</span>              :     }</span>
<span id="L911"><span class="lineNum">     911</span>              :     // Intentionally don't call default, which also handles symbolic</span>
<span id="L912"><span class="lineNum">     912</span>              :     return sizes_and_strides_.stride_at_unchecked(d);</span>
<span id="L913"><span class="lineNum">     913</span>              :   }</span>
<span id="L914"><span class="lineNum">     914</span>              : </span>
<span id="L915"><span class="lineNum">     915</span>              :   enum class SizesStridesPolicy : uint8_t {</span>
<span id="L916"><span class="lineNum">     916</span>              :     // Default behavior, e.g., dense tensor.</span>
<span id="L917"><span class="lineNum">     917</span>              :     //</span>
<span id="L918"><span class="lineNum">     918</span>              :     // Can override: nothing</span>
<span id="L919"><span class="lineNum">     919</span>              :     Default = 0,</span>
<span id="L920"><span class="lineNum">     920</span>              :     // Customizable strides behavior, e.g., sparse tensor,</span>
<span id="L921"><span class="lineNum">     921</span>              :     // mkldnn tensor.</span>
<span id="L922"><span class="lineNum">     922</span>              :     //</span>
<span id="L923"><span class="lineNum">     923</span>              :     // Can override: strides(), is_contiguous()</span>
<span id="L924"><span class="lineNum">     924</span>              :     CustomStrides = 1,</span>
<span id="L925"><span class="lineNum">     925</span>              :     // Customizable sizes behavior, e.g., nested tensor</span>
<span id="L926"><span class="lineNum">     926</span>              :     //</span>
<span id="L927"><span class="lineNum">     927</span>              :     // Can override: strides(), is_contiguous(), sizes(), dim(), numel()</span>
<span id="L928"><span class="lineNum">     928</span>              :     CustomSizes = 2</span>
<span id="L929"><span class="lineNum">     929</span>              :   };</span>
<span id="L930"><span class="lineNum">     930</span>              : </span>
<span id="L931"><span class="lineNum">     931</span>              :  protected:</span>
<span id="L932"><span class="lineNum">     932</span> <span class="tlaGNC">    30717910 :   inline bool matches_policy(SizesStridesPolicy policy) const {</span></span>
<span id="L933"><span class="lineNum">     933</span> <span class="tlaGNC">    30717910 :     return sizes_strides_policy_ &gt;= static_cast&lt;uint8_t&gt;(policy);</span></span>
<span id="L934"><span class="lineNum">     934</span>              :   }</span>
<span id="L935"><span class="lineNum">     935</span>              : </span>
<span id="L936"><span class="lineNum">     936</span>              :   inline bool matches_custom(SizesStridesPolicy policy) const {</span>
<span id="L937"><span class="lineNum">     937</span>              :     return custom_sizes_strides_ &gt;= static_cast&lt;uint8_t&gt;(policy);</span>
<span id="L938"><span class="lineNum">     938</span>              :   }</span>
<span id="L939"><span class="lineNum">     939</span>              : </span>
<span id="L940"><span class="lineNum">     940</span>              :   inline bool matches_python_custom(SizesStridesPolicy policy) const {</span>
<span id="L941"><span class="lineNum">     941</span>              :     auto r = python_custom_sizes_strides_ &gt;= static_cast&lt;uint8_t&gt;(policy);</span>
<span id="L942"><span class="lineNum">     942</span>              :     if (r) {</span>
<span id="L943"><span class="lineNum">     943</span>              :       TORCH_INTERNAL_ASSERT(is_python_dispatch())</span>
<span id="L944"><span class="lineNum">     944</span>              :     }</span>
<span id="L945"><span class="lineNum">     945</span>              :     return r;</span>
<span id="L946"><span class="lineNum">     946</span>              :   }</span>
<span id="L947"><span class="lineNum">     947</span>              : </span>
<span id="L948"><span class="lineNum">     948</span>              :   /**</span>
<span id="L949"><span class="lineNum">     949</span>              :    * Customization points for the functions above.  sizes_strides_policy_</span>
<span id="L950"><span class="lineNum">     950</span>              :    * must be set to enable these.</span>
<span id="L951"><span class="lineNum">     951</span>              :    *</span>
<span id="L952"><span class="lineNum">     952</span>              :    * NB: dim is overrideable separately from sizes because it is possible</span>
<span id="L953"><span class="lineNum">     953</span>              :    * for a tensor to have rank, but not well defined sizes.</span>
<span id="L954"><span class="lineNum">     954</span>              :    */</span>
<span id="L955"><span class="lineNum">     955</span>              :   // sizes_strides_policy_ &gt;= CustomStrides</span>
<span id="L956"><span class="lineNum">     956</span>              :   virtual bool is_contiguous_custom(at::MemoryFormat memory_format) const;</span>
<span id="L957"><span class="lineNum">     957</span>              :   virtual bool is_strides_like_custom(at::MemoryFormat memory_format) const;</span>
<span id="L958"><span class="lineNum">     958</span>              :   virtual bool is_non_overlapping_and_dense_custom() const;</span>
<span id="L959"><span class="lineNum">     959</span>              :   // sizes_strides_policy_ &gt;= CustomSizes</span>
<span id="L960"><span class="lineNum">     960</span>              :   // Currently this method only exists to be overwritten by subclasses such as</span>
<span id="L961"><span class="lineNum">     961</span>              :   // NestedTensorImpl.</span>
<span id="L962"><span class="lineNum">     962</span>              :   virtual int64_t size_custom(int64_t d) const {</span>
<span id="L963"><span class="lineNum">     963</span>              :     // TODO: We could add support to Python dispatch here.</span>
<span id="L964"><span class="lineNum">     964</span>              :     // TODO: We could call into aten::size.int instead of</span>
<span id="L965"><span class="lineNum">     965</span>              :     // sizes_custom()[d] and enable use of the dispatcher.</span>
<span id="L966"><span class="lineNum">     966</span>              :     d = maybe_wrap_dim(d, dim(), /*wrap_scalar=*/false);</span>
<span id="L967"><span class="lineNum">     967</span>              :     return sizes_custom()[d]; // unchecked (maybe_wrap_dim enforces bounds)</span>
<span id="L968"><span class="lineNum">     968</span>              :   }</span>
<span id="L969"><span class="lineNum">     969</span>              : </span>
<span id="L970"><span class="lineNum">     970</span>              :   virtual c10::SymInt sym_size_custom(int64_t d) const {</span>
<span id="L971"><span class="lineNum">     971</span>              :     // TODO: We could add support to Python dispatch here.</span>
<span id="L972"><span class="lineNum">     972</span>              :     // TODO: We could call into aten::size.int instead of</span>
<span id="L973"><span class="lineNum">     973</span>              :     // sym_sizes_custom()[d] and enable use of the dispatcher.</span>
<span id="L974"><span class="lineNum">     974</span>              :     d = maybe_wrap_dim(d, dim(), /*wrap_scalar=*/false);</span>
<span id="L975"><span class="lineNum">     975</span>              :     return sym_sizes_custom()[d]; // unchecked (maybe_wrap_dim enforces bounds)</span>
<span id="L976"><span class="lineNum">     976</span>              :   }</span>
<span id="L977"><span class="lineNum">     977</span>              : </span>
<span id="L978"><span class="lineNum">     978</span>              :   virtual IntArrayRef sizes_custom() const;</span>
<span id="L979"><span class="lineNum">     979</span>              :   virtual IntArrayRef strides_custom() const;</span>
<span id="L980"><span class="lineNum">     980</span>              :   virtual int64_t numel_custom() const;</span>
<span id="L981"><span class="lineNum">     981</span>              :   virtual int64_t storage_offset_custom() const;</span>
<span id="L982"><span class="lineNum">     982</span>              :   virtual int64_t dim_custom() const;</span>
<span id="L983"><span class="lineNum">     983</span>              :   virtual Device device_custom() const;</span>
<span id="L984"><span class="lineNum">     984</span>              :   virtual Layout layout_custom() const;</span>
<span id="L985"><span class="lineNum">     985</span>              : </span>
<span id="L986"><span class="lineNum">     986</span>              :   virtual c10::SymIntArrayRef sym_sizes_custom() const;</span>
<span id="L987"><span class="lineNum">     987</span>              :   virtual c10::SymIntArrayRef sym_strides_custom() const;</span>
<span id="L988"><span class="lineNum">     988</span>              :   virtual c10::SymInt sym_numel_custom() const;</span>
<span id="L989"><span class="lineNum">     989</span>              :   virtual c10::SymInt sym_storage_offset_custom() const;</span>
<span id="L990"><span class="lineNum">     990</span>              : </span>
<span id="L991"><span class="lineNum">     991</span>              :  public:</span>
<span id="L992"><span class="lineNum">     992</span>              :   /**</span>
<span id="L993"><span class="lineNum">     993</span>              :    * True if this tensor has storage. See storage() for details.</span>
<span id="L994"><span class="lineNum">     994</span>              :    */</span>
<span id="L995"><span class="lineNum">     995</span>              : #ifdef DEBUG</span>
<span id="L996"><span class="lineNum">     996</span>              :   // Allow subclasses to check that their storage_ is never getting set in debug</span>
<span id="L997"><span class="lineNum">     997</span>              :   // builds.</span>
<span id="L998"><span class="lineNum">     998</span>              :   virtual</span>
<span id="L999"><span class="lineNum">     999</span>              : #else</span>
<span id="L1000"><span class="lineNum">    1000</span>              :   TENSORIMPL_MAYBE_VIRTUAL</span>
<span id="L1001"><span class="lineNum">    1001</span>              : #endif</span>
<span id="L1002"><span class="lineNum">    1002</span>              :       bool</span>
<span id="L1003"><span class="lineNum">    1003</span>              :       has_storage() const</span>
<span id="L1004"><span class="lineNum">    1004</span>              :   // NOTE: we devirtualize this because it arguably shouldn't be an</span>
<span id="L1005"><span class="lineNum">    1005</span>              :   // error just to ask subclasses if they have storage.</span>
<span id="L1006"><span class="lineNum">    1006</span>              :   // This used to throw for most subclasses, but OpaqueTensorImpl</span>
<span id="L1007"><span class="lineNum">    1007</span>              :   // wanted it to successfully return false, so we went ahead and made</span>
<span id="L1008"><span class="lineNum">    1008</span>              :   // it a non-error.</span>
<span id="L1009"><span class="lineNum">    1009</span>              : #ifdef C10_DISABLE_TENSORIMPL_EXTENSIBILITY</span>
<span id="L1010"><span class="lineNum">    1010</span>              :   {</span>
<span id="L1011"><span class="lineNum">    1011</span>              :     return storage_;</span>
<span id="L1012"><span class="lineNum">    1012</span>              :   }</span>
<span id="L1013"><span class="lineNum">    1013</span>              : #else</span>
<span id="L1014"><span class="lineNum">    1014</span>              :       ;</span>
<span id="L1015"><span class="lineNum">    1015</span>              : #endif</span>
<span id="L1016"><span class="lineNum">    1016</span>              : </span>
<span id="L1017"><span class="lineNum">    1017</span>              :   /**</span>
<span id="L1018"><span class="lineNum">    1018</span>              :    * Return the underlying storage of a Tensor.  Multiple tensors may share</span>
<span id="L1019"><span class="lineNum">    1019</span>              :    * a single storage.  A Storage is an impoverished, Tensor-like class</span>
<span id="L1020"><span class="lineNum">    1020</span>              :    * which supports far less operations than Tensor.</span>
<span id="L1021"><span class="lineNum">    1021</span>              :    *</span>
<span id="L1022"><span class="lineNum">    1022</span>              :    * Avoid using this method if possible; try to use only Tensor APIs to perform</span>
<span id="L1023"><span class="lineNum">    1023</span>              :    * operations.</span>
<span id="L1024"><span class="lineNum">    1024</span>              :    */</span>
<span id="L1025"><span class="lineNum">    1025</span>              :   TENSORIMPL_MAYBE_VIRTUAL const Storage&amp; storage() const {</span>
<span id="L1026"><span class="lineNum">    1026</span>              :     if (C10_UNLIKELY(storage_access_should_throw_)) {</span>
<span id="L1027"><span class="lineNum">    1027</span>              :       throw_storage_access_error();</span>
<span id="L1028"><span class="lineNum">    1028</span>              :     }</span>
<span id="L1029"><span class="lineNum">    1029</span>              :     return storage_;</span>
<span id="L1030"><span class="lineNum">    1030</span>              :   }</span>
<span id="L1031"><span class="lineNum">    1031</span>              : </span>
<span id="L1032"><span class="lineNum">    1032</span>              :   /**</span>
<span id="L1033"><span class="lineNum">    1033</span>              :    * Return the underlying storage, unsafely assuming this is a basic strided</span>
<span id="L1034"><span class="lineNum">    1034</span>              :    * tensor. In cases where `storage` access would throw, this returns a</span>
<span id="L1035"><span class="lineNum">    1035</span>              :    * default-constructed Storage.</span>
<span id="L1036"><span class="lineNum">    1036</span>              :    */</span>
<span id="L1037"><span class="lineNum">    1037</span>              :   inline const Storage&amp; unsafe_storage() const {</span>
<span id="L1038"><span class="lineNum">    1038</span>              :     return storage_;</span>
<span id="L1039"><span class="lineNum">    1039</span>              :   }</span>
<span id="L1040"><span class="lineNum">    1040</span>              : </span>
<span id="L1041"><span class="lineNum">    1041</span> <span class="tlaGNC">       40076 :   bool unique_version() const {</span></span>
<span id="L1042"><span class="lineNum">    1042</span> <span class="tlaGNC">       40076 :     return version_counter_.unique();</span></span>
<span id="L1043"><span class="lineNum">    1043</span>              :   }</span>
<span id="L1044"><span class="lineNum">    1044</span>              : </span>
<span id="L1045"><span class="lineNum">    1045</span>              :  protected:</span>
<span id="L1046"><span class="lineNum">    1046</span>              :   virtual Layout layout_impl() const {</span>
<span id="L1047"><span class="lineNum">    1047</span>              :     TORCH_CHECK(</span>
<span id="L1048"><span class="lineNum">    1048</span>              :         false, &quot;layout_impl is only implemented for TensorImpl subclasses.&quot;);</span>
<span id="L1049"><span class="lineNum">    1049</span>              :   }</span>
<span id="L1050"><span class="lineNum">    1050</span>              : </span>
<span id="L1051"><span class="lineNum">    1051</span>              :  public:</span>
<span id="L1052"><span class="lineNum">    1052</span>              :   // Whether a tensor is sparse COO or not.</span>
<span id="L1053"><span class="lineNum">    1053</span>              :   bool is_sparse() const {</span>
<span id="L1054"><span class="lineNum">    1054</span>              :     // NB: This method is not virtual and avoid dispatches for performance</span>
<span id="L1055"><span class="lineNum">    1055</span>              :     // reasons.</span>
<span id="L1056"><span class="lineNum">    1056</span>              :     return key_set_.has_all(c10::sparse_ks);</span>
<span id="L1057"><span class="lineNum">    1057</span>              :   }</span>
<span id="L1058"><span class="lineNum">    1058</span>              : </span>
<span id="L1059"><span class="lineNum">    1059</span>              :   // Whether a tensor is sparse CSR or not.</span>
<span id="L1060"><span class="lineNum">    1060</span>              :   bool is_sparse_csr() const {</span>
<span id="L1061"><span class="lineNum">    1061</span>              :     return layout() == kSparseCsr;</span>
<span id="L1062"><span class="lineNum">    1062</span>              :   }</span>
<span id="L1063"><span class="lineNum">    1063</span>              : </span>
<span id="L1064"><span class="lineNum">    1064</span>              :   bool is_quantized() const {</span>
<span id="L1065"><span class="lineNum">    1065</span>              :     // NB: This method is not virtual and avoid dispatches for performance</span>
<span id="L1066"><span class="lineNum">    1066</span>              :     // reasons.</span>
<span id="L1067"><span class="lineNum">    1067</span>              :     constexpr auto quantized_ks = DispatchKeySet(DispatchKey::Quantized);</span>
<span id="L1068"><span class="lineNum">    1068</span>              :     return key_set_.has_all(quantized_ks);</span>
<span id="L1069"><span class="lineNum">    1069</span>              :   }</span>
<span id="L1070"><span class="lineNum">    1070</span>              : </span>
<span id="L1071"><span class="lineNum">    1071</span>              :   bool is_meta() const {</span>
<span id="L1072"><span class="lineNum">    1072</span>              :     // NB: This method is not virtual and avoid dispatches for performance</span>
<span id="L1073"><span class="lineNum">    1073</span>              :     // reasons.</span>
<span id="L1074"><span class="lineNum">    1074</span>              :     if (C10_UNLIKELY(device_policy_)) {</span>
<span id="L1075"><span class="lineNum">    1075</span>              :       return device_custom().is_meta();</span>
<span id="L1076"><span class="lineNum">    1076</span>              :     }</span>
<span id="L1077"><span class="lineNum">    1077</span>              :     return device_opt_.has_value() &amp;&amp; device_opt_-&gt;type() == kMeta;</span>
<span id="L1078"><span class="lineNum">    1078</span>              :   }</span>
<span id="L1079"><span class="lineNum">    1079</span>              : </span>
<span id="L1080"><span class="lineNum">    1080</span>              :   bool is_cpu() const {</span>
<span id="L1081"><span class="lineNum">    1081</span>              :     // NB: This method is not virtual and avoid dispatches for performance</span>
<span id="L1082"><span class="lineNum">    1082</span>              :     // reasons.</span>
<span id="L1083"><span class="lineNum">    1083</span>              :     if (C10_UNLIKELY(device_policy_)) {</span>
<span id="L1084"><span class="lineNum">    1084</span>              :       return device_custom().is_cpu();</span>
<span id="L1085"><span class="lineNum">    1085</span>              :     }</span>
<span id="L1086"><span class="lineNum">    1086</span>              :     // Note: we cannot rely on dispatch keys to determine the device type</span>
<span id="L1087"><span class="lineNum">    1087</span>              :     // of a tensor, because &quot;wrapper&quot; tensors (like FunctionalTensorWrapper)</span>
<span id="L1088"><span class="lineNum">    1088</span>              :     // don't include backend dispatch keys.</span>
<span id="L1089"><span class="lineNum">    1089</span>              :     return device_opt_.has_value() &amp;&amp; device_opt_-&gt;type() == kCPU;</span>
<span id="L1090"><span class="lineNum">    1090</span>              :   }</span>
<span id="L1091"><span class="lineNum">    1091</span>              : </span>
<span id="L1092"><span class="lineNum">    1092</span>              :   bool is_cuda() const {</span>
<span id="L1093"><span class="lineNum">    1093</span>              :     // NB: This method is not virtual and avoid dispatches for performance</span>
<span id="L1094"><span class="lineNum">    1094</span>              :     // reasons.</span>
<span id="L1095"><span class="lineNum">    1095</span>              :     if (C10_UNLIKELY(device_policy_)) {</span>
<span id="L1096"><span class="lineNum">    1096</span>              :       return device_custom().is_cuda();</span>
<span id="L1097"><span class="lineNum">    1097</span>              :     }</span>
<span id="L1098"><span class="lineNum">    1098</span>              :     return device_opt_.has_value() &amp;&amp; device_opt_-&gt;type() == kCUDA;</span>
<span id="L1099"><span class="lineNum">    1099</span>              :   }</span>
<span id="L1100"><span class="lineNum">    1100</span>              : </span>
<span id="L1101"><span class="lineNum">    1101</span>              :   bool is_xpu() const {</span>
<span id="L1102"><span class="lineNum">    1102</span>              :     // NB: This method is not virtual and avoid dispatches for performance</span>
<span id="L1103"><span class="lineNum">    1103</span>              :     // reasons.</span>
<span id="L1104"><span class="lineNum">    1104</span>              :     if (C10_UNLIKELY(device_policy_)) {</span>
<span id="L1105"><span class="lineNum">    1105</span>              :       return device_custom().is_xpu();</span>
<span id="L1106"><span class="lineNum">    1106</span>              :     }</span>
<span id="L1107"><span class="lineNum">    1107</span>              :     return device_opt_.has_value() &amp;&amp; device_opt_-&gt;type() == kXPU;</span>
<span id="L1108"><span class="lineNum">    1108</span>              :   }</span>
<span id="L1109"><span class="lineNum">    1109</span>              : </span>
<span id="L1110"><span class="lineNum">    1110</span>              :   bool is_ipu() const {</span>
<span id="L1111"><span class="lineNum">    1111</span>              :     if (C10_UNLIKELY(device_policy_)) {</span>
<span id="L1112"><span class="lineNum">    1112</span>              :       return device_custom().is_ipu();</span>
<span id="L1113"><span class="lineNum">    1113</span>              :     }</span>
<span id="L1114"><span class="lineNum">    1114</span>              :     return device_opt_.has_value() &amp;&amp; device_opt_-&gt;type() == kIPU;</span>
<span id="L1115"><span class="lineNum">    1115</span>              :   }</span>
<span id="L1116"><span class="lineNum">    1116</span>              : </span>
<span id="L1117"><span class="lineNum">    1117</span>              :   bool is_xla() const {</span>
<span id="L1118"><span class="lineNum">    1118</span>              :     if (C10_UNLIKELY(device_policy_)) {</span>
<span id="L1119"><span class="lineNum">    1119</span>              :       return device_custom().is_xla();</span>
<span id="L1120"><span class="lineNum">    1120</span>              :     }</span>
<span id="L1121"><span class="lineNum">    1121</span>              :     return device_opt_.has_value() &amp;&amp; device_opt_-&gt;type() == kXLA;</span>
<span id="L1122"><span class="lineNum">    1122</span>              :   }</span>
<span id="L1123"><span class="lineNum">    1123</span>              : </span>
<span id="L1124"><span class="lineNum">    1124</span>              :   bool is_mtia() const {</span>
<span id="L1125"><span class="lineNum">    1125</span>              :     if (C10_UNLIKELY(device_policy_)) {</span>
<span id="L1126"><span class="lineNum">    1126</span>              :       return device_custom().is_mtia();</span>
<span id="L1127"><span class="lineNum">    1127</span>              :     }</span>
<span id="L1128"><span class="lineNum">    1128</span>              :     return device_opt_.has_value() &amp;&amp; device_opt_-&gt;type() == kMTIA;</span>
<span id="L1129"><span class="lineNum">    1129</span>              :   }</span>
<span id="L1130"><span class="lineNum">    1130</span>              : </span>
<span id="L1131"><span class="lineNum">    1131</span>              :   bool is_hpu() const {</span>
<span id="L1132"><span class="lineNum">    1132</span>              :     if (C10_UNLIKELY(device_policy_)) {</span>
<span id="L1133"><span class="lineNum">    1133</span>              :       return device_custom().is_hpu();</span>
<span id="L1134"><span class="lineNum">    1134</span>              :     }</span>
<span id="L1135"><span class="lineNum">    1135</span>              :     return device_opt_.has_value() &amp;&amp; device_opt_-&gt;type() == kHPU;</span>
<span id="L1136"><span class="lineNum">    1136</span>              :   }</span>
<span id="L1137"><span class="lineNum">    1137</span>              : </span>
<span id="L1138"><span class="lineNum">    1138</span>              :   bool is_lazy() const {</span>
<span id="L1139"><span class="lineNum">    1139</span>              :     if (C10_UNLIKELY(device_policy_)) {</span>
<span id="L1140"><span class="lineNum">    1140</span>              :       return device_custom().is_lazy();</span>
<span id="L1141"><span class="lineNum">    1141</span>              :     }</span>
<span id="L1142"><span class="lineNum">    1142</span>              :     return device_opt_.has_value() &amp;&amp; device_opt_-&gt;type() == kLazy;</span>
<span id="L1143"><span class="lineNum">    1143</span>              :   }</span>
<span id="L1144"><span class="lineNum">    1144</span>              : </span>
<span id="L1145"><span class="lineNum">    1145</span>              :   bool is_hip() const {</span>
<span id="L1146"><span class="lineNum">    1146</span>              :     // NB: This method is not virtual and avoid dispatches for performance</span>
<span id="L1147"><span class="lineNum">    1147</span>              :     // reasons.</span>
<span id="L1148"><span class="lineNum">    1148</span>              :     if (C10_UNLIKELY(device_policy_)) {</span>
<span id="L1149"><span class="lineNum">    1149</span>              :       return device_custom().is_hip();</span>
<span id="L1150"><span class="lineNum">    1150</span>              :     }</span>
<span id="L1151"><span class="lineNum">    1151</span>              :     return device_opt_.has_value() &amp;&amp; device_opt_-&gt;type() == kHIP;</span>
<span id="L1152"><span class="lineNum">    1152</span>              :   }</span>
<span id="L1153"><span class="lineNum">    1153</span>              : </span>
<span id="L1154"><span class="lineNum">    1154</span>              :   bool is_ve() const {</span>
<span id="L1155"><span class="lineNum">    1155</span>              :     // NB: This method is not virtual and avoid dispatches for performance</span>
<span id="L1156"><span class="lineNum">    1156</span>              :     // reasons.</span>
<span id="L1157"><span class="lineNum">    1157</span>              :     if (C10_UNLIKELY(device_policy_)) {</span>
<span id="L1158"><span class="lineNum">    1158</span>              :       return device_custom().is_ve();</span>
<span id="L1159"><span class="lineNum">    1159</span>              :     }</span>
<span id="L1160"><span class="lineNum">    1160</span>              :     return device_opt_.has_value() &amp;&amp; device_opt_-&gt;type() == kVE;</span>
<span id="L1161"><span class="lineNum">    1161</span>              :   }</span>
<span id="L1162"><span class="lineNum">    1162</span>              : </span>
<span id="L1163"><span class="lineNum">    1163</span>              :   bool is_mkldnn() const {</span>
<span id="L1164"><span class="lineNum">    1164</span>              :     return key_set_.has_all(c10::mkldnn_ks);</span>
<span id="L1165"><span class="lineNum">    1165</span>              :   }</span>
<span id="L1166"><span class="lineNum">    1166</span>              : </span>
<span id="L1167"><span class="lineNum">    1167</span>              :   bool is_vulkan() const {</span>
<span id="L1168"><span class="lineNum">    1168</span>              :     if (C10_UNLIKELY(device_policy_)) {</span>
<span id="L1169"><span class="lineNum">    1169</span>              :       return device_custom().is_vulkan();</span>
<span id="L1170"><span class="lineNum">    1170</span>              :     }</span>
<span id="L1171"><span class="lineNum">    1171</span>              :     return device_opt_.has_value() &amp;&amp; device_opt_-&gt;type() == kVulkan;</span>
<span id="L1172"><span class="lineNum">    1172</span>              :   }</span>
<span id="L1173"><span class="lineNum">    1173</span>              : </span>
<span id="L1174"><span class="lineNum">    1174</span>              :   bool is_metal() const {</span>
<span id="L1175"><span class="lineNum">    1175</span>              :     if (C10_UNLIKELY(device_policy_)) {</span>
<span id="L1176"><span class="lineNum">    1176</span>              :       return device_custom().is_metal();</span>
<span id="L1177"><span class="lineNum">    1177</span>              :     }</span>
<span id="L1178"><span class="lineNum">    1178</span>              :     return device_opt_.has_value() &amp;&amp; device_opt_-&gt;type() == kMetal;</span>
<span id="L1179"><span class="lineNum">    1179</span>              :   }</span>
<span id="L1180"><span class="lineNum">    1180</span>              : </span>
<span id="L1181"><span class="lineNum">    1181</span>              :   bool is_mps() const {</span>
<span id="L1182"><span class="lineNum">    1182</span>              :     if (C10_UNLIKELY(device_policy_)) {</span>
<span id="L1183"><span class="lineNum">    1183</span>              :       return device_custom().is_mps();</span>
<span id="L1184"><span class="lineNum">    1184</span>              :     }</span>
<span id="L1185"><span class="lineNum">    1185</span>              :     return device_opt_.has_value() &amp;&amp; device_opt_-&gt;type() == kMPS;</span>
<span id="L1186"><span class="lineNum">    1186</span>              :   }</span>
<span id="L1187"><span class="lineNum">    1187</span>              : </span>
<span id="L1188"><span class="lineNum">    1188</span>              :   bool is_ort() const {</span>
<span id="L1189"><span class="lineNum">    1189</span>              :     if (C10_UNLIKELY(device_policy_)) {</span>
<span id="L1190"><span class="lineNum">    1190</span>              :       return device_custom().is_ort();</span>
<span id="L1191"><span class="lineNum">    1191</span>              :     }</span>
<span id="L1192"><span class="lineNum">    1192</span>              :     return device_opt_.has_value() &amp;&amp; device_opt_-&gt;type() == kORT;</span>
<span id="L1193"><span class="lineNum">    1193</span>              :   }</span>
<span id="L1194"><span class="lineNum">    1194</span>              : </span>
<span id="L1195"><span class="lineNum">    1195</span>              :   bool is_nested() const {</span>
<span id="L1196"><span class="lineNum">    1196</span>              :     return key_set_.has(DispatchKey::NestedTensor);</span>
<span id="L1197"><span class="lineNum">    1197</span>              :   }</span>
<span id="L1198"><span class="lineNum">    1198</span>              : </span>
<span id="L1199"><span class="lineNum">    1199</span>              :   // TODO: remove this once we don't automatically enabled Autograd dispatch</span>
<span id="L1200"><span class="lineNum">    1200</span>              :   // keys</span>
<span id="L1201"><span class="lineNum">    1201</span>              :   //       in TensorImpl constructor.</span>
<span id="L1202"><span class="lineNum">    1202</span>              :   // DON'T USE THIS API!! It's only created for testing purpose in</span>
<span id="L1203"><span class="lineNum">    1203</span>              :   // file aten/src/ATen/core/boxing/impl/test_helpers.h</span>
<span id="L1204"><span class="lineNum">    1204</span>              :   void remove_autograd_key() {</span>
<span id="L1205"><span class="lineNum">    1205</span>              :     key_set_ = key_set_ - autograd_dispatch_keyset;</span>
<span id="L1206"><span class="lineNum">    1206</span>              :   }</span>
<span id="L1207"><span class="lineNum">    1207</span>              : </span>
<span id="L1208"><span class="lineNum">    1208</span>              :   // Inference tensor doesn't have autograd or ADInplaceOrView key.</span>
<span id="L1209"><span class="lineNum">    1209</span>              :   // Invariant:</span>
<span id="L1210"><span class="lineNum">    1210</span>              :   //   Inference tensor has version_counter_.enabled() == false</span>
<span id="L1211"><span class="lineNum">    1211</span>              :   bool is_inference() {</span>
<span id="L1212"><span class="lineNum">    1212</span>              :     bool no_ADInplaceOrView = !key_set_.has_any(c10::inplace_or_view_ks);</span>
<span id="L1213"><span class="lineNum">    1213</span>              :     bool no_Autograd = !key_set_.has_any(c10::autograd_dispatch_keyset);</span>
<span id="L1214"><span class="lineNum">    1214</span>              :     TORCH_INTERNAL_ASSERT_DEBUG_ONLY(</span>
<span id="L1215"><span class="lineNum">    1215</span>              :         no_ADInplaceOrView == no_Autograd,</span>
<span id="L1216"><span class="lineNum">    1216</span>              :         &quot;ADInplaceOrView and Autograd keys must be on/off at the same time.&quot;);</span>
<span id="L1217"><span class="lineNum">    1217</span>              :     return no_ADInplaceOrView &amp;&amp; no_Autograd;</span>
<span id="L1218"><span class="lineNum">    1218</span>              :   }</span>
<span id="L1219"><span class="lineNum">    1219</span>              : </span>
<span id="L1220"><span class="lineNum">    1220</span>              :   int64_t get_device() const {</span>
<span id="L1221"><span class="lineNum">    1221</span>              :     if (C10_UNLIKELY(device_policy_)) {</span>
<span id="L1222"><span class="lineNum">    1222</span>              :       return device_custom().index();</span>
<span id="L1223"><span class="lineNum">    1223</span>              :     }</span>
<span id="L1224"><span class="lineNum">    1224</span>              :     return device_default().index();</span>
<span id="L1225"><span class="lineNum">    1225</span>              :   }</span>
<span id="L1226"><span class="lineNum">    1226</span>              : </span>
<span id="L1227"><span class="lineNum">    1227</span>              :   Device device() const {</span>
<span id="L1228"><span class="lineNum">    1228</span>              :     if (C10_UNLIKELY(device_policy_)) {</span>
<span id="L1229"><span class="lineNum">    1229</span>              :       return device_custom();</span>
<span id="L1230"><span class="lineNum">    1230</span>              :     }</span>
<span id="L1231"><span class="lineNum">    1231</span>              :     return device_default();</span>
<span id="L1232"><span class="lineNum">    1232</span>              :   }</span>
<span id="L1233"><span class="lineNum">    1233</span>              : </span>
<span id="L1234"><span class="lineNum">    1234</span>              :  protected:</span>
<span id="L1235"><span class="lineNum">    1235</span>              :   c10::Device device_default() const {</span>
<span id="L1236"><span class="lineNum">    1236</span>              :     TORCH_CHECK(device_opt_.has_value(), &quot;tensor does not have a device&quot;);</span>
<span id="L1237"><span class="lineNum">    1237</span>              :     // See NOTE [c10::optional operator usage in CUDA]</span>
<span id="L1238"><span class="lineNum">    1238</span>              :     return *device_opt_;</span>
<span id="L1239"><span class="lineNum">    1239</span>              :   }</span>
<span id="L1240"><span class="lineNum">    1240</span>              : </span>
<span id="L1241"><span class="lineNum">    1241</span>              :  public:</span>
<span id="L1242"><span class="lineNum">    1242</span>              :   Layout layout() const {</span>
<span id="L1243"><span class="lineNum">    1243</span>              :     if (C10_UNLIKELY(layout_policy_)) {</span>
<span id="L1244"><span class="lineNum">    1244</span>              :       return layout_custom();</span>
<span id="L1245"><span class="lineNum">    1245</span>              :     }</span>
<span id="L1246"><span class="lineNum">    1246</span>              : </span>
<span id="L1247"><span class="lineNum">    1247</span>              :     // NB: This method is not virtual and avoid dispatches for perf.</span>
<span id="L1248"><span class="lineNum">    1248</span>              :     // strided is also the most common layout type, so we check for</span>
<span id="L1249"><span class="lineNum">    1249</span>              :     // strided case first.</span>
<span id="L1250"><span class="lineNum">    1250</span>              :     // This keyset must also be kept in sync with the logic in</span>
<span id="L1251"><span class="lineNum">    1251</span>              :     // is_sparse() / is_sparse_csr() / is_mkldnn()</span>
<span id="L1252"><span class="lineNum">    1252</span>              :     constexpr auto sparse_and_sparsecsr_and_mkldnn_ks =</span>
<span id="L1253"><span class="lineNum">    1253</span>              :         c10::sparse_ks | c10::sparse_csr_ks | c10::mkldnn_ks;</span>
<span id="L1254"><span class="lineNum">    1254</span>              :     if (!key_set_.has_any(sparse_and_sparsecsr_and_mkldnn_ks)) {</span>
<span id="L1255"><span class="lineNum">    1255</span>              :       return kStrided;</span>
<span id="L1256"><span class="lineNum">    1256</span>              :     } else if (is_sparse()) {</span>
<span id="L1257"><span class="lineNum">    1257</span>              :       return kSparse;</span>
<span id="L1258"><span class="lineNum">    1258</span>              :     } else if (key_set_.has_any(c10::sparse_csr_ks)) {</span>
<span id="L1259"><span class="lineNum">    1259</span>              :       // Typically, the tensor dispatch keys define the tensor layout</span>
<span id="L1260"><span class="lineNum">    1260</span>              :       // uniquely. This allows using non-virtual layout method for</span>
<span id="L1261"><span class="lineNum">    1261</span>              :       // better performance. However, when tensor's layout depends,</span>
<span id="L1262"><span class="lineNum">    1262</span>              :       // say, on tensor attributes, one must use this execution path</span>
<span id="L1263"><span class="lineNum">    1263</span>              :       // where the corresponding tensor impl class overwrites virtual</span>
<span id="L1264"><span class="lineNum">    1264</span>              :       // layout_impl() method.</span>
<span id="L1265"><span class="lineNum">    1265</span>              :       //</span>
<span id="L1266"><span class="lineNum">    1266</span>              :       // TODO: implement layout() as native function/method so that</span>
<span id="L1267"><span class="lineNum">    1267</span>              :       // __torch_dispatch__ users will be able to redefine the</span>
<span id="L1268"><span class="lineNum">    1268</span>              :       // layout() method.</span>
<span id="L1269"><span class="lineNum">    1269</span>              :       return layout_impl();</span>
<span id="L1270"><span class="lineNum">    1270</span>              :     } else {</span>
<span id="L1271"><span class="lineNum">    1271</span>              :       TORCH_INTERNAL_ASSERT(</span>
<span id="L1272"><span class="lineNum">    1272</span>              :           is_mkldnn(), &quot;There is an error in the layout calculation logic.&quot;);</span>
<span id="L1273"><span class="lineNum">    1273</span>              :       return kMkldnn;</span>
<span id="L1274"><span class="lineNum">    1274</span>              :     }</span>
<span id="L1275"><span class="lineNum">    1275</span>              :   }</span>
<span id="L1276"><span class="lineNum">    1276</span>              : </span>
<span id="L1277"><span class="lineNum">    1277</span>              :   /**</span>
<span id="L1278"><span class="lineNum">    1278</span>              :    * True if a tensor was auto-wrapped from a C++ or Python number.</span>
<span id="L1279"><span class="lineNum">    1279</span>              :    * For example, when you write 't + 2', 2 is auto-wrapped into a Tensor</span>
<span id="L1280"><span class="lineNum">    1280</span>              :    * with `is_wrapped_number_` set to true.</span>
<span id="L1281"><span class="lineNum">    1281</span>              :    *</span>
<span id="L1282"><span class="lineNum">    1282</span>              :    * Wrapped numbers do not participate in the result type computation for</span>
<span id="L1283"><span class="lineNum">    1283</span>              :    * mixed-type operations if there are any Tensors that are not wrapped</span>
<span id="L1284"><span class="lineNum">    1284</span>              :    * numbers.  This is useful, because we want 't + 2' to work with</span>
<span id="L1285"><span class="lineNum">    1285</span>              :    * any type of tensor, not just LongTensor (which is what integers</span>
<span id="L1286"><span class="lineNum">    1286</span>              :    * in Python represent).</span>
<span id="L1287"><span class="lineNum">    1287</span>              :    *</span>
<span id="L1288"><span class="lineNum">    1288</span>              :    * Otherwise, they behave like their non-wrapped equivalents.</span>
<span id="L1289"><span class="lineNum">    1289</span>              :    * See [Result type computation] in TensorIterator.h.</span>
<span id="L1290"><span class="lineNum">    1290</span>              :    *</span>
<span id="L1291"><span class="lineNum">    1291</span>              :    * Why did we opt for wrapped numbers, as opposed to just having</span>
<span id="L1292"><span class="lineNum">    1292</span>              :    * an extra function add(Tensor, Scalar)?  This helps greatly reduce</span>
<span id="L1293"><span class="lineNum">    1293</span>              :    * the amount of code we have to write for add, when actually</span>
<span id="L1294"><span class="lineNum">    1294</span>              :    * a Tensor-Scalar addition is really just a Tensor-Tensor</span>
<span id="L1295"><span class="lineNum">    1295</span>              :    * addition when the RHS is 0-dim (except for promotion behavior.)</span>
<span id="L1296"><span class="lineNum">    1296</span>              :    */</span>
<span id="L1297"><span class="lineNum">    1297</span>              :   bool is_wrapped_number() const {</span>
<span id="L1298"><span class="lineNum">    1298</span>              :     return is_wrapped_number_;</span>
<span id="L1299"><span class="lineNum">    1299</span>              :   }</span>
<span id="L1300"><span class="lineNum">    1300</span>              : </span>
<span id="L1301"><span class="lineNum">    1301</span>              :   /**</span>
<span id="L1302"><span class="lineNum">    1302</span>              :    * Set whether or not a tensor was auto-wrapped from a C++ or Python</span>
<span id="L1303"><span class="lineNum">    1303</span>              :    * number.  You probably don't want to call this, unless you are</span>
<span id="L1304"><span class="lineNum">    1304</span>              :    * writing binding code.</span>
<span id="L1305"><span class="lineNum">    1305</span>              :    */</span>
<span id="L1306"><span class="lineNum">    1306</span>              :   void set_wrapped_number(bool value) {</span>
<span id="L1307"><span class="lineNum">    1307</span>              :     TORCH_INTERNAL_ASSERT(dim() == 0);</span>
<span id="L1308"><span class="lineNum">    1308</span>              :     is_wrapped_number_ = value;</span>
<span id="L1309"><span class="lineNum">    1309</span>              :   }</span>
<span id="L1310"><span class="lineNum">    1310</span>              : </span>
<span id="L1311"><span class="lineNum">    1311</span>              :   /**</span>
<span id="L1312"><span class="lineNum">    1312</span>              :    * Returns true if Tensor supports as_strided and as_strided_backward.</span>
<span id="L1313"><span class="lineNum">    1313</span>              :    * This is used in autograd to perform inplace update on view Tensors.</span>
<span id="L1314"><span class="lineNum">    1314</span>              :    * See Note [View + Inplace update for base tensor] and</span>
<span id="L1315"><span class="lineNum">    1315</span>              :    * [View + Inplace update for view tensor] for details.</span>
<span id="L1316"><span class="lineNum">    1316</span>              :    * Note this method only returns true for XLA backend, where it</span>
<span id="L1317"><span class="lineNum">    1317</span>              :    * simulates strided Tensor to support most view ops, but it cannot</span>
<span id="L1318"><span class="lineNum">    1318</span>              :    * fully support general `as_strided` case.</span>
<span id="L1319"><span class="lineNum">    1319</span>              :    * It can be expanded as needed in the future, e.g sparse Tensor.</span>
<span id="L1320"><span class="lineNum">    1320</span>              :    */</span>
<span id="L1321"><span class="lineNum">    1321</span>              :   inline bool support_as_strided() const {</span>
<span id="L1322"><span class="lineNum">    1322</span>              :     if (is_nested()) {</span>
<span id="L1323"><span class="lineNum">    1323</span>              :       return false;</span>
<span id="L1324"><span class="lineNum">    1324</span>              :     }</span>
<span id="L1325"><span class="lineNum">    1325</span>              :     if (key_set_.has(DispatchKey::Functionalize)) {</span>
<span id="L1326"><span class="lineNum">    1326</span>              :       return false;</span>
<span id="L1327"><span class="lineNum">    1327</span>              :     }</span>
<span id="L1328"><span class="lineNum">    1328</span>              :     return device().supports_as_strided();</span>
<span id="L1329"><span class="lineNum">    1329</span>              :   }</span>
<span id="L1330"><span class="lineNum">    1330</span>              : </span>
<span id="L1331"><span class="lineNum">    1331</span>              :   // ~~~~~ Autograd API ~~~~~</span>
<span id="L1332"><span class="lineNum">    1332</span>              :   // Some methods below are defined in TensorImpl.cpp because Tensor is an</span>
<span id="L1333"><span class="lineNum">    1333</span>              :   // incomplete type.</span>
<span id="L1334"><span class="lineNum">    1334</span>              : </span>
<span id="L1335"><span class="lineNum">    1335</span>              :   /**</span>
<span id="L1336"><span class="lineNum">    1336</span>              :    * Set whether or not a tensor requires gradient.</span>
<span id="L1337"><span class="lineNum">    1337</span>              :    */</span>
<span id="L1338"><span class="lineNum">    1338</span>              :   void set_requires_grad(bool requires_grad);</span>
<span id="L1339"><span class="lineNum">    1339</span>              : </span>
<span id="L1340"><span class="lineNum">    1340</span>              :   /**</span>
<span id="L1341"><span class="lineNum">    1341</span>              :    * True if a tensor requires gradient.  Tensors which require gradient</span>
<span id="L1342"><span class="lineNum">    1342</span>              :    * have history tracked for any operations performed on them, so that</span>
<span id="L1343"><span class="lineNum">    1343</span>              :    * we can automatically differentiate back to them.  A tensor that</span>
<span id="L1344"><span class="lineNum">    1344</span>              :    * requires gradient and has no history is a &quot;leaf&quot; tensor, which we</span>
<span id="L1345"><span class="lineNum">    1345</span>              :    * accumulate gradients into.</span>
<span id="L1346"><span class="lineNum">    1346</span>              :    */</span>
<span id="L1347"><span class="lineNum">    1347</span>              :   bool requires_grad() const;</span>
<span id="L1348"><span class="lineNum">    1348</span>              : </span>
<span id="L1349"><span class="lineNum">    1349</span>              :   /**</span>
<span id="L1350"><span class="lineNum">    1350</span>              :    * Return a mutable reference to the gradient.  This is conventionally</span>
<span id="L1351"><span class="lineNum">    1351</span>              :    * used as `t.grad() = x` to set a gradient to a completely new tensor.</span>
<span id="L1352"><span class="lineNum">    1352</span>              :    */</span>
<span id="L1353"><span class="lineNum">    1353</span>              :   at::Tensor&amp; mutable_grad();</span>
<span id="L1354"><span class="lineNum">    1354</span>              : </span>
<span id="L1355"><span class="lineNum">    1355</span>              :   /**</span>
<span id="L1356"><span class="lineNum">    1356</span>              :    * Return the accumulated gradient of a tensor.  This gradient is written</span>
<span id="L1357"><span class="lineNum">    1357</span>              :    * into when performing backwards, when this tensor is a leaf tensor.</span>
<span id="L1358"><span class="lineNum">    1358</span>              :    */</span>
<span id="L1359"><span class="lineNum">    1359</span>              :   const at::Tensor&amp; grad() const;</span>
<span id="L1360"><span class="lineNum">    1360</span>              : </span>
<span id="L1361"><span class="lineNum">    1361</span>              :   /**</span>
<span id="L1362"><span class="lineNum">    1362</span>              :    * Whether or not the imaginary part of the tensor should be negated</span>
<span id="L1363"><span class="lineNum">    1363</span>              :    */</span>
<span id="L1364"><span class="lineNum">    1364</span>              :   inline bool is_conj() const {</span>
<span id="L1365"><span class="lineNum">    1365</span>              :     constexpr auto conjugate_ks = DispatchKeySet(DispatchKey::Conjugate);</span>
<span id="L1366"><span class="lineNum">    1366</span>              :     return key_set_.has_all(conjugate_ks);</span>
<span id="L1367"><span class="lineNum">    1367</span>              :   }</span>
<span id="L1368"><span class="lineNum">    1368</span>              : </span>
<span id="L1369"><span class="lineNum">    1369</span>              :   /**</span>
<span id="L1370"><span class="lineNum">    1370</span>              :    * Set whether or not to take the conjugate of the tensor (flip the imaginary</span>
<span id="L1371"><span class="lineNum">    1371</span>              :    * bit).</span>
<span id="L1372"><span class="lineNum">    1372</span>              :    */</span>
<span id="L1373"><span class="lineNum">    1373</span>              :   void _set_conj(bool value) {</span>
<span id="L1374"><span class="lineNum">    1374</span>              :     if (value) {</span>
<span id="L1375"><span class="lineNum">    1375</span>              :       key_set_ = key_set_.add(DispatchKey::Conjugate);</span>
<span id="L1376"><span class="lineNum">    1376</span>              :       TORCH_INTERNAL_ASSERT(isComplexType(typeMetaToScalarType(dtype())));</span>
<span id="L1377"><span class="lineNum">    1377</span>              :     } else {</span>
<span id="L1378"><span class="lineNum">    1378</span>              :       key_set_ = key_set_.remove(DispatchKey::Conjugate);</span>
<span id="L1379"><span class="lineNum">    1379</span>              :     }</span>
<span id="L1380"><span class="lineNum">    1380</span>              :   }</span>
<span id="L1381"><span class="lineNum">    1381</span>              : </span>
<span id="L1382"><span class="lineNum">    1382</span>              :   /**</span>
<span id="L1383"><span class="lineNum">    1383</span>              :    * XXX: do not use, private api!</span>
<span id="L1384"><span class="lineNum">    1384</span>              :    * Update the backend component related keys to the backend component</span>
<span id="L1385"><span class="lineNum">    1385</span>              :    * corresponding to this device.</span>
<span id="L1386"><span class="lineNum">    1386</span>              :    */</span>
<span id="L1387"><span class="lineNum">    1387</span>              :   void _change_backend_component_keys(c10::Device device);</span>
<span id="L1388"><span class="lineNum">    1388</span>              : </span>
<span id="L1389"><span class="lineNum">    1389</span>              :   /**</span>
<span id="L1390"><span class="lineNum">    1390</span>              :    * Whether or not the tensor is a zerotensor</span>
<span id="L1391"><span class="lineNum">    1391</span>              :    */</span>
<span id="L1392"><span class="lineNum">    1392</span>              :   inline bool _is_zerotensor() const {</span>
<span id="L1393"><span class="lineNum">    1393</span>              :     constexpr auto zerotensor_ks = DispatchKeySet(DispatchKey::ZeroTensor);</span>
<span id="L1394"><span class="lineNum">    1394</span>              :     return key_set_.has_all(zerotensor_ks);</span>
<span id="L1395"><span class="lineNum">    1395</span>              :   }</span>
<span id="L1396"><span class="lineNum">    1396</span>              : </span>
<span id="L1397"><span class="lineNum">    1397</span>              :   /**</span>
<span id="L1398"><span class="lineNum">    1398</span>              :    Set whether or not the tensor is a zero tensor</span>
<span id="L1399"><span class="lineNum">    1399</span>              :   */</span>
<span id="L1400"><span class="lineNum">    1400</span>              :   void _set_zero(bool value) {</span>
<span id="L1401"><span class="lineNum">    1401</span>              :     if (value) {</span>
<span id="L1402"><span class="lineNum">    1402</span>              :       TORCH_INTERNAL_ASSERT(</span>
<span id="L1403"><span class="lineNum">    1403</span>              :           false,</span>
<span id="L1404"><span class="lineNum">    1404</span>              :           &quot;Please call `torch._efficientzerotensor` if you want to create a tensor with no storage.&quot;);</span>
<span id="L1405"><span class="lineNum">    1405</span>              :     } else {</span>
<span id="L1406"><span class="lineNum">    1406</span>              :       key_set_ = key_set_.remove(DispatchKey::ZeroTensor);</span>
<span id="L1407"><span class="lineNum">    1407</span>              :     }</span>
<span id="L1408"><span class="lineNum">    1408</span>              :   }</span>
<span id="L1409"><span class="lineNum">    1409</span>              : </span>
<span id="L1410"><span class="lineNum">    1410</span>              :   /**</span>
<span id="L1411"><span class="lineNum">    1411</span>              :    * Whether or not the tensor should be negated</span>
<span id="L1412"><span class="lineNum">    1412</span>              :    */</span>
<span id="L1413"><span class="lineNum">    1413</span>              :   inline bool is_neg() const {</span>
<span id="L1414"><span class="lineNum">    1414</span>              :     constexpr auto negative_ks = DispatchKeySet(DispatchKey::Negative);</span>
<span id="L1415"><span class="lineNum">    1415</span>              :     return key_set_.has_all(negative_ks);</span>
<span id="L1416"><span class="lineNum">    1416</span>              :   }</span>
<span id="L1417"><span class="lineNum">    1417</span>              : </span>
<span id="L1418"><span class="lineNum">    1418</span>              :   /**</span>
<span id="L1419"><span class="lineNum">    1419</span>              :    * Set whether or not to take the conjugate of the tensor (flip the imaginary</span>
<span id="L1420"><span class="lineNum">    1420</span>              :    * bit).</span>
<span id="L1421"><span class="lineNum">    1421</span>              :    */</span>
<span id="L1422"><span class="lineNum">    1422</span>              :   void _set_neg(bool value) {</span>
<span id="L1423"><span class="lineNum">    1423</span>              :     if (value) {</span>
<span id="L1424"><span class="lineNum">    1424</span>              :       key_set_ = key_set_.add(DispatchKey::Negative);</span>
<span id="L1425"><span class="lineNum">    1425</span>              :     } else {</span>
<span id="L1426"><span class="lineNum">    1426</span>              :       key_set_ = key_set_.remove(DispatchKey::Negative);</span>
<span id="L1427"><span class="lineNum">    1427</span>              :     }</span>
<span id="L1428"><span class="lineNum">    1428</span>              :   }</span>
<span id="L1429"><span class="lineNum">    1429</span>              : </span>
<span id="L1430"><span class="lineNum">    1430</span>              :   /**</span>
<span id="L1431"><span class="lineNum">    1431</span>              :    * Return the accumulated gradient of a tensor. This gradient is computed</span>
<span id="L1432"><span class="lineNum">    1432</span>              :    * using forward mode AD.</span>
<span id="L1433"><span class="lineNum">    1433</span>              :    *</span>
<span id="L1434"><span class="lineNum">    1434</span>              :    * This is an internal API that should never be used by end users.</span>
<span id="L1435"><span class="lineNum">    1435</span>              :    *</span>
<span id="L1436"><span class="lineNum">    1436</span>              :    * The API is as follows:</span>
<span id="L1437"><span class="lineNum">    1437</span>              :    *   - &quot;level&quot; allows to specify the level of forward AD nesting for which the</span>
<span id="L1438"><span class="lineNum">    1438</span>              :    *     gradient should be returned. Note that since levels are not fully</span>
<span id="L1439"><span class="lineNum">    1439</span>              :    *     supported yet, this argument should be 0. See documentation for</span>
<span id="L1440"><span class="lineNum">    1440</span>              :    *     torch::autograd::enter_dual_level for more details about forward AD</span>
<span id="L1441"><span class="lineNum">    1441</span>              :    * nesting.</span>
<span id="L1442"><span class="lineNum">    1442</span>              :    *   - &quot;self&quot; should represent the Tensor whose forward grad is accessed. It</span>
<span id="L1443"><span class="lineNum">    1443</span>              :    * is required when dealing with view.</span>
<span id="L1444"><span class="lineNum">    1444</span>              :    */</span>
<span id="L1445"><span class="lineNum">    1445</span>              :   const at::Tensor&amp; _fw_grad(uint64_t level, const at::TensorBase&amp; self) const;</span>
<span id="L1446"><span class="lineNum">    1446</span>              : </span>
<span id="L1447"><span class="lineNum">    1447</span>              :   /**</span>
<span id="L1448"><span class="lineNum">    1448</span>              :    * Sets the forward gradient for this Tensor.</span>
<span id="L1449"><span class="lineNum">    1449</span>              :    * The given Tensor might not be used directly and its content will be copied.</span>
<span id="L1450"><span class="lineNum">    1450</span>              :    *</span>
<span id="L1451"><span class="lineNum">    1451</span>              :    * This is an internal API that should never be used by end users.</span>
<span id="L1452"><span class="lineNum">    1452</span>              :    *</span>
<span id="L1453"><span class="lineNum">    1453</span>              :    * The API is as follows:</span>
<span id="L1454"><span class="lineNum">    1454</span>              :    *   - &quot;new_grad&quot; is a Tensor containing the new value of the gradient that</span>
<span id="L1455"><span class="lineNum">    1455</span>              :    * should be set</span>
<span id="L1456"><span class="lineNum">    1456</span>              :    *   - &quot;self&quot; should represent the Tensor whose forward grad is accessed. It</span>
<span id="L1457"><span class="lineNum">    1457</span>              :    * is required when dealing with view.</span>
<span id="L1458"><span class="lineNum">    1458</span>              :    *   - &quot;level&quot; allows to specify the level of forward AD nesting for which the</span>
<span id="L1459"><span class="lineNum">    1459</span>              :    *     gradient should be set. Note that since levels are not fully supported</span>
<span id="L1460"><span class="lineNum">    1460</span>              :    *     yet, this argument should be 0. See documentation for</span>
<span id="L1461"><span class="lineNum">    1461</span>              :    * torch::autograd::enter_dual_level for more details about forward AD</span>
<span id="L1462"><span class="lineNum">    1462</span>              :    * nesting.</span>
<span id="L1463"><span class="lineNum">    1463</span>              :    *   - &quot;is_inplace_op&quot; is a boolean flag that tells if this gradient was</span>
<span id="L1464"><span class="lineNum">    1464</span>              :    * generated by an inplace operation or an out of place one. This allows</span>
<span id="L1465"><span class="lineNum">    1465</span>              :    * better error checking.</span>
<span id="L1466"><span class="lineNum">    1466</span>              :    */</span>
<span id="L1467"><span class="lineNum">    1467</span>              :   void _set_fw_grad(</span>
<span id="L1468"><span class="lineNum">    1468</span>              :       const at::TensorBase&amp; new_grad,</span>
<span id="L1469"><span class="lineNum">    1469</span>              :       const at::TensorBase&amp; self,</span>
<span id="L1470"><span class="lineNum">    1470</span>              :       uint64_t level,</span>
<span id="L1471"><span class="lineNum">    1471</span>              :       bool is_inplace_op);</span>
<span id="L1472"><span class="lineNum">    1472</span>              : </span>
<span id="L1473"><span class="lineNum">    1473</span>              :   /**</span>
<span id="L1474"><span class="lineNum">    1474</span>              :    * Return a typed data pointer to the actual data which this tensor refers to.</span>
<span id="L1475"><span class="lineNum">    1475</span>              :    * This checks that the requested type (from the template parameter) matches</span>
<span id="L1476"><span class="lineNum">    1476</span>              :    * the internal type of the tensor.</span>
<span id="L1477"><span class="lineNum">    1477</span>              :    *</span>
<span id="L1478"><span class="lineNum">    1478</span>              :    * It is invalid to call data() on a dtype-uninitialized tensor, even if</span>
<span id="L1479"><span class="lineNum">    1479</span>              :    * the size is 0.</span>
<span id="L1480"><span class="lineNum">    1480</span>              :    *</span>
<span id="L1481"><span class="lineNum">    1481</span>              :    * WARNING: If a tensor is not contiguous, you MUST use strides when</span>
<span id="L1482"><span class="lineNum">    1482</span>              :    * performing index calculations to determine the location of elements in</span>
<span id="L1483"><span class="lineNum">    1483</span>              :    * the tensor.  We recommend using 'TensorAccessor' to handle this computation</span>
<span id="L1484"><span class="lineNum">    1484</span>              :    * for you; this class is available from 'Tensor'.</span>
<span id="L1485"><span class="lineNum">    1485</span>              :    */</span>
<span id="L1486"><span class="lineNum">    1486</span>              :   template &lt;typename T&gt;</span>
<span id="L1487"><span class="lineNum">    1487</span>              :   const T* data_dtype_initialized() const {</span>
<span id="L1488"><span class="lineNum">    1488</span>              :     return data_dtype_initialized_impl&lt;const T&gt;(</span>
<span id="L1489"><span class="lineNum">    1489</span>              :         [this] { return static_cast&lt;const T*&gt;(storage_.data()); });</span>
<span id="L1490"><span class="lineNum">    1490</span>              :   }</span>
<span id="L1491"><span class="lineNum">    1491</span>              : </span>
<span id="L1492"><span class="lineNum">    1492</span>              :   /**</span>
<span id="L1493"><span class="lineNum">    1493</span>              :    * Return a mutable typed data pointer to the actual data which this</span>
<span id="L1494"><span class="lineNum">    1494</span>              :    * tensor refers to. This checks that the requested type (from the</span>
<span id="L1495"><span class="lineNum">    1495</span>              :    * template parameter) matches the internal type of the tensor.</span>
<span id="L1496"><span class="lineNum">    1496</span>              :    *</span>
<span id="L1497"><span class="lineNum">    1497</span>              :    * It is invalid to call data() on a dtype-uninitialized tensor, even if</span>
<span id="L1498"><span class="lineNum">    1498</span>              :    * the size is 0.</span>
<span id="L1499"><span class="lineNum">    1499</span>              :    *</span>
<span id="L1500"><span class="lineNum">    1500</span>              :    * WARNING: If a tensor is not contiguous, you MUST use strides when</span>
<span id="L1501"><span class="lineNum">    1501</span>              :    * performing index calculations to determine the location of elements in</span>
<span id="L1502"><span class="lineNum">    1502</span>              :    * the tensor.  We recommend using 'TensorAccessor' to handle this computation</span>
<span id="L1503"><span class="lineNum">    1503</span>              :    * for you; this class is available from 'Tensor'.</span>
<span id="L1504"><span class="lineNum">    1504</span>              :    */</span>
<span id="L1505"><span class="lineNum">    1505</span>              :   template &lt;typename T&gt;</span>
<span id="L1506"><span class="lineNum">    1506</span>              :   T* mutable_data_dtype_initialized() {</span>
<span id="L1507"><span class="lineNum">    1507</span>              :     return data_dtype_initialized_impl&lt;T&gt;(</span>
<span id="L1508"><span class="lineNum">    1508</span>              :         [this] { return static_cast&lt;T*&gt;(storage_.mutable_data()); });</span>
<span id="L1509"><span class="lineNum">    1509</span>              :   }</span>
<span id="L1510"><span class="lineNum">    1510</span>              : </span>
<span id="L1511"><span class="lineNum">    1511</span>              :  private:</span>
<span id="L1512"><span class="lineNum">    1512</span>              :   // Shared implementation of data_dtype_initialized() and</span>
<span id="L1513"><span class="lineNum">    1513</span>              :   // mutable_data_dtype_initialized().</span>
<span id="L1514"><span class="lineNum">    1514</span>              :   template &lt;typename T, typename Func&gt;</span>
<span id="L1515"><span class="lineNum">    1515</span>              :   T* data_dtype_initialized_impl(const Func&amp; get_data) const {</span>
<span id="L1516"><span class="lineNum">    1516</span>              :     TORCH_CHECK(</span>
<span id="L1517"><span class="lineNum">    1517</span>              :         data_type_.Match&lt;std::remove_const_t&lt;T&gt;&gt;(),</span>
<span id="L1518"><span class="lineNum">    1518</span>              :         &quot;Tensor type mismatch, caller expects elements to be &quot;,</span>
<span id="L1519"><span class="lineNum">    1519</span>              :         caffe2::TypeMeta::TypeName&lt;std::remove_const_t&lt;T&gt;&gt;(),</span>
<span id="L1520"><span class="lineNum">    1520</span>              :         &quot;, while tensor contains &quot;,</span>
<span id="L1521"><span class="lineNum">    1521</span>              :         data_type_.name(),</span>
<span id="L1522"><span class="lineNum">    1522</span>              :         &quot;. &quot;);</span>
<span id="L1523"><span class="lineNum">    1523</span>              :     return data_ptr_impl_impl&lt;T&gt;(get_data);</span>
<span id="L1524"><span class="lineNum">    1524</span>              :   }</span>
<span id="L1525"><span class="lineNum">    1525</span>              : </span>
<span id="L1526"><span class="lineNum">    1526</span>              :  public:</span>
<span id="L1527"><span class="lineNum">    1527</span>              :   /**</span>
<span id="L1528"><span class="lineNum">    1528</span>              :    * More efficient helper for Tensor::data_ptr(). Like data&lt;T&gt;(), but</span>
<span id="L1529"><span class="lineNum">    1529</span>              :    * does not do a type check. Unlike the untemplated data(), does</span>
<span id="L1530"><span class="lineNum">    1530</span>              :    * check has_storage() and storage_initialized().</span>
<span id="L1531"><span class="lineNum">    1531</span>              :    */</span>
<span id="L1532"><span class="lineNum">    1532</span>              :   template &lt;typename T&gt;</span>
<span id="L1533"><span class="lineNum">    1533</span>              :   inline const T* data_ptr_impl() const {</span>
<span id="L1534"><span class="lineNum">    1534</span>              :     return data_ptr_impl_impl&lt;const T&gt;(</span>
<span id="L1535"><span class="lineNum">    1535</span>              :         [this] { return static_cast&lt;const T*&gt;(storage_.data()); });</span>
<span id="L1536"><span class="lineNum">    1536</span>              :   }</span>
<span id="L1537"><span class="lineNum">    1537</span>              : </span>
<span id="L1538"><span class="lineNum">    1538</span>              :   /**</span>
<span id="L1539"><span class="lineNum">    1539</span>              :    * More efficient helper for Tensor::data_ptr(). Like data&lt;T&gt;(), but</span>
<span id="L1540"><span class="lineNum">    1540</span>              :    * does not do a type check. Unlike the untemplated data(), does</span>
<span id="L1541"><span class="lineNum">    1541</span>              :    * check has_storage() and storage_initialized().</span>
<span id="L1542"><span class="lineNum">    1542</span>              :    */</span>
<span id="L1543"><span class="lineNum">    1543</span>              :   template &lt;typename T&gt;</span>
<span id="L1544"><span class="lineNum">    1544</span>              :   inline T* mutable_data_ptr_impl() {</span>
<span id="L1545"><span class="lineNum">    1545</span>              :     return data_ptr_impl_impl&lt;T&gt;(</span>
<span id="L1546"><span class="lineNum">    1546</span>              :         [this] { return static_cast&lt;T*&gt;(storage_.mutable_data()); });</span>
<span id="L1547"><span class="lineNum">    1547</span>              :   }</span>
<span id="L1548"><span class="lineNum">    1548</span>              : </span>
<span id="L1549"><span class="lineNum">    1549</span>              :  private:</span>
<span id="L1550"><span class="lineNum">    1550</span>              :   // Shared implementation of mutable_data_ptr_impl() and the future</span>
<span id="L1551"><span class="lineNum">    1551</span>              :   // mutable_data_ptr_impl().</span>
<span id="L1552"><span class="lineNum">    1552</span>              :   template &lt;typename T, typename Func&gt;</span>
<span id="L1553"><span class="lineNum">    1553</span>              :   __ubsan_ignore_pointer_overflow__ T* data_ptr_impl_impl(</span>
<span id="L1554"><span class="lineNum">    1554</span>              :       const Func&amp; get_data) const {</span>
<span id="L1555"><span class="lineNum">    1555</span>              :     if (C10_UNLIKELY(!has_storage())) {</span>
<span id="L1556"><span class="lineNum">    1556</span>              :       throw_data_ptr_access_error();</span>
<span id="L1557"><span class="lineNum">    1557</span>              :     }</span>
<span id="L1558"><span class="lineNum">    1558</span>              :     TORCH_CHECK(</span>
<span id="L1559"><span class="lineNum">    1559</span>              :         storage_initialized(),</span>
<span id="L1560"><span class="lineNum">    1560</span>              :         &quot;The tensor has a non-zero number of elements, but its data is not allocated yet. &quot;</span>
<span id="L1561"><span class="lineNum">    1561</span>              :         &quot;Caffe2 uses a lazy allocation, so you will need to call &quot;</span>
<span id="L1562"><span class="lineNum">    1562</span>              :         &quot;mutable_data() or raw_mutable_data() to actually allocate memory.&quot;);</span>
<span id="L1563"><span class="lineNum">    1563</span>              :     // Caller does the type check.</span>
<span id="L1564"><span class="lineNum">    1564</span>              :     // Note: storage_offset_ can be non-null even for zero-elements tensors</span>
<span id="L1565"><span class="lineNum">    1565</span>              :     // (for example if created as `torch.empty(5)[10:]`) that triggers</span>
<span id="L1566"><span class="lineNum">    1566</span>              :     // applying non-zero offset to null pointer in UBSan</span>
<span id="L1567"><span class="lineNum">    1567</span>              :     return get_data() + storage_offset_;</span>
<span id="L1568"><span class="lineNum">    1568</span>              :   }</span>
<span id="L1569"><span class="lineNum">    1569</span>              : </span>
<span id="L1570"><span class="lineNum">    1570</span>              :  public:</span>
<span id="L1571"><span class="lineNum">    1571</span>              :   /**</span>
<span id="L1572"><span class="lineNum">    1572</span>              :    * Return a const void* data pointer to the actual data which this</span>
<span id="L1573"><span class="lineNum">    1573</span>              :    * tensor refers to.</span>
<span id="L1574"><span class="lineNum">    1574</span>              :    *</span>
<span id="L1575"><span class="lineNum">    1575</span>              :    * It is invalid to call data() on a dtype-uninitialized tensor, even if the</span>
<span id="L1576"><span class="lineNum">    1576</span>              :    * size is 0.</span>
<span id="L1577"><span class="lineNum">    1577</span>              :    *</span>
<span id="L1578"><span class="lineNum">    1578</span>              :    * WARNING: The data pointed to by this tensor may not contiguous; do NOT</span>
<span id="L1579"><span class="lineNum">    1579</span>              :    * assume that itemsize() * numel() is sufficient to compute the bytes that</span>
<span id="L1580"><span class="lineNum">    1580</span>              :    * can be validly read from this tensor.</span>
<span id="L1581"><span class="lineNum">    1581</span>              :    */</span>
<span id="L1582"><span class="lineNum">    1582</span>              :   inline const void* data() const {</span>
<span id="L1583"><span class="lineNum">    1583</span>              :     return data_impl&lt;const void&gt;(</span>
<span id="L1584"><span class="lineNum">    1584</span>              :         [this] { return static_cast&lt;const char*&gt;(storage_.data()); });</span>
<span id="L1585"><span class="lineNum">    1585</span>              :   }</span>
<span id="L1586"><span class="lineNum">    1586</span>              : </span>
<span id="L1587"><span class="lineNum">    1587</span>              :   /**</span>
<span id="L1588"><span class="lineNum">    1588</span>              :    * Return a void* data pointer to the actual data which this tensor refers to.</span>
<span id="L1589"><span class="lineNum">    1589</span>              :    *</span>
<span id="L1590"><span class="lineNum">    1590</span>              :    * It is invalid to call mutable_data() on a dtype-uninitialized</span>
<span id="L1591"><span class="lineNum">    1591</span>              :    * tensor, even if the size is 0.</span>
<span id="L1592"><span class="lineNum">    1592</span>              :    *</span>
<span id="L1593"><span class="lineNum">    1593</span>              :    * WARNING: The data pointed to by this tensor may not contiguous; do NOT</span>
<span id="L1594"><span class="lineNum">    1594</span>              :    * assume that itemsize() * numel() is sufficient to compute the bytes that</span>
<span id="L1595"><span class="lineNum">    1595</span>              :    * can be validly read from this tensor.</span>
<span id="L1596"><span class="lineNum">    1596</span>              :    */</span>
<span id="L1597"><span class="lineNum">    1597</span>              :   inline void* mutable_data() {</span>
<span id="L1598"><span class="lineNum">    1598</span>              :     return data_impl&lt;void&gt;(</span>
<span id="L1599"><span class="lineNum">    1599</span>              :         [this] { return static_cast&lt;char*&gt;(storage_.mutable_data()); });</span>
<span id="L1600"><span class="lineNum">    1600</span>              :   }</span>
<span id="L1601"><span class="lineNum">    1601</span>              : </span>
<span id="L1602"><span class="lineNum">    1602</span>              :  private:</span>
<span id="L1603"><span class="lineNum">    1603</span>              :   /// Shared implementation of data() and mutable_data().</span>
<span id="L1604"><span class="lineNum">    1604</span>              :   ///</span>
<span id="L1605"><span class="lineNum">    1605</span>              :   /// get_data must return a byte-addressed pointer, e.g. char*,</span>
<span id="L1606"><span class="lineNum">    1606</span>              :   /// std::byte const*, etc.</span>
<span id="L1607"><span class="lineNum">    1607</span>              :   template &lt;typename Void, typename Func&gt;</span>
<span id="L1608"><span class="lineNum">    1608</span>              :   Void* data_impl(const Func&amp; get_data) const {</span>
<span id="L1609"><span class="lineNum">    1609</span>              :     if (C10_UNLIKELY(!has_storage())) {</span>
<span id="L1610"><span class="lineNum">    1610</span>              :       throw_data_ptr_access_error();</span>
<span id="L1611"><span class="lineNum">    1611</span>              :     }</span>
<span id="L1612"><span class="lineNum">    1612</span>              :     TORCH_CHECK(</span>
<span id="L1613"><span class="lineNum">    1613</span>              :         dtype_initialized(),</span>
<span id="L1614"><span class="lineNum">    1614</span>              :         &quot;Cannot access data pointer of Tensor that doesn't have initialized dtype &quot;</span>
<span id="L1615"><span class="lineNum">    1615</span>              :         &quot;(e.g., caffe2::Tensor x(CPU), prior to calling mutable_data&lt;T&gt;() on x)&quot;);</span>
<span id="L1616"><span class="lineNum">    1616</span>              :     auto* data = get_data();</span>
<span id="L1617"><span class="lineNum">    1617</span>              :     static_assert(</span>
<span id="L1618"><span class="lineNum">    1618</span>              :         sizeof(*data) == 1, &quot;get_data must return a byte-addressed pointer.&quot;);</span>
<span id="L1619"><span class="lineNum">    1619</span>              :     // Computing an offset into an empty tensor would be UB, since an empty</span>
<span id="L1620"><span class="lineNum">    1620</span>              :     // tensor's storage will be nullptr, and adding a nonzero offset to nullptr</span>
<span id="L1621"><span class="lineNum">    1621</span>              :     // is UB.  So we skip the offset computation in this case.</span>
<span id="L1622"><span class="lineNum">    1622</span>              :     if (is_empty()) {</span>
<span id="L1623"><span class="lineNum">    1623</span>              :       return nullptr;</span>
<span id="L1624"><span class="lineNum">    1624</span>              :     }</span>
<span id="L1625"><span class="lineNum">    1625</span>              :     return data + data_type_.itemsize() * storage_offset_;</span>
<span id="L1626"><span class="lineNum">    1626</span>              :   }</span>
<span id="L1627"><span class="lineNum">    1627</span>              : </span>
<span id="L1628"><span class="lineNum">    1628</span>              :  public:</span>
<span id="L1629"><span class="lineNum">    1629</span>              :   /**</span>
<span id="L1630"><span class="lineNum">    1630</span>              :    * Returns the TypeMeta of a tensor, which describes what data type</span>
<span id="L1631"><span class="lineNum">    1631</span>              :    * it is (e.g., int, float, ...)</span>
<span id="L1632"><span class="lineNum">    1632</span>              :    */</span>
<span id="L1633"><span class="lineNum">    1633</span> <span class="tlaGNC">      402994 :   const caffe2::TypeMeta dtype() const {</span></span>
<span id="L1634"><span class="lineNum">    1634</span> <span class="tlaGNC">      402994 :     return data_type_;</span></span>
<span id="L1635"><span class="lineNum">    1635</span>              :   }</span>
<span id="L1636"><span class="lineNum">    1636</span>              : </span>
<span id="L1637"><span class="lineNum">    1637</span>              :   /**</span>
<span id="L1638"><span class="lineNum">    1638</span>              :    * Return the size of a single element of this tensor in bytes.</span>
<span id="L1639"><span class="lineNum">    1639</span>              :    */</span>
<span id="L1640"><span class="lineNum">    1640</span>              :   size_t itemsize() const {</span>
<span id="L1641"><span class="lineNum">    1641</span>              :     TORCH_CHECK(</span>
<span id="L1642"><span class="lineNum">    1642</span>              :         dtype_initialized(),</span>
<span id="L1643"><span class="lineNum">    1643</span>              :         &quot;Cannot report itemsize of Tensor that doesn't have initialized dtype &quot;</span>
<span id="L1644"><span class="lineNum">    1644</span>              :         &quot;(e.g., caffe2::Tensor x(CPU), prior to calling mutable_data&lt;T&gt;() on x)&quot;);</span>
<span id="L1645"><span class="lineNum">    1645</span>              :     return data_type_.itemsize();</span>
<span id="L1646"><span class="lineNum">    1646</span>              :   }</span>
<span id="L1647"><span class="lineNum">    1647</span>              : </span>
<span id="L1648"><span class="lineNum">    1648</span>              :   void set_backend_meta(intrusive_ptr&lt;c10::BackendMeta&gt; backend_meta) {</span>
<span id="L1649"><span class="lineNum">    1649</span>              :     get_extra_meta().backend_meta_ = std::move(backend_meta);</span>
<span id="L1650"><span class="lineNum">    1650</span>              :   }</span>
<span id="L1651"><span class="lineNum">    1651</span>              : </span>
<span id="L1652"><span class="lineNum">    1652</span>              :   c10::BackendMeta* get_backend_meta() {</span>
<span id="L1653"><span class="lineNum">    1653</span>              :     if (!extra_meta_) {</span>
<span id="L1654"><span class="lineNum">    1654</span>              :       return nullptr;</span>
<span id="L1655"><span class="lineNum">    1655</span>              :     }</span>
<span id="L1656"><span class="lineNum">    1656</span>              :     return extra_meta_-&gt;backend_meta_.get();</span>
<span id="L1657"><span class="lineNum">    1657</span>              :   }</span>
<span id="L1658"><span class="lineNum">    1658</span>              : </span>
<span id="L1659"><span class="lineNum">    1659</span>              :   intrusive_ptr&lt;c10::BackendMeta&gt; get_backend_meta_intrusive_ptr() const {</span>
<span id="L1660"><span class="lineNum">    1660</span>              :     if (!extra_meta_) {</span>
<span id="L1661"><span class="lineNum">    1661</span>              :       return nullptr;</span>
<span id="L1662"><span class="lineNum">    1662</span>              :     }</span>
<span id="L1663"><span class="lineNum">    1663</span>              :     return extra_meta_-&gt;backend_meta_;</span>
<span id="L1664"><span class="lineNum">    1664</span>              :   }</span>
<span id="L1665"><span class="lineNum">    1665</span>              : </span>
<span id="L1666"><span class="lineNum">    1666</span>              :   void release_storage_and_set_meta_custom_data_ptr_error_msg_(</span>
<span id="L1667"><span class="lineNum">    1667</span>              :       c10::optional&lt;std::string&gt; s) {</span>
<span id="L1668"><span class="lineNum">    1668</span>              :     storage_ = {};</span>
<span id="L1669"><span class="lineNum">    1669</span>              :     get_extra_meta().custom_data_ptr_error_msg_ = std::move(s);</span>
<span id="L1670"><span class="lineNum">    1670</span>              :   }</span>
<span id="L1671"><span class="lineNum">    1671</span>              : </span>
<span id="L1672"><span class="lineNum">    1672</span>              :  protected:</span>
<span id="L1673"><span class="lineNum">    1673</span>              :   /**</span>
<span id="L1674"><span class="lineNum">    1674</span>              :    * Returns the human-readable name of the actual type of this object (e.g.,</span>
<span id="L1675"><span class="lineNum">    1675</span>              :    * TensorImpl, BatchedTensorImpl, etc.). Used for error messages.</span>
<span id="L1676"><span class="lineNum">    1676</span>              :    */</span>
<span id="L1677"><span class="lineNum">    1677</span>              :   virtual const char* tensorimpl_type_name() const {</span>
<span id="L1678"><span class="lineNum">    1678</span>              :     return &quot;TensorImpl&quot;;</span>
<span id="L1679"><span class="lineNum">    1679</span>              :   }</span>
<span id="L1680"><span class="lineNum">    1680</span>              : </span>
<span id="L1681"><span class="lineNum">    1681</span>              :  private:</span>
<span id="L1682"><span class="lineNum">    1682</span>              :   [[noreturn]] void throw_storage_access_error() const;</span>
<span id="L1683"><span class="lineNum">    1683</span>              :   [[noreturn]] void throw_data_ptr_access_error() const;</span>
<span id="L1684"><span class="lineNum">    1684</span>              : </span>
<span id="L1685"><span class="lineNum">    1685</span>              :   ExtraMeta&amp; get_extra_meta() {</span>
<span id="L1686"><span class="lineNum">    1686</span>              :     if (!extra_meta_) {</span>
<span id="L1687"><span class="lineNum">    1687</span>              :       extra_meta_ = std::make_unique&lt;ExtraMeta&gt;();</span>
<span id="L1688"><span class="lineNum">    1688</span>              :     }</span>
<span id="L1689"><span class="lineNum">    1689</span>              :     return *extra_meta_;</span>
<span id="L1690"><span class="lineNum">    1690</span>              :   }</span>
<span id="L1691"><span class="lineNum">    1691</span>              : </span>
<span id="L1692"><span class="lineNum">    1692</span>              :   c10::SymbolicShapeMeta&amp; symbolic_shape_meta() {</span>
<span id="L1693"><span class="lineNum">    1693</span>              :     TORCH_INTERNAL_ASSERT(extra_meta_ &amp;&amp; extra_meta_-&gt;symbolic_shape_meta_);</span>
<span id="L1694"><span class="lineNum">    1694</span>              :     return *extra_meta_-&gt;symbolic_shape_meta_;</span>
<span id="L1695"><span class="lineNum">    1695</span>              :   }</span>
<span id="L1696"><span class="lineNum">    1696</span>              : </span>
<span id="L1697"><span class="lineNum">    1697</span>              :   const c10::SymbolicShapeMeta&amp; symbolic_shape_meta() const {</span>
<span id="L1698"><span class="lineNum">    1698</span>              :     TORCH_INTERNAL_ASSERT(extra_meta_ &amp;&amp; extra_meta_-&gt;symbolic_shape_meta_);</span>
<span id="L1699"><span class="lineNum">    1699</span>              :     return *extra_meta_-&gt;symbolic_shape_meta_;</span>
<span id="L1700"><span class="lineNum">    1700</span>              :   }</span>
<span id="L1701"><span class="lineNum">    1701</span>              : </span>
<span id="L1702"><span class="lineNum">    1702</span>              :  public:</span>
<span id="L1703"><span class="lineNum">    1703</span>              :   /**</span>
<span id="L1704"><span class="lineNum">    1704</span>              :    * True if a tensor has no elements (e.g., numel() == 0).</span>
<span id="L1705"><span class="lineNum">    1705</span>              :    */</span>
<span id="L1706"><span class="lineNum">    1706</span>              :   inline bool is_empty() const {</span>
<span id="L1707"><span class="lineNum">    1707</span>              :     return numel() == 0;</span>
<span id="L1708"><span class="lineNum">    1708</span>              :   }</span>
<span id="L1709"><span class="lineNum">    1709</span>              : </span>
<span id="L1710"><span class="lineNum">    1710</span>              :   // if we are going to use sym sizes, we should be setting sym strides at the</span>
<span id="L1711"><span class="lineNum">    1711</span>              :   // same time, otherwise it's very easy to misuse this API</span>
<span id="L1712"><span class="lineNum">    1712</span>              :   void set_sizes_and_strides(</span>
<span id="L1713"><span class="lineNum">    1713</span>              :       c10::SymIntArrayRef sizes,</span>
<span id="L1714"><span class="lineNum">    1714</span>              :       c10::SymIntArrayRef strides,</span>
<span id="L1715"><span class="lineNum">    1715</span>              :       c10::optional&lt;c10::SymInt&gt; storage_offset = c10::nullopt);</span>
<span id="L1716"><span class="lineNum">    1716</span>              :   // This is renamed to avoid breaking overload BC</span>
<span id="L1717"><span class="lineNum">    1717</span>              :   void generic_set_sizes_contiguous(c10::SymIntArrayRef sizes);</span>
<span id="L1718"><span class="lineNum">    1718</span>              :   void generic_set_sizes_contiguous(c10::IntArrayRef sizes) {</span>
<span id="L1719"><span class="lineNum">    1719</span>              :     set_sizes_contiguous(sizes);</span>
<span id="L1720"><span class="lineNum">    1720</span>              :   }</span>
<span id="L1721"><span class="lineNum">    1721</span>              : </span>
<span id="L1722"><span class="lineNum">    1722</span>              :   /**</span>
<span id="L1723"><span class="lineNum">    1723</span>              :    * Change the size at some dimension.  This DOES NOT update strides;</span>
<span id="L1724"><span class="lineNum">    1724</span>              :    * thus, most changes to size will not preserve contiguity.  You probably</span>
<span id="L1725"><span class="lineNum">    1725</span>              :    * also want to call set_stride() when you call this.</span>
<span id="L1726"><span class="lineNum">    1726</span>              :    *</span>
<span id="L1727"><span class="lineNum">    1727</span>              :    * TODO: This should be jettisoned in favor of `set_sizes_and_strides`,</span>
<span id="L1728"><span class="lineNum">    1728</span>              :    * which is harder to misuse.</span>
<span id="L1729"><span class="lineNum">    1729</span>              :    */</span>
<span id="L1730"><span class="lineNum">    1730</span>              :   virtual void set_size(int64_t dim, int64_t new_size) {</span>
<span id="L1731"><span class="lineNum">    1731</span>              :     TORCH_CHECK(</span>
<span id="L1732"><span class="lineNum">    1732</span>              :         allow_tensor_metadata_change(),</span>
<span id="L1733"><span class="lineNum">    1733</span>              :         &quot;set_size &quot;,</span>
<span id="L1734"><span class="lineNum">    1734</span>              :         err_msg_tensor_metadata_change_not_allowed);</span>
<span id="L1735"><span class="lineNum">    1735</span>              :     TORCH_CHECK(</span>
<span id="L1736"><span class="lineNum">    1736</span>              :         !matches_policy(SizesStridesPolicy::CustomSizes),</span>
<span id="L1737"><span class="lineNum">    1737</span>              :         &quot;set_size() called on tensor with dynamic shapes or customized size behavior&quot;)</span>
<span id="L1738"><span class="lineNum">    1738</span>              :     sizes_and_strides_.size_at(dim) = new_size;</span>
<span id="L1739"><span class="lineNum">    1739</span>              :     refresh_numel();</span>
<span id="L1740"><span class="lineNum">    1740</span>              :     refresh_contiguous();</span>
<span id="L1741"><span class="lineNum">    1741</span>              :   }</span>
<span id="L1742"><span class="lineNum">    1742</span>              : </span>
<span id="L1743"><span class="lineNum">    1743</span>              :   /**</span>
<span id="L1744"><span class="lineNum">    1744</span>              :    * Change the stride at some dimension.</span>
<span id="L1745"><span class="lineNum">    1745</span>              :    *</span>
<span id="L1746"><span class="lineNum">    1746</span>              :    * TODO: This should be jettisoned in favor of `set_sizes_and_strides`,</span>
<span id="L1747"><span class="lineNum">    1747</span>              :    * which is harder to misuse.</span>
<span id="L1748"><span class="lineNum">    1748</span>              :    */</span>
<span id="L1749"><span class="lineNum">    1749</span>              :   virtual void set_stride(int64_t dim, int64_t new_stride) {</span>
<span id="L1750"><span class="lineNum">    1750</span>              :     TORCH_CHECK(</span>
<span id="L1751"><span class="lineNum">    1751</span>              :         allow_tensor_metadata_change(),</span>
<span id="L1752"><span class="lineNum">    1752</span>              :         &quot;set_stride &quot;,</span>
<span id="L1753"><span class="lineNum">    1753</span>              :         err_msg_tensor_metadata_change_not_allowed);</span>
<span id="L1754"><span class="lineNum">    1754</span>              :     TORCH_CHECK(</span>
<span id="L1755"><span class="lineNum">    1755</span>              :         !has_symbolic_sizes_strides_,</span>
<span id="L1756"><span class="lineNum">    1756</span>              :         &quot;set_stride() called on tensor with symbolic shape&quot;)</span>
<span id="L1757"><span class="lineNum">    1757</span>              :     sizes_and_strides_.stride_at_unchecked(dim) = new_stride;</span>
<span id="L1758"><span class="lineNum">    1758</span>              :     refresh_contiguous();</span>
<span id="L1759"><span class="lineNum">    1759</span>              :   }</span>
<span id="L1760"><span class="lineNum">    1760</span>              : </span>
<span id="L1761"><span class="lineNum">    1761</span>              :   /**</span>
<span id="L1762"><span class="lineNum">    1762</span>              :    * Set the offset into the storage of this tensor.</span>
<span id="L1763"><span class="lineNum">    1763</span>              :    *</span>
<span id="L1764"><span class="lineNum">    1764</span>              :    * WARNING: This does NOT check if the tensor is in bounds for the new</span>
<span id="L1765"><span class="lineNum">    1765</span>              :    * location at the storage; the caller is responsible for checking this</span>
<span id="L1766"><span class="lineNum">    1766</span>              :    * (and resizing if necessary.)</span>
<span id="L1767"><span class="lineNum">    1767</span>              :    */</span>
<span id="L1768"><span class="lineNum">    1768</span>              :   virtual void set_storage_offset(int64_t storage_offset) {</span>
<span id="L1769"><span class="lineNum">    1769</span>              :     TORCH_CHECK(</span>
<span id="L1770"><span class="lineNum">    1770</span>              :         allow_tensor_metadata_change(),</span>
<span id="L1771"><span class="lineNum">    1771</span>              :         &quot;set_storage_offset &quot;,</span>
<span id="L1772"><span class="lineNum">    1772</span>              :         err_msg_tensor_metadata_change_not_allowed);</span>
<span id="L1773"><span class="lineNum">    1773</span>              :     // TODO: this should probably consult policy</span>
<span id="L1774"><span class="lineNum">    1774</span>              :     TORCH_CHECK(</span>
<span id="L1775"><span class="lineNum">    1775</span>              :         !has_symbolic_sizes_strides_,</span>
<span id="L1776"><span class="lineNum">    1776</span>              :         &quot;set_storage_offset() called on tensor with symbolic shape&quot;)</span>
<span id="L1777"><span class="lineNum">    1777</span>              :     storage_offset_ = storage_offset;</span>
<span id="L1778"><span class="lineNum">    1778</span>              :   }</span>
<span id="L1779"><span class="lineNum">    1779</span>              : </span>
<span id="L1780"><span class="lineNum">    1780</span>              :   /**</span>
<span id="L1781"><span class="lineNum">    1781</span>              :    * Like set_sizes_and_strides but assumes contiguous strides.</span>
<span id="L1782"><span class="lineNum">    1782</span>              :    *</span>
<span id="L1783"><span class="lineNum">    1783</span>              :    * WARNING: This function does not check if the requested</span>
<span id="L1784"><span class="lineNum">    1784</span>              :    * sizes/strides are in bounds for the storage that is allocated;</span>
<span id="L1785"><span class="lineNum">    1785</span>              :    * this is the responsibility of the caller</span>
<span id="L1786"><span class="lineNum">    1786</span>              :    */</span>
<span id="L1787"><span class="lineNum">    1787</span>              :   void set_sizes_contiguous(IntArrayRef new_size) {</span>
<span id="L1788"><span class="lineNum">    1788</span>              :     TORCH_CHECK(</span>
<span id="L1789"><span class="lineNum">    1789</span>              :         allow_tensor_metadata_change(),</span>
<span id="L1790"><span class="lineNum">    1790</span>              :         &quot;set_sizes_contiguous &quot;,</span>
<span id="L1791"><span class="lineNum">    1791</span>              :         err_msg_tensor_metadata_change_not_allowed);</span>
<span id="L1792"><span class="lineNum">    1792</span>              :     TORCH_CHECK(</span>
<span id="L1793"><span class="lineNum">    1793</span>              :         !matches_policy(SizesStridesPolicy::CustomStrides),</span>
<span id="L1794"><span class="lineNum">    1794</span>              :         &quot;tried to directly modify sizes for customized tensor&quot;);</span>
<span id="L1795"><span class="lineNum">    1795</span>              :     sizes_and_strides_.set_sizes(new_size);</span>
<span id="L1796"><span class="lineNum">    1796</span>              : </span>
<span id="L1797"><span class="lineNum">    1797</span>              :     refresh_numel();</span>
<span id="L1798"><span class="lineNum">    1798</span>              :     empty_tensor_restride(</span>
<span id="L1799"><span class="lineNum">    1799</span>              :         MemoryFormat::Contiguous); // calls refresh_contiguous()</span>
<span id="L1800"><span class="lineNum">    1800</span>              :   }</span>
<span id="L1801"><span class="lineNum">    1801</span>              : </span>
<span id="L1802"><span class="lineNum">    1802</span>              :   /**</span>
<span id="L1803"><span class="lineNum">    1803</span>              :    * Set the sizes and strides of a tensor.</span>
<span id="L1804"><span class="lineNum">    1804</span>              :    *</span>
<span id="L1805"><span class="lineNum">    1805</span>              :    * WARNING: This function does not check if the requested</span>
<span id="L1806"><span class="lineNum">    1806</span>              :    * sizes/strides are in bounds for the storage that is allocated;</span>
<span id="L1807"><span class="lineNum">    1807</span>              :    * this is the responsibility of the caller</span>
<span id="L1808"><span class="lineNum">    1808</span>              :    */</span>
<span id="L1809"><span class="lineNum">    1809</span>              :   void set_sizes_and_strides(</span>
<span id="L1810"><span class="lineNum">    1810</span>              :       IntArrayRef new_size,</span>
<span id="L1811"><span class="lineNum">    1811</span>              :       IntArrayRef new_stride,</span>
<span id="L1812"><span class="lineNum">    1812</span>              :       c10::optional&lt;int64_t&gt; storage_offset = c10::nullopt) {</span>
<span id="L1813"><span class="lineNum">    1813</span>              :     TORCH_CHECK(</span>
<span id="L1814"><span class="lineNum">    1814</span>              :         allow_tensor_metadata_change(),</span>
<span id="L1815"><span class="lineNum">    1815</span>              :         &quot;set_sizes_and_strides &quot;,</span>
<span id="L1816"><span class="lineNum">    1816</span>              :         err_msg_tensor_metadata_change_not_allowed);</span>
<span id="L1817"><span class="lineNum">    1817</span>              :     TORCH_CHECK(</span>
<span id="L1818"><span class="lineNum">    1818</span>              :         !has_symbolic_sizes_strides_,</span>
<span id="L1819"><span class="lineNum">    1819</span>              :         &quot;set_sizes_and_strides() called on tensor with symbolic shape&quot;)</span>
<span id="L1820"><span class="lineNum">    1820</span>              :     TORCH_CHECK(</span>
<span id="L1821"><span class="lineNum">    1821</span>              :         new_size.size() == new_stride.size(),</span>
<span id="L1822"><span class="lineNum">    1822</span>              :         &quot;dimensionality of sizes (&quot;,</span>
<span id="L1823"><span class="lineNum">    1823</span>              :         new_size.size(),</span>
<span id="L1824"><span class="lineNum">    1824</span>              :         &quot;) must match dimensionality of strides (&quot;,</span>
<span id="L1825"><span class="lineNum">    1825</span>              :         new_stride.size(),</span>
<span id="L1826"><span class="lineNum">    1826</span>              :         &quot;)&quot;);</span>
<span id="L1827"><span class="lineNum">    1827</span>              :     const auto new_dim = new_size.size();</span>
<span id="L1828"><span class="lineNum">    1828</span>              :     bool overflowed = false;</span>
<span id="L1829"><span class="lineNum">    1829</span>              :     sizes_and_strides_.set_sizes(new_size);</span>
<span id="L1830"><span class="lineNum">    1830</span>              : </span>
<span id="L1831"><span class="lineNum">    1831</span>              :     if (new_dim &gt; 0) {</span>
<span id="L1832"><span class="lineNum">    1832</span>              :       for (size_t dim = new_dim - 1;; dim--) {</span>
<span id="L1833"><span class="lineNum">    1833</span>              :         if (new_stride[dim] &gt;= 0) {</span>
<span id="L1834"><span class="lineNum">    1834</span>              :           sizes_and_strides_.stride_at_unchecked(dim) = new_stride[dim];</span>
<span id="L1835"><span class="lineNum">    1835</span>              :         } else {</span>
<span id="L1836"><span class="lineNum">    1836</span>              :           // XXX: This behavior is surprising and may need to be removed to</span>
<span id="L1837"><span class="lineNum">    1837</span>              :           // support negative strides. Some pytorch functions rely on it:</span>
<span id="L1838"><span class="lineNum">    1838</span>              :           // for example, torch.cat (run TestTorch.test_cat_empty).</span>
<span id="L1839"><span class="lineNum">    1839</span>              :           if (dim == new_dim - 1) {</span>
<span id="L1840"><span class="lineNum">    1840</span>              :             sizes_and_strides_.stride_at_unchecked(dim) = 1;</span>
<span id="L1841"><span class="lineNum">    1841</span>              :           } else {</span>
<span id="L1842"><span class="lineNum">    1842</span>              :             // Keep stride monotonically increasing to match NumPy.</span>
<span id="L1843"><span class="lineNum">    1843</span>              :             overflowed |= c10::mul_overflows(</span>
<span id="L1844"><span class="lineNum">    1844</span>              :                 sizes_and_strides_.stride_at_unchecked(dim + 1),</span>
<span id="L1845"><span class="lineNum">    1845</span>              :                 std::max&lt;int64_t&gt;(</span>
<span id="L1846"><span class="lineNum">    1846</span>              :                     sizes_and_strides_.size_at_unchecked(dim + 1), 1),</span>
<span id="L1847"><span class="lineNum">    1847</span>              :                 std::addressof(sizes_and_strides_.stride_at_unchecked(dim)));</span>
<span id="L1848"><span class="lineNum">    1848</span>              :           }</span>
<span id="L1849"><span class="lineNum">    1849</span>              :         }</span>
<span id="L1850"><span class="lineNum">    1850</span>              :         if (dim == 0)</span>
<span id="L1851"><span class="lineNum">    1851</span>              :           break;</span>
<span id="L1852"><span class="lineNum">    1852</span>              :       }</span>
<span id="L1853"><span class="lineNum">    1853</span>              :       TORCH_CHECK(!overflowed, &quot;Stride calculation overflowed&quot;);</span>
<span id="L1854"><span class="lineNum">    1854</span>              :     }</span>
<span id="L1855"><span class="lineNum">    1855</span>              : </span>
<span id="L1856"><span class="lineNum">    1856</span>              :     refresh_numel();</span>
<span id="L1857"><span class="lineNum">    1857</span>              :     refresh_contiguous();</span>
<span id="L1858"><span class="lineNum">    1858</span>              : </span>
<span id="L1859"><span class="lineNum">    1859</span>              :     if (storage_offset.has_value()) {</span>
<span id="L1860"><span class="lineNum">    1860</span>              :       storage_offset_ = *storage_offset;</span>
<span id="L1861"><span class="lineNum">    1861</span>              :     }</span>
<span id="L1862"><span class="lineNum">    1862</span>              :   }</span>
<span id="L1863"><span class="lineNum">    1863</span>              : </span>
<span id="L1864"><span class="lineNum">    1864</span>              :   /**</span>
<span id="L1865"><span class="lineNum">    1865</span>              :    * Set whether a tensor allows changes to its metadata (e.g. sizes / strides /</span>
<span id="L1866"><span class="lineNum">    1866</span>              :    * storage / storage_offset). See NOTE [ Metadata Change for a Detached Tensor</span>
<span id="L1867"><span class="lineNum">    1867</span>              :    * ] for details.</span>
<span id="L1868"><span class="lineNum">    1868</span>              :    */</span>
<span id="L1869"><span class="lineNum">    1869</span> <span class="tlaGNC">       40076 :   void set_allow_tensor_metadata_change(bool value) {</span></span>
<span id="L1870"><span class="lineNum">    1870</span>              :     // TODO: at some point, we should kill this field completely.</span>
<span id="L1871"><span class="lineNum">    1871</span> <span class="tlaGNC">       40076 :     allow_tensor_metadata_change_ = true;</span></span>
<span id="L1872"><span class="lineNum">    1872</span> <span class="tlaGNC">       40076 :   }</span></span>
<span id="L1873"><span class="lineNum">    1873</span>              : </span>
<span id="L1874"><span class="lineNum">    1874</span>              :   /**</span>
<span id="L1875"><span class="lineNum">    1875</span>              :    * True if a tensor allows changes to its metadata (e.g. sizes / strides /</span>
<span id="L1876"><span class="lineNum">    1876</span>              :    * storage / storage_offset). See NOTE [ Metadata Change for a Detached Tensor</span>
<span id="L1877"><span class="lineNum">    1877</span>              :    * ] for details.</span>
<span id="L1878"><span class="lineNum">    1878</span>              :    */</span>
<span id="L1879"><span class="lineNum">    1879</span>              :   bool allow_tensor_metadata_change() const {</span>
<span id="L1880"><span class="lineNum">    1880</span>              :     return allow_tensor_metadata_change_;</span>
<span id="L1881"><span class="lineNum">    1881</span>              :   }</span>
<span id="L1882"><span class="lineNum">    1882</span>              : </span>
<span id="L1883"><span class="lineNum">    1883</span>              :   /**</span>
<span id="L1884"><span class="lineNum">    1884</span>              :    * Set the pointer to autograd metadata.</span>
<span id="L1885"><span class="lineNum">    1885</span>              :    */</span>
<span id="L1886"><span class="lineNum">    1886</span>              :   void set_autograd_meta(</span>
<span id="L1887"><span class="lineNum">    1887</span>              :       std::unique_ptr&lt;c10::AutogradMetaInterface&gt; autograd_meta);</span>
<span id="L1888"><span class="lineNum">    1888</span>              : </span>
<span id="L1889"><span class="lineNum">    1889</span>              :   /**</span>
<span id="L1890"><span class="lineNum">    1890</span>              :    * Return the pointer to autograd metadata.  May return nullptr if the</span>
<span id="L1891"><span class="lineNum">    1891</span>              :    * tensor does not track gradients.</span>
<span id="L1892"><span class="lineNum">    1892</span>              :    */</span>
<span id="L1893"><span class="lineNum">    1893</span>              :   c10::AutogradMetaInterface* autograd_meta() const;</span>
<span id="L1894"><span class="lineNum">    1894</span>              : </span>
<span id="L1895"><span class="lineNum">    1895</span>              :   /**</span>
<span id="L1896"><span class="lineNum">    1896</span>              :    * Set the pointer to named tensor metadata.</span>
<span id="L1897"><span class="lineNum">    1897</span>              :    */</span>
<span id="L1898"><span class="lineNum">    1898</span>              :   void set_named_tensor_meta(</span>
<span id="L1899"><span class="lineNum">    1899</span>              :       std::unique_ptr&lt;c10::NamedTensorMetaInterface&gt; named_tensor_meta) {</span>
<span id="L1900"><span class="lineNum">    1900</span>              :     TORCH_WARN_ONCE(</span>
<span id="L1901"><span class="lineNum">    1901</span>              :         &quot;Named tensors and all their associated APIs are an experimental feature &quot;,</span>
<span id="L1902"><span class="lineNum">    1902</span>              :         &quot;and subject to change. Please do not use them for anything important &quot;,</span>
<span id="L1903"><span class="lineNum">    1903</span>              :         &quot;until they are released as stable.&quot;);</span>
<span id="L1904"><span class="lineNum">    1904</span>              : #ifdef DEBUG</span>
<span id="L1905"><span class="lineNum">    1905</span>              :     if (named_tensor_meta) {</span>
<span id="L1906"><span class="lineNum">    1906</span>              :       TORCH_INTERNAL_ASSERT(named_tensor_meta-&gt;slow_dim() == dim());</span>
<span id="L1907"><span class="lineNum">    1907</span>              :     }</span>
<span id="L1908"><span class="lineNum">    1908</span>              : #endif</span>
<span id="L1909"><span class="lineNum">    1909</span>              :     if (named_tensor_meta) {</span>
<span id="L1910"><span class="lineNum">    1910</span>              :       get_extra_meta().named_tensor_meta_ = std::move(named_tensor_meta);</span>
<span id="L1911"><span class="lineNum">    1911</span>              :       key_set_ = key_set_.add(DispatchKey::Named);</span>
<span id="L1912"><span class="lineNum">    1912</span>              :     } else {</span>
<span id="L1913"><span class="lineNum">    1913</span>              :       if (extra_meta_) {</span>
<span id="L1914"><span class="lineNum">    1914</span>              :         extra_meta_-&gt;named_tensor_meta_ = nullptr;</span>
<span id="L1915"><span class="lineNum">    1915</span>              :       }</span>
<span id="L1916"><span class="lineNum">    1916</span>              :       key_set_ = key_set_.remove(DispatchKey::Named);</span>
<span id="L1917"><span class="lineNum">    1917</span>              :     }</span>
<span id="L1918"><span class="lineNum">    1918</span>              :   }</span>
<span id="L1919"><span class="lineNum">    1919</span>              : </span>
<span id="L1920"><span class="lineNum">    1920</span>              :   void set_python_dispatch(bool k) {</span>
<span id="L1921"><span class="lineNum">    1921</span>              :     if (k) {</span>
<span id="L1922"><span class="lineNum">    1922</span>              :       key_set_ = key_set_.add(c10::python_ks);</span>
<span id="L1923"><span class="lineNum">    1923</span>              :     } else {</span>
<span id="L1924"><span class="lineNum">    1924</span>              :       key_set_ = key_set_ - c10::python_ks;</span>
<span id="L1925"><span class="lineNum">    1925</span>              :     }</span>
<span id="L1926"><span class="lineNum">    1926</span>              :   }</span>
<span id="L1927"><span class="lineNum">    1927</span>              : </span>
<span id="L1928"><span class="lineNum">    1928</span>              :   bool is_python_dispatch() const {</span>
<span id="L1929"><span class="lineNum">    1929</span>              :     return key_set_.has_all(c10::python_ks);</span>
<span id="L1930"><span class="lineNum">    1930</span>              :   }</span>
<span id="L1931"><span class="lineNum">    1931</span>              : </span>
<span id="L1932"><span class="lineNum">    1932</span>              :   /**</span>
<span id="L1933"><span class="lineNum">    1933</span>              :    * Return the pointer to named tensor metadata.</span>
<span id="L1934"><span class="lineNum">    1934</span>              :    */</span>
<span id="L1935"><span class="lineNum">    1935</span>              :   const c10::NamedTensorMetaInterface* named_tensor_meta() const {</span>
<span id="L1936"><span class="lineNum">    1936</span>              :     if (!extra_meta_) {</span>
<span id="L1937"><span class="lineNum">    1937</span>              :       return nullptr;</span>
<span id="L1938"><span class="lineNum">    1938</span>              :     }</span>
<span id="L1939"><span class="lineNum">    1939</span>              :     return extra_meta_-&gt;named_tensor_meta_.get();</span>
<span id="L1940"><span class="lineNum">    1940</span>              :   }</span>
<span id="L1941"><span class="lineNum">    1941</span>              : </span>
<span id="L1942"><span class="lineNum">    1942</span>              :   c10::NamedTensorMetaInterface* named_tensor_meta() {</span>
<span id="L1943"><span class="lineNum">    1943</span>              :     if (!extra_meta_) {</span>
<span id="L1944"><span class="lineNum">    1944</span>              :       return nullptr;</span>
<span id="L1945"><span class="lineNum">    1945</span>              :     }</span>
<span id="L1946"><span class="lineNum">    1946</span>              :     return extra_meta_-&gt;named_tensor_meta_.get();</span>
<span id="L1947"><span class="lineNum">    1947</span>              :   }</span>
<span id="L1948"><span class="lineNum">    1948</span>              : </span>
<span id="L1949"><span class="lineNum">    1949</span>              :   bool has_named_tensor_meta() const {</span>
<span id="L1950"><span class="lineNum">    1950</span>              :     if (!extra_meta_) {</span>
<span id="L1951"><span class="lineNum">    1951</span>              :       return false;</span>
<span id="L1952"><span class="lineNum">    1952</span>              :     }</span>
<span id="L1953"><span class="lineNum">    1953</span>              :     return extra_meta_-&gt;named_tensor_meta_ != nullptr;</span>
<span id="L1954"><span class="lineNum">    1954</span>              :   }</span>
<span id="L1955"><span class="lineNum">    1955</span>              : </span>
<span id="L1956"><span class="lineNum">    1956</span>              :   // NOTE [ TensorImpl Shallow-Copying ]</span>
<span id="L1957"><span class="lineNum">    1957</span>              :   //</span>
<span id="L1958"><span class="lineNum">    1958</span>              :   // TensorImpl shallow-copying is used when we want to have two Variables share</span>
<span id="L1959"><span class="lineNum">    1959</span>              :   // the same tensor metadata (e.g. sizes / strides / storage pointer /</span>
<span id="L1960"><span class="lineNum">    1960</span>              :   // storage_offset), but each with a different autograd history. Example call</span>
<span id="L1961"><span class="lineNum">    1961</span>              :   // sites:</span>
<span id="L1962"><span class="lineNum">    1962</span>              :   //</span>
<span id="L1963"><span class="lineNum">    1963</span>              :   // 1. `var_detached = var.detach()` uses `shallow_copy_and_detach()` to create</span>
<span id="L1964"><span class="lineNum">    1964</span>              :   // `var_detached` that shares the same tensor metadata with `var`, but with a</span>
<span id="L1965"><span class="lineNum">    1965</span>              :   // completely new autograd history.</span>
<span id="L1966"><span class="lineNum">    1966</span>              :   // 2. `var.set_data(tensor)` uses `shallow_copy_from()` to copy tensor</span>
<span id="L1967"><span class="lineNum">    1967</span>              :   // metadata from `tensor` into `var`, while keeping `var`'s original</span>
<span id="L1968"><span class="lineNum">    1968</span>              :   // AutogradMeta.</span>
<span id="L1969"><span class="lineNum">    1969</span>              :   //</span>
<span id="L1970"><span class="lineNum">    1970</span>              :   // Functions that shallow-copy a TensorImpl (such as</span>
<span id="L1971"><span class="lineNum">    1971</span>              :   // `shallow_copy_and_detach()` / `shallow_copy_from()` /</span>
<span id="L1972"><span class="lineNum">    1972</span>              :   // `copy_tensor_metadata()`) copy the tensor metadata fields (e.g. sizes /</span>
<span id="L1973"><span class="lineNum">    1973</span>              :   // strides / storage pointer / storage_offset) by value. However, the</span>
<span id="L1974"><span class="lineNum">    1974</span>              :   // following fields are not copied:</span>
<span id="L1975"><span class="lineNum">    1975</span>              :   //</span>
<span id="L1976"><span class="lineNum">    1976</span>              :   // 1. the AutogradMeta pointer, because it is unique for each Variable.</span>
<span id="L1977"><span class="lineNum">    1977</span>              :   // 2. the version counter, because the destination TensorImpl's version</span>
<span id="L1978"><span class="lineNum">    1978</span>              :   // counter is either set to the passed-in `version_counter` (in</span>
<span id="L1979"><span class="lineNum">    1979</span>              :   // `shallow_copy_and_detach()` and `copy_tensor_metadata()`), or it is kept</span>
<span id="L1980"><span class="lineNum">    1980</span>              :   // intact (in `shallow_copy_from()`). See NOTE [ Version Counter Sharing ] for</span>
<span id="L1981"><span class="lineNum">    1981</span>              :   // details.</span>
<span id="L1982"><span class="lineNum">    1982</span>              :   //</span>
<span id="L1983"><span class="lineNum">    1983</span>              :   // In `shallow_copy_and_detach()` and `copy_tensor_metadata()`, the passed-in</span>
<span id="L1984"><span class="lineNum">    1984</span>              :   // `allow_tensor_metadata_change` determines whether the TensorImpl</span>
<span id="L1985"><span class="lineNum">    1985</span>              :   // shallow-copy allows changes to its metadata (e.g. sizes / strides / storage</span>
<span id="L1986"><span class="lineNum">    1986</span>              :   // / storage_offset). See NOTE [ Metadata Change for a Detached Tensor ] for</span>
<span id="L1987"><span class="lineNum">    1987</span>              :   // details.</span>
<span id="L1988"><span class="lineNum">    1988</span>              :   //</span>
<span id="L1989"><span class="lineNum">    1989</span>              :   // In `shallow_copy_from()`, we don't check the destination TensorImpl's</span>
<span id="L1990"><span class="lineNum">    1990</span>              :   // `allow_tensor_metadata_change_`, because `shallow_copy_from()` is used for</span>
<span id="L1991"><span class="lineNum">    1991</span>              :   // implementing functions such as `var.set_data(tensor)`, which changes</span>
<span id="L1992"><span class="lineNum">    1992</span>              :   // `var`'s tensor metadata and expects its `allow_tensor_metadata_change_` to</span>
<span id="L1993"><span class="lineNum">    1993</span>              :   // be ignored.</span>
<span id="L1994"><span class="lineNum">    1994</span>              : </span>
<span id="L1995"><span class="lineNum">    1995</span>              :   /**</span>
<span id="L1996"><span class="lineNum">    1996</span>              :    * One TensorImpl can be copied to another TensorImpl if they have the same</span>
<span id="L1997"><span class="lineNum">    1997</span>              :    * DispatchKeySet. The only two special cases (for legacy reason) are:</span>
<span id="L1998"><span class="lineNum">    1998</span>              :    * CPU is compatible with CUDA and SparseCPU is</span>
<span id="L1999"><span class="lineNum">    1999</span>              :    * compatible with SparseCUDA.</span>
<span id="L2000"><span class="lineNum">    2000</span>              :    */</span>
<span id="L2001"><span class="lineNum">    2001</span>              :   inline bool has_compatible_shallow_copy_type(DispatchKeySet from) {</span>
<span id="L2002"><span class="lineNum">    2002</span>              :     auto is_dense = [](DispatchKeySet ts) {</span>
<span id="L2003"><span class="lineNum">    2003</span>              :       constexpr auto dense_backends = DispatchKeySet(</span>
<span id="L2004"><span class="lineNum">    2004</span>              :           {BackendComponent::CPUBit,</span>
<span id="L2005"><span class="lineNum">    2005</span>              :            BackendComponent::CUDABit,</span>
<span id="L2006"><span class="lineNum">    2006</span>              :            BackendComponent::MPSBit,</span>
<span id="L2007"><span class="lineNum">    2007</span>              :            BackendComponent::HIPBit,</span>
<span id="L2008"><span class="lineNum">    2008</span>              :            BackendComponent::XPUBit,</span>
<span id="L2009"><span class="lineNum">    2009</span>              :            BackendComponent::HPUBit});</span>
<span id="L2010"><span class="lineNum">    2010</span>              :       constexpr auto dense_k = DispatchKeySet(DispatchKey::Dense);</span>
<span id="L2011"><span class="lineNum">    2011</span>              :       return ts.has_any(dense_k) &amp;&amp; ts.has_any(dense_backends);</span>
<span id="L2012"><span class="lineNum">    2012</span>              :     };</span>
<span id="L2013"><span class="lineNum">    2013</span>              :     auto is_sparse = [](DispatchKeySet ts) {</span>
<span id="L2014"><span class="lineNum">    2014</span>              :       constexpr auto sparse_backends = DispatchKeySet(</span>
<span id="L2015"><span class="lineNum">    2015</span>              :           {BackendComponent::CPUBit,</span>
<span id="L2016"><span class="lineNum">    2016</span>              :            BackendComponent::CUDABit,</span>
<span id="L2017"><span class="lineNum">    2017</span>              :            BackendComponent::HIPBit,</span>
<span id="L2018"><span class="lineNum">    2018</span>              :            BackendComponent::XPUBit});</span>
<span id="L2019"><span class="lineNum">    2019</span>              :       constexpr auto sparse_k = DispatchKeySet(DispatchKey::Sparse);</span>
<span id="L2020"><span class="lineNum">    2020</span>              :       return ts.has_any(sparse_k) &amp;&amp; ts.has_any(sparse_backends);</span>
<span id="L2021"><span class="lineNum">    2021</span>              :     };</span>
<span id="L2022"><span class="lineNum">    2022</span>              :     return (key_set_ == from) || (is_dense(key_set_) &amp;&amp; is_dense(from)) ||</span>
<span id="L2023"><span class="lineNum">    2023</span>              :         (is_sparse(key_set_) &amp;&amp; is_sparse(from));</span>
<span id="L2024"><span class="lineNum">    2024</span>              :   }</span>
<span id="L2025"><span class="lineNum">    2025</span>              : </span>
<span id="L2026"><span class="lineNum">    2026</span>              :  private:</span>
<span id="L2027"><span class="lineNum">    2027</span>              :   template &lt;typename VariableVersion&gt;</span>
<span id="L2028"><span class="lineNum">    2028</span>              :   c10::intrusive_ptr&lt;TensorImpl&gt; shallow_copy_and_detach_core(</span>
<span id="L2029"><span class="lineNum">    2029</span>              :       VariableVersion&amp;&amp; version_counter,</span>
<span id="L2030"><span class="lineNum">    2030</span>              :       bool allow_tensor_metadata_change) const;</span>
<span id="L2031"><span class="lineNum">    2031</span>              : </span>
<span id="L2032"><span class="lineNum">    2032</span>              :  public:</span>
<span id="L2033"><span class="lineNum">    2033</span>              :   /**</span>
<span id="L2034"><span class="lineNum">    2034</span>              :    * Return a TensorImpl that is a shallow-copy of this TensorImpl.</span>
<span id="L2035"><span class="lineNum">    2035</span>              :    *</span>
<span id="L2036"><span class="lineNum">    2036</span>              :    * For usage of `version_counter` and `allow_tensor_metadata_change`,</span>
<span id="L2037"><span class="lineNum">    2037</span>              :    * see NOTE [ TensorImpl Shallow-Copying ].</span>
<span id="L2038"><span class="lineNum">    2038</span>              :    */</span>
<span id="L2039"><span class="lineNum">    2039</span>              :   virtual c10::intrusive_ptr&lt;TensorImpl&gt; shallow_copy_and_detach(</span>
<span id="L2040"><span class="lineNum">    2040</span>              :       const c10::VariableVersion&amp; version_counter,</span>
<span id="L2041"><span class="lineNum">    2041</span>              :       bool allow_tensor_metadata_change) const;</span>
<span id="L2042"><span class="lineNum">    2042</span>              : </span>
<span id="L2043"><span class="lineNum">    2043</span>              :   /**</span>
<span id="L2044"><span class="lineNum">    2044</span>              :    * Return a TensorImpl that is a shallow-copy of this TensorImpl.</span>
<span id="L2045"><span class="lineNum">    2045</span>              :    *</span>
<span id="L2046"><span class="lineNum">    2046</span>              :    * For usage of `version_counter` and `allow_tensor_metadata_change`,</span>
<span id="L2047"><span class="lineNum">    2047</span>              :    * see NOTE [ TensorImpl Shallow-Copying ].</span>
<span id="L2048"><span class="lineNum">    2048</span>              :    */</span>
<span id="L2049"><span class="lineNum">    2049</span>              :   virtual c10::intrusive_ptr&lt;TensorImpl&gt; shallow_copy_and_detach(</span>
<span id="L2050"><span class="lineNum">    2050</span>              :       c10::VariableVersion&amp;&amp; version_counter,</span>
<span id="L2051"><span class="lineNum">    2051</span>              :       bool allow_tensor_metadata_change) const;</span>
<span id="L2052"><span class="lineNum">    2052</span>              : </span>
<span id="L2053"><span class="lineNum">    2053</span>              :   /**</span>
<span id="L2054"><span class="lineNum">    2054</span>              :    * Shallow-copies data from another TensorImpl into this TensorImpl.</span>
<span id="L2055"><span class="lineNum">    2055</span>              :    *</span>
<span id="L2056"><span class="lineNum">    2056</span>              :    * For why this function doesn't check this TensorImpl's</span>
<span id="L2057"><span class="lineNum">    2057</span>              :    * `allow_tensor_metadata_change_`, see NOTE [ TensorImpl Shallow-Copying ].</span>
<span id="L2058"><span class="lineNum">    2058</span>              :    */</span>
<span id="L2059"><span class="lineNum">    2059</span>              :   virtual void shallow_copy_from(const c10::intrusive_ptr&lt;TensorImpl&gt;&amp; impl) {</span>
<span id="L2060"><span class="lineNum">    2060</span>              :     copy_tensor_metadata(</span>
<span id="L2061"><span class="lineNum">    2061</span>              :         /*src_impl=*/impl.get(),</span>
<span id="L2062"><span class="lineNum">    2062</span>              :         /*dest_impl=*/this,</span>
<span id="L2063"><span class="lineNum">    2063</span>              :         /*version_counter=*/version_counter(),</span>
<span id="L2064"><span class="lineNum">    2064</span>              :         /*allow_tensor_metadata_change=*/allow_tensor_metadata_change());</span>
<span id="L2065"><span class="lineNum">    2065</span>              :     refresh_numel();</span>
<span id="L2066"><span class="lineNum">    2066</span>              :     refresh_contiguous();</span>
<span id="L2067"><span class="lineNum">    2067</span>              :   }</span>
<span id="L2068"><span class="lineNum">    2068</span>              : </span>
<span id="L2069"><span class="lineNum">    2069</span>              :   // Inference tensor doesn't have version counter,</span>
<span id="L2070"><span class="lineNum">    2070</span>              :   // set_version_counter is no-op for them.</span>
<span id="L2071"><span class="lineNum">    2071</span>              :   void set_version_counter(const c10::VariableVersion&amp; version_counter) {</span>
<span id="L2072"><span class="lineNum">    2072</span>              :     TORCH_CHECK(</span>
<span id="L2073"><span class="lineNum">    2073</span>              :         !(is_inference() &amp;&amp; version_counter.enabled()),</span>
<span id="L2074"><span class="lineNum">    2074</span>              :         &quot;Cannot set version_counter for inference tensor&quot;);</span>
<span id="L2075"><span class="lineNum">    2075</span>              :     version_counter_ = version_counter;</span>
<span id="L2076"><span class="lineNum">    2076</span>              :   }</span>
<span id="L2077"><span class="lineNum">    2077</span>              : </span>
<span id="L2078"><span class="lineNum">    2078</span>              :   void set_version_counter(c10::VariableVersion&amp;&amp; version_counter) {</span>
<span id="L2079"><span class="lineNum">    2079</span>              :     TORCH_CHECK(</span>
<span id="L2080"><span class="lineNum">    2080</span>              :         !(is_inference() &amp;&amp; version_counter.enabled()),</span>
<span id="L2081"><span class="lineNum">    2081</span>              :         &quot;Cannot set version_counter for inference tensor&quot;);</span>
<span id="L2082"><span class="lineNum">    2082</span>              :     version_counter_ = std::move(version_counter);</span>
<span id="L2083"><span class="lineNum">    2083</span>              :   }</span>
<span id="L2084"><span class="lineNum">    2084</span>              : </span>
<span id="L2085"><span class="lineNum">    2085</span>              :   const c10::VariableVersion&amp; version_counter() const noexcept {</span>
<span id="L2086"><span class="lineNum">    2086</span>              :     return version_counter_;</span>
<span id="L2087"><span class="lineNum">    2087</span>              :   }</span>
<span id="L2088"><span class="lineNum">    2088</span>              : </span>
<span id="L2089"><span class="lineNum">    2089</span>              :   void bump_version() {</span>
<span id="L2090"><span class="lineNum">    2090</span>              :     version_counter_.bump();</span>
<span id="L2091"><span class="lineNum">    2091</span>              :   }</span>
<span id="L2092"><span class="lineNum">    2092</span>              : </span>
<span id="L2093"><span class="lineNum">    2093</span>              :   impl::PyObjectSlot* pyobj_slot() {</span>
<span id="L2094"><span class="lineNum">    2094</span>              :     return &amp;pyobj_slot_;</span>
<span id="L2095"><span class="lineNum">    2095</span>              :   }</span>
<span id="L2096"><span class="lineNum">    2096</span>              : </span>
<span id="L2097"><span class="lineNum">    2097</span>              :   const impl::PyObjectSlot* pyobj_slot() const {</span>
<span id="L2098"><span class="lineNum">    2098</span>              :     return &amp;pyobj_slot_;</span>
<span id="L2099"><span class="lineNum">    2099</span>              :   }</span>
<span id="L2100"><span class="lineNum">    2100</span>              : </span>
<span id="L2101"><span class="lineNum">    2101</span>              :  private:</span>
<span id="L2102"><span class="lineNum">    2102</span>              :   // See NOTE [c10::optional operator usage in CUDA]</span>
<span id="L2103"><span class="lineNum">    2103</span>              :   // We probably don't want to expose this publicly until</span>
<span id="L2104"><span class="lineNum">    2104</span>              :   // the note is addressed.</span>
<span id="L2105"><span class="lineNum">    2105</span>              :   c10::optional&lt;c10::Device&gt; device_opt() const {</span>
<span id="L2106"><span class="lineNum">    2106</span>              :     return device_opt_;</span>
<span id="L2107"><span class="lineNum">    2107</span>              :   }</span>
<span id="L2108"><span class="lineNum">    2108</span>              : </span>
<span id="L2109"><span class="lineNum">    2109</span>              :  public:</span>
<span id="L2110"><span class="lineNum">    2110</span>              :   /**</span>
<span id="L2111"><span class="lineNum">    2111</span>              :    * The device type of a Tensor, e.g., DeviceType::CPU or DeviceType::CUDA.</span>
<span id="L2112"><span class="lineNum">    2112</span>              :    */</span>
<span id="L2113"><span class="lineNum">    2113</span>              :   DeviceType device_type() const {</span>
<span id="L2114"><span class="lineNum">    2114</span>              :     // TODO: A useful internal assert would be to show that device_opt_ is null</span>
<span id="L2115"><span class="lineNum">    2115</span>              :     // only if you are an undefined tensor</span>
<span id="L2116"><span class="lineNum">    2116</span>              :     TORCH_CHECK(</span>
<span id="L2117"><span class="lineNum">    2117</span>              :         device_opt_.has_value(),</span>
<span id="L2118"><span class="lineNum">    2118</span>              :         &quot;device_type cannot be run on undefined Tensor&quot;);</span>
<span id="L2119"><span class="lineNum">    2119</span>              :     // See NOTE [c10::optional operator usage in CUDA]</span>
<span id="L2120"><span class="lineNum">    2120</span>              :     return (*device_opt_).type();</span>
<span id="L2121"><span class="lineNum">    2121</span>              :   }</span>
<span id="L2122"><span class="lineNum">    2122</span>              : </span>
<span id="L2123"><span class="lineNum">    2123</span>              :   /**</span>
<span id="L2124"><span class="lineNum">    2124</span>              :    * @brief Extends the outer-most dimension of this tensor by num elements,</span>
<span id="L2125"><span class="lineNum">    2125</span>              :    * preserving the existing data.</span>
<span id="L2126"><span class="lineNum">    2126</span>              :    *</span>
<span id="L2127"><span class="lineNum">    2127</span>              :    * The underlying data may be reallocated in order to accommodate the new</span>
<span id="L2128"><span class="lineNum">    2128</span>              :    * elements, in which case this tensors' capacity is grown at a factor of</span>
<span id="L2129"><span class="lineNum">    2129</span>              :    * growthPct. This ensures that Extend runs on an amortized O(1) time</span>
<span id="L2130"><span class="lineNum">    2130</span>              :    * complexity.</span>
<span id="L2131"><span class="lineNum">    2131</span>              :    *</span>
<span id="L2132"><span class="lineNum">    2132</span>              :    * This op is auto-asynchronous if the underlying device (CUDA) supports it.</span>
<span id="L2133"><span class="lineNum">    2133</span>              :    */</span>
<span id="L2134"><span class="lineNum">    2134</span>              :   void Extend(int64_t num, float growthPct);</span>
<span id="L2135"><span class="lineNum">    2135</span>              : </span>
<span id="L2136"><span class="lineNum">    2136</span>              :   /**</span>
<span id="L2137"><span class="lineNum">    2137</span>              :    * @brief Reserve space for the underlying tensor.</span>
<span id="L2138"><span class="lineNum">    2138</span>              :    *</span>
<span id="L2139"><span class="lineNum">    2139</span>              :    * This must be called after Resize(), since we only specify the first</span>
<span id="L2140"><span class="lineNum">    2140</span>              :    * dimension This does not copy over the old data to the newly allocated space</span>
<span id="L2141"><span class="lineNum">    2141</span>              :    */</span>
<span id="L2142"><span class="lineNum">    2142</span>              :   void ReserveSpace(int64_t outer_dim);</span>
<span id="L2143"><span class="lineNum">    2143</span>              : </span>
<span id="L2144"><span class="lineNum">    2144</span>              :   /**</span>
<span id="L2145"><span class="lineNum">    2145</span>              :    * @brief Resizes a tensor.</span>
<span id="L2146"><span class="lineNum">    2146</span>              :    *</span>
<span id="L2147"><span class="lineNum">    2147</span>              :    * Resize takes in a vector of ints specifying the dimensions of the tensor.</span>
<span id="L2148"><span class="lineNum">    2148</span>              :    * You can pass in an empty vector to specify that it is a scalar (i.e.</span>
<span id="L2149"><span class="lineNum">    2149</span>              :    * containing one single item).</span>
<span id="L2150"><span class="lineNum">    2150</span>              :    *</span>
<span id="L2151"><span class="lineNum">    2151</span>              :    * The underlying storage may be deleted after calling Resize: if the new</span>
<span id="L2152"><span class="lineNum">    2152</span>              :    * shape leads to a different number of items in the tensor, the old memory</span>
<span id="L2153"><span class="lineNum">    2153</span>              :    * is deleted and new memory will be allocated next time you call</span>
<span id="L2154"><span class="lineNum">    2154</span>              :    * mutable_data(). However, if the shape is different but the total number of</span>
<span id="L2155"><span class="lineNum">    2155</span>              :    * items is the same, the underlying storage is kept.</span>
<span id="L2156"><span class="lineNum">    2156</span>              :    *</span>
<span id="L2157"><span class="lineNum">    2157</span>              :    * This method respects caffe2_keep_on_shrink.  Consult the internal logic</span>
<span id="L2158"><span class="lineNum">    2158</span>              :    * of this method to see exactly under what circumstances this flag matters.</span>
<span id="L2159"><span class="lineNum">    2159</span>              :    */</span>
<span id="L2160"><span class="lineNum">    2160</span>              :   template &lt;typename... Ts&gt;</span>
<span id="L2161"><span class="lineNum">    2161</span>              :   void Resize(Ts... dim_source) {</span>
<span id="L2162"><span class="lineNum">    2162</span>              :     bool size_changed = SetDims(dim_source...);</span>
<span id="L2163"><span class="lineNum">    2163</span>              :     if (size_changed) {</span>
<span id="L2164"><span class="lineNum">    2164</span>              :       HandleResize();</span>
<span id="L2165"><span class="lineNum">    2165</span>              :     }</span>
<span id="L2166"><span class="lineNum">    2166</span>              :   }</span>
<span id="L2167"><span class="lineNum">    2167</span>              : </span>
<span id="L2168"><span class="lineNum">    2168</span>              :   template &lt;typename T&gt;</span>
<span id="L2169"><span class="lineNum">    2169</span>              :   void Resize(const std::vector&lt;T&gt;&amp; dim_source) {</span>
<span id="L2170"><span class="lineNum">    2170</span>              :     Resize(ArrayRef&lt;T&gt;(dim_source));</span>
<span id="L2171"><span class="lineNum">    2171</span>              :   }</span>
<span id="L2172"><span class="lineNum">    2172</span>              : </span>
<span id="L2173"><span class="lineNum">    2173</span>              :   /**</span>
<span id="L2174"><span class="lineNum">    2174</span>              :    * Resizes the tensor without touching underlying storage.</span>
<span id="L2175"><span class="lineNum">    2175</span>              :    * This requires the total size of the tensor to remains constant.</span>
<span id="L2176"><span class="lineNum">    2176</span>              :    */</span>
<span id="L2177"><span class="lineNum">    2177</span>              :   void Reshape(const std::vector&lt;int64_t&gt;&amp; dims);</span>
<span id="L2178"><span class="lineNum">    2178</span>              : </span>
<span id="L2179"><span class="lineNum">    2179</span>              :   /**</span>
<span id="L2180"><span class="lineNum">    2180</span>              :    * Release whatever memory the tensor was holding but keep size and type</span>
<span id="L2181"><span class="lineNum">    2181</span>              :    * information. Subsequent call to mutable_data will trigger new memory</span>
<span id="L2182"><span class="lineNum">    2182</span>              :    * allocation.</span>
<span id="L2183"><span class="lineNum">    2183</span>              :    */</span>
<span id="L2184"><span class="lineNum">    2184</span>              :   void FreeMemory();</span>
<span id="L2185"><span class="lineNum">    2185</span>              : </span>
<span id="L2186"><span class="lineNum">    2186</span>              :   /**</span>
<span id="L2187"><span class="lineNum">    2187</span>              :    * @brief Shares the data with another tensor.</span>
<span id="L2188"><span class="lineNum">    2188</span>              :    *</span>
<span id="L2189"><span class="lineNum">    2189</span>              :    * To share data between two tensors, the sizes of the two tensors must be</span>
<span id="L2190"><span class="lineNum">    2190</span>              :    * equal already. The reason we do not implicitly do a Resize to make the two</span>
<span id="L2191"><span class="lineNum">    2191</span>              :    * tensors have the same shape is that we want to allow tensors of different</span>
<span id="L2192"><span class="lineNum">    2192</span>              :    * shapes but the same number of items to still be able to share data. This</span>
<span id="L2193"><span class="lineNum">    2193</span>              :    * allows one to e.g. have a n-dimensional Tensor and a flattened version</span>
<span id="L2194"><span class="lineNum">    2194</span>              :    * sharing the same underlying storage.</span>
<span id="L2195"><span class="lineNum">    2195</span>              :    *</span>
<span id="L2196"><span class="lineNum">    2196</span>              :    * The source tensor should already have its data allocated.</span>
<span id="L2197"><span class="lineNum">    2197</span>              :    */</span>
<span id="L2198"><span class="lineNum">    2198</span>              :   // To be deprecated</span>
<span id="L2199"><span class="lineNum">    2199</span>              :   void ShareData(const TensorImpl&amp; src);</span>
<span id="L2200"><span class="lineNum">    2200</span>              : </span>
<span id="L2201"><span class="lineNum">    2201</span>              :   void ShareExternalPointer(</span>
<span id="L2202"><span class="lineNum">    2202</span>              :       DataPtr&amp;&amp; data_ptr,</span>
<span id="L2203"><span class="lineNum">    2203</span>              :       const caffe2::TypeMeta data_type,</span>
<span id="L2204"><span class="lineNum">    2204</span>              :       size_t size_bytes);</span>
<span id="L2205"><span class="lineNum">    2205</span>              : </span>
<span id="L2206"><span class="lineNum">    2206</span>              :   /**</span>
<span id="L2207"><span class="lineNum">    2207</span>              :    * Returns a mutable raw pointer of the underlying storage. Since we will need</span>
<span id="L2208"><span class="lineNum">    2208</span>              :    * to know the type of the data for allocation, a TypeMeta object is passed in</span>
<span id="L2209"><span class="lineNum">    2209</span>              :    * to specify the necessary information. This is conceptually equivalent of</span>
<span id="L2210"><span class="lineNum">    2210</span>              :    * calling mutable_data&lt;T&gt;() where the TypeMeta parameter meta is derived from</span>
<span id="L2211"><span class="lineNum">    2211</span>              :    * the type T. This function differs from mutable_data&lt;T&gt;() in the sense that</span>
<span id="L2212"><span class="lineNum">    2212</span>              :    * the type T can be specified during runtime via the TypeMeta object.</span>
<span id="L2213"><span class="lineNum">    2213</span>              :    *</span>
<span id="L2214"><span class="lineNum">    2214</span>              :    * If the existing data does not match the desired type, it will be deleted</span>
<span id="L2215"><span class="lineNum">    2215</span>              :    * and a new storage will be created.</span>
<span id="L2216"><span class="lineNum">    2216</span>              :    */</span>
<span id="L2217"><span class="lineNum">    2217</span>              :   inline void* raw_mutable_data(const caffe2::TypeMeta&amp; meta) {</span>
<span id="L2218"><span class="lineNum">    2218</span>              :     // For 0-size tensors it's fine to return any pointer (including nullptr)</span>
<span id="L2219"><span class="lineNum">    2219</span>              :     if (data_type_ == meta &amp;&amp; storage_initialized()) {</span>
<span id="L2220"><span class="lineNum">    2220</span>              :       return static_cast&lt;void*&gt;(</span>
<span id="L2221"><span class="lineNum">    2221</span>              :           static_cast&lt;char*&gt;(storage_.mutable_data()) +</span>
<span id="L2222"><span class="lineNum">    2222</span>              :           storage_offset_ * meta.itemsize());</span>
<span id="L2223"><span class="lineNum">    2223</span>              :     } else {</span>
<span id="L2224"><span class="lineNum">    2224</span>              :       bool had_special_dtor = data_type_.placementDelete() != nullptr;</span>
<span id="L2225"><span class="lineNum">    2225</span>              :       storage_offset_ = 0;</span>
<span id="L2226"><span class="lineNum">    2226</span>              :       data_type_ = meta;</span>
<span id="L2227"><span class="lineNum">    2227</span>              :       // NB: device is not changed</span>
<span id="L2228"><span class="lineNum">    2228</span>              : </span>
<span id="L2229"><span class="lineNum">    2229</span>              :       // We can reuse the existing buffer if the current data does not have</span>
<span id="L2230"><span class="lineNum">    2230</span>              :       // a special destructor and the new data doesn't have a special</span>
<span id="L2231"><span class="lineNum">    2231</span>              :       // constructor.</span>
<span id="L2232"><span class="lineNum">    2232</span>              :       if (numel_ == 0 ||</span>
<span id="L2233"><span class="lineNum">    2233</span>              :           (meta.placementNew() == nullptr &amp;&amp; !had_special_dtor &amp;&amp;</span>
<span id="L2234"><span class="lineNum">    2234</span>              :            (storage_.nbytes() &gt;= (numel_ * data_type_.itemsize())))) {</span>
<span id="L2235"><span class="lineNum">    2235</span>              :         TORCH_INTERNAL_ASSERT(</span>
<span id="L2236"><span class="lineNum">    2236</span>              :             storage_offset_ == 0); // because we just reallocated</span>
<span id="L2237"><span class="lineNum">    2237</span>              :         return storage_.mutable_data();</span>
<span id="L2238"><span class="lineNum">    2238</span>              :       }</span>
<span id="L2239"><span class="lineNum">    2239</span>              :       const Allocator* allocator = storage_.allocator();</span>
<span id="L2240"><span class="lineNum">    2240</span>              :       // Storage might have nullptr allocator in rare cases, for example, if</span>
<span id="L2241"><span class="lineNum">    2241</span>              :       // an external memory segment has been wrapped with Tensor and we don't</span>
<span id="L2242"><span class="lineNum">    2242</span>              :       // know how to reallocate it. However, in order to preserve legacy C2</span>
<span id="L2243"><span class="lineNum">    2243</span>              :       // behavior, we allow reallocating the memory using default allocator.</span>
<span id="L2244"><span class="lineNum">    2244</span>              :       if (allocator == nullptr) {</span>
<span id="L2245"><span class="lineNum">    2245</span>              :         allocator = GetAllocator(storage_.device_type());</span>
<span id="L2246"><span class="lineNum">    2246</span>              :       }</span>
<span id="L2247"><span class="lineNum">    2247</span>              :       if (meta.placementNew()) {</span>
<span id="L2248"><span class="lineNum">    2248</span>              :         // For types that need placement new, we will call it, as well as</span>
<span id="L2249"><span class="lineNum">    2249</span>              :         // making sure that when the data is freed, it calls the right</span>
<span id="L2250"><span class="lineNum">    2250</span>              :         // destruction procedure.</span>
<span id="L2251"><span class="lineNum">    2251</span>              :         auto size = numel_;</span>
<span id="L2252"><span class="lineNum">    2252</span>              :         auto dtor = data_type_.placementDelete();</span>
<span id="L2253"><span class="lineNum">    2253</span>              :         auto data_ptr = allocator-&gt;allocate(numel_ * data_type_.itemsize());</span>
<span id="L2254"><span class="lineNum">    2254</span>              :         storage_.set_data_ptr_noswap(PlacementDeleteContext::makeDataPtr(</span>
<span id="L2255"><span class="lineNum">    2255</span>              :             std::move(data_ptr), dtor, size, storage_.device()));</span>
<span id="L2256"><span class="lineNum">    2256</span>              :         data_type_.placementNew()(storage_.mutable_data(), numel_);</span>
<span id="L2257"><span class="lineNum">    2257</span>              :       } else {</span>
<span id="L2258"><span class="lineNum">    2258</span>              :         // For fundamental type, new and delete is easier.</span>
<span id="L2259"><span class="lineNum">    2259</span>              :         storage_.set_data_ptr_noswap(</span>
<span id="L2260"><span class="lineNum">    2260</span>              :             allocator-&gt;allocate(numel_ * data_type_.itemsize()));</span>
<span id="L2261"><span class="lineNum">    2261</span>              :       }</span>
<span id="L2262"><span class="lineNum">    2262</span>              :       storage_.set_nbytes(numel_ * data_type_.itemsize());</span>
<span id="L2263"><span class="lineNum">    2263</span>              :       TORCH_INTERNAL_ASSERT(</span>
<span id="L2264"><span class="lineNum">    2264</span>              :           storage_offset_ == 0); // because we just reallocated</span>
<span id="L2265"><span class="lineNum">    2265</span>              :       device_opt_ = storage_.device();</span>
<span id="L2266"><span class="lineNum">    2266</span>              :       return storage_.mutable_data();</span>
<span id="L2267"><span class="lineNum">    2267</span>              :     }</span>
<span id="L2268"><span class="lineNum">    2268</span>              :   }</span>
<span id="L2269"><span class="lineNum">    2269</span>              : </span>
<span id="L2270"><span class="lineNum">    2270</span>              :   /**</span>
<span id="L2271"><span class="lineNum">    2271</span>              :    * Returns a typed pointer of the underlying storage.</span>
<span id="L2272"><span class="lineNum">    2272</span>              :    *</span>
<span id="L2273"><span class="lineNum">    2273</span>              :    * For fundamental types, we reuse possible existing storage if there</span>
<span id="L2274"><span class="lineNum">    2274</span>              :    * is sufficient capacity.</span>
<span id="L2275"><span class="lineNum">    2275</span>              :    */</span>
<span id="L2276"><span class="lineNum">    2276</span>              :   template &lt;typename T&gt;</span>
<span id="L2277"><span class="lineNum">    2277</span>              :   inline T* mutable_data() {</span>
<span id="L2278"><span class="lineNum">    2278</span>              :     if (storage_initialized() &amp;&amp; data_type_.Match&lt;T&gt;()) {</span>
<span id="L2279"><span class="lineNum">    2279</span>              :       return static_cast&lt;T*&gt;(storage_.mutable_data()) + storage_offset_;</span>
<span id="L2280"><span class="lineNum">    2280</span>              :     }</span>
<span id="L2281"><span class="lineNum">    2281</span>              :     // Check it here statically - otherwise TypeMeta would throw the runtime</span>
<span id="L2282"><span class="lineNum">    2282</span>              :     // error in attempt to invoke TypeMeta::ctor()</span>
<span id="L2283"><span class="lineNum">    2283</span>              :     static_assert(</span>
<span id="L2284"><span class="lineNum">    2284</span>              :         std::is_default_constructible&lt;T&gt;::value,</span>
<span id="L2285"><span class="lineNum">    2285</span>              :         &quot;Tensor can't hold non-default-constructable types&quot;);</span>
<span id="L2286"><span class="lineNum">    2286</span>              :     return static_cast&lt;T*&gt;(raw_mutable_data(caffe2::TypeMeta::Make&lt;T&gt;()));</span>
<span id="L2287"><span class="lineNum">    2287</span>              :   }</span>
<span id="L2288"><span class="lineNum">    2288</span>              : </span>
<span id="L2289"><span class="lineNum">    2289</span>              :   /**</span>
<span id="L2290"><span class="lineNum">    2290</span>              :    * True if a tensor is storage initialized.  A tensor may become</span>
<span id="L2291"><span class="lineNum">    2291</span>              :    * storage UNINITIALIZED after a Resize() or FreeMemory()</span>
<span id="L2292"><span class="lineNum">    2292</span>              :    */</span>
<span id="L2293"><span class="lineNum">    2293</span>              :   bool storage_initialized() const {</span>
<span id="L2294"><span class="lineNum">    2294</span>              :     TORCH_CHECK(</span>
<span id="L2295"><span class="lineNum">    2295</span>              :         has_storage(),</span>
<span id="L2296"><span class="lineNum">    2296</span>              :         &quot;cannot call storage_initialized on tensor that does not have storage&quot;);</span>
<span id="L2297"><span class="lineNum">    2297</span>              :     return storage_.data() || numel_ == 0;</span>
<span id="L2298"><span class="lineNum">    2298</span>              :   }</span>
<span id="L2299"><span class="lineNum">    2299</span>              : </span>
<span id="L2300"><span class="lineNum">    2300</span>              :   /**</span>
<span id="L2301"><span class="lineNum">    2301</span>              :    * True if a tensor is dtype initialized.  A tensor allocated with</span>
<span id="L2302"><span class="lineNum">    2302</span>              :    * Caffe2-style constructors is dtype uninitialized until the</span>
<span id="L2303"><span class="lineNum">    2303</span>              :    * first time mutable_data&lt;T&gt;() is called.</span>
<span id="L2304"><span class="lineNum">    2304</span>              :    */</span>
<span id="L2305"><span class="lineNum">    2305</span>              :   bool dtype_initialized() const noexcept {</span>
<span id="L2306"><span class="lineNum">    2306</span>              :     return data_type_ != caffe2::TypeMeta();</span>
<span id="L2307"><span class="lineNum">    2307</span>              :   }</span>
<span id="L2308"><span class="lineNum">    2308</span>              : </span>
<span id="L2309"><span class="lineNum">    2309</span>              :   void set_storage_keep_dtype(at::Storage storage) {</span>
<span id="L2310"><span class="lineNum">    2310</span>              :     TORCH_CHECK(</span>
<span id="L2311"><span class="lineNum">    2311</span>              :         allow_tensor_metadata_change(),</span>
<span id="L2312"><span class="lineNum">    2312</span>              :         &quot;set_storage &quot;,</span>
<span id="L2313"><span class="lineNum">    2313</span>              :         err_msg_tensor_metadata_change_not_allowed);</span>
<span id="L2314"><span class="lineNum">    2314</span>              :     storage_ = std::move(storage);</span>
<span id="L2315"><span class="lineNum">    2315</span>              :     device_opt_ = storage_.device();</span>
<span id="L2316"><span class="lineNum">    2316</span>              :   }</span>
<span id="L2317"><span class="lineNum">    2317</span>              : </span>
<span id="L2318"><span class="lineNum">    2318</span>              :   void set_storage_and_dtype(</span>
<span id="L2319"><span class="lineNum">    2319</span>              :       at::Storage storage,</span>
<span id="L2320"><span class="lineNum">    2320</span>              :       const caffe2::TypeMeta data_type) {</span>
<span id="L2321"><span class="lineNum">    2321</span>              :     set_storage_keep_dtype(std::move(storage));</span>
<span id="L2322"><span class="lineNum">    2322</span>              :     data_type_ = data_type;</span>
<span id="L2323"><span class="lineNum">    2323</span>              :   }</span>
<span id="L2324"><span class="lineNum">    2324</span>              : </span>
<span id="L2325"><span class="lineNum">    2325</span>              :   void empty_tensor_restride_symint(MemoryFormat memory_format);</span>
<span id="L2326"><span class="lineNum">    2326</span>              : </span>
<span id="L2327"><span class="lineNum">    2327</span>              :   /**</span>
<span id="L2328"><span class="lineNum">    2328</span>              :    * Set the strides of the tensor to match memory_format</span>
<span id="L2329"><span class="lineNum">    2329</span>              :    *</span>
<span id="L2330"><span class="lineNum">    2330</span>              :    * WARNING: This function doesn't rearrange data and assumes tensor is a</span>
<span id="L2331"><span class="lineNum">    2331</span>              :    * memory contiguous</span>
<span id="L2332"><span class="lineNum">    2332</span>              :    */</span>
<span id="L2333"><span class="lineNum">    2333</span>              :   void empty_tensor_restride(MemoryFormat memory_format) {</span>
<span id="L2334"><span class="lineNum">    2334</span>              :     if (has_symbolic_sizes_strides_) {</span>
<span id="L2335"><span class="lineNum">    2335</span>              :       empty_tensor_restride_symint(memory_format);</span>
<span id="L2336"><span class="lineNum">    2336</span>              :       return;</span>
<span id="L2337"><span class="lineNum">    2337</span>              :     }</span>
<span id="L2338"><span class="lineNum">    2338</span>              : #ifdef DEBUG</span>
<span id="L2339"><span class="lineNum">    2339</span>              :     TORCH_INTERNAL_ASSERT(</span>
<span id="L2340"><span class="lineNum">    2340</span>              :         compute_numel() == numel_,</span>
<span id="L2341"><span class="lineNum">    2341</span>              :         &quot;If you are seeing this error, that means empty_tensor_restride was &quot;</span>
<span id="L2342"><span class="lineNum">    2342</span>              :         &quot;called before setting correct numel&quot;);</span>
<span id="L2343"><span class="lineNum">    2343</span>              : #endif</span>
<span id="L2344"><span class="lineNum">    2344</span>              :     switch (memory_format) {</span>
<span id="L2345"><span class="lineNum">    2345</span>              :       case MemoryFormat::Contiguous: {</span>
<span id="L2346"><span class="lineNum">    2346</span>              :         // dim_ is a virtual call, don't repeat it</span>
<span id="L2347"><span class="lineNum">    2347</span>              :         const auto dim_ = dim();</span>
<span id="L2348"><span class="lineNum">    2348</span>              :         sizes_and_strides_.resize(dim_);</span>
<span id="L2349"><span class="lineNum">    2349</span>              :         if (dim_ &gt; 0) {</span>
<span id="L2350"><span class="lineNum">    2350</span>              :           bool overflowed = false;</span>
<span id="L2351"><span class="lineNum">    2351</span>              :           const auto last_idx = dim_ - 1;</span>
<span id="L2352"><span class="lineNum">    2352</span>              :           sizes_and_strides_.stride_at_unchecked(last_idx) = 1;</span>
<span id="L2353"><span class="lineNum">    2353</span>              :           for (auto i = last_idx - 1; i &gt;= 0; --i) {</span>
<span id="L2354"><span class="lineNum">    2354</span>              :             overflowed |= c10::mul_overflows(</span>
<span id="L2355"><span class="lineNum">    2355</span>              :                 sizes_and_strides_.stride_at_unchecked(i + 1),</span>
<span id="L2356"><span class="lineNum">    2356</span>              :                 std::max&lt;int64_t&gt;(</span>
<span id="L2357"><span class="lineNum">    2357</span>              :                     sizes_and_strides_.size_at_unchecked(i + 1), 1),</span>
<span id="L2358"><span class="lineNum">    2358</span>              :                 std::addressof(sizes_and_strides_.stride_at_unchecked(i)));</span>
<span id="L2359"><span class="lineNum">    2359</span>              :           }</span>
<span id="L2360"><span class="lineNum">    2360</span>              :           TORCH_CHECK(!overflowed, &quot;Stride calculation overflowed&quot;);</span>
<span id="L2361"><span class="lineNum">    2361</span>              :         }</span>
<span id="L2362"><span class="lineNum">    2362</span>              :         break;</span>
<span id="L2363"><span class="lineNum">    2363</span>              :       }</span>
<span id="L2364"><span class="lineNum">    2364</span>              :       case MemoryFormat::ChannelsLast: {</span>
<span id="L2365"><span class="lineNum">    2365</span>              :         TORCH_CHECK(</span>
<span id="L2366"><span class="lineNum">    2366</span>              :             dim() == 4, &quot;required rank 4 tensor to use channels_last format&quot;);</span>
<span id="L2367"><span class="lineNum">    2367</span>              :         set_sizes_and_strides(sizes(), get_channels_last_strides_2d(sizes()));</span>
<span id="L2368"><span class="lineNum">    2368</span>              :         break;</span>
<span id="L2369"><span class="lineNum">    2369</span>              :       }</span>
<span id="L2370"><span class="lineNum">    2370</span>              :       case MemoryFormat::ChannelsLast3d: {</span>
<span id="L2371"><span class="lineNum">    2371</span>              :         TORCH_CHECK(</span>
<span id="L2372"><span class="lineNum">    2372</span>              :             dim() == 5,</span>
<span id="L2373"><span class="lineNum">    2373</span>              :             &quot;required rank 5 tensor to use channels_last_3d format&quot;);</span>
<span id="L2374"><span class="lineNum">    2374</span>              :         set_sizes_and_strides(sizes(), get_channels_last_strides_3d(sizes()));</span>
<span id="L2375"><span class="lineNum">    2375</span>              :         break;</span>
<span id="L2376"><span class="lineNum">    2376</span>              :       }</span>
<span id="L2377"><span class="lineNum">    2377</span>              :       case MemoryFormat::Preserve:</span>
<span id="L2378"><span class="lineNum">    2378</span>              :         TORCH_CHECK(false, &quot;unsupported memory format &quot;, memory_format);</span>
<span id="L2379"><span class="lineNum">    2379</span>              :         // Cleaning warning messages, no need to break as TORCH_CHECK(false)</span>
<span id="L2380"><span class="lineNum">    2380</span>              :         // terminates flow.</span>
<span id="L2381"><span class="lineNum">    2381</span>              :         // break;</span>
<span id="L2382"><span class="lineNum">    2382</span>              :       case MemoryFormat::NumOptions:</span>
<span id="L2383"><span class="lineNum">    2383</span>              :         TORCH_INTERNAL_ASSERT(false, &quot;invalid memory format &quot;, memory_format);</span>
<span id="L2384"><span class="lineNum">    2384</span>              :     }</span>
<span id="L2385"><span class="lineNum">    2385</span>              :     // recompute contiguous flag, as currently NHWC/NCHW flags are not mutually</span>
<span id="L2386"><span class="lineNum">    2386</span>              :     // exclusive see #24090</span>
<span id="L2387"><span class="lineNum">    2387</span>              :     refresh_contiguous();</span>
<span id="L2388"><span class="lineNum">    2388</span>              :   }</span>
<span id="L2389"><span class="lineNum">    2389</span>              : </span>
<span id="L2390"><span class="lineNum">    2390</span>              :   bool is_strides_like(at::MemoryFormat memory_format) const {</span>
<span id="L2391"><span class="lineNum">    2391</span>              :     if (C10_UNLIKELY(matches_policy(SizesStridesPolicy::CustomStrides))) {</span>
<span id="L2392"><span class="lineNum">    2392</span>              :       return is_strides_like_custom(memory_format);</span>
<span id="L2393"><span class="lineNum">    2393</span>              :     }</span>
<span id="L2394"><span class="lineNum">    2394</span>              :     return is_strides_like_default(memory_format);</span>
<span id="L2395"><span class="lineNum">    2395</span>              :   }</span>
<span id="L2396"><span class="lineNum">    2396</span>              : </span>
<span id="L2397"><span class="lineNum">    2397</span>              :   bool is_strides_like_channels_last() const {</span>
<span id="L2398"><span class="lineNum">    2398</span>              :     return is_strides_like(at::MemoryFormat::ChannelsLast);</span>
<span id="L2399"><span class="lineNum">    2399</span>              :   }</span>
<span id="L2400"><span class="lineNum">    2400</span>              : </span>
<span id="L2401"><span class="lineNum">    2401</span>              :   bool is_strides_like_channels_last_3d() const {</span>
<span id="L2402"><span class="lineNum">    2402</span>              :     return is_strides_like(at::MemoryFormat::ChannelsLast3d);</span>
<span id="L2403"><span class="lineNum">    2403</span>              :   }</span>
<span id="L2404"><span class="lineNum">    2404</span>              : </span>
<span id="L2405"><span class="lineNum">    2405</span>              :   bool is_non_overlapping_and_dense() const {</span>
<span id="L2406"><span class="lineNum">    2406</span>              :     if (C10_UNLIKELY(matches_policy(SizesStridesPolicy::CustomStrides))) {</span>
<span id="L2407"><span class="lineNum">    2407</span>              :       return is_non_overlapping_and_dense_custom();</span>
<span id="L2408"><span class="lineNum">    2408</span>              :     }</span>
<span id="L2409"><span class="lineNum">    2409</span>              :     return is_non_overlapping_and_dense_default();</span>
<span id="L2410"><span class="lineNum">    2410</span>              :   }</span>
<span id="L2411"><span class="lineNum">    2411</span>              : </span>
<span id="L2412"><span class="lineNum">    2412</span>              :   bool has_symbolic_sizes_strides() const {</span>
<span id="L2413"><span class="lineNum">    2413</span>              :     return has_symbolic_sizes_strides_;</span>
<span id="L2414"><span class="lineNum">    2414</span>              :   }</span>
<span id="L2415"><span class="lineNum">    2415</span>              : </span>
<span id="L2416"><span class="lineNum">    2416</span>              :  private:</span>
<span id="L2417"><span class="lineNum">    2417</span>              :   void HandleResize();</span>
<span id="L2418"><span class="lineNum">    2418</span>              : </span>
<span id="L2419"><span class="lineNum">    2419</span>              :   // The Caffe2 Resize() method supports being called both as Resize({2,2}) as</span>
<span id="L2420"><span class="lineNum">    2420</span>              :   // well as variadic with Resize(2, 2).  These overloads provide all of the</span>
<span id="L2421"><span class="lineNum">    2421</span>              :   // supported calling configurations, while being overloads (and not templates)</span>
<span id="L2422"><span class="lineNum">    2422</span>              :   // so that implicit conversions still work.</span>
<span id="L2423"><span class="lineNum">    2423</span>              :   //</span>
<span id="L2424"><span class="lineNum">    2424</span>              :   // SetDims on ArrayRef is internally implemented as a template, so we can</span>
<span id="L2425"><span class="lineNum">    2425</span>              :   // handle both ArrayRefs of different types (there are some uses of</span>
<span id="L2426"><span class="lineNum">    2426</span>              :   // Resize in Caffe2 which pass in int, not int64_t.)</span>
<span id="L2427"><span class="lineNum">    2427</span>              : </span>
<span id="L2428"><span class="lineNum">    2428</span>              :   template &lt;</span>
<span id="L2429"><span class="lineNum">    2429</span>              :       typename T,</span>
<span id="L2430"><span class="lineNum">    2430</span>              :       typename = typename std::enable_if&lt;std::is_integral&lt;T&gt;::value&gt;::type&gt;</span>
<span id="L2431"><span class="lineNum">    2431</span>              :   bool SetDimsTemplate(ArrayRef&lt;T&gt; src) {</span>
<span id="L2432"><span class="lineNum">    2432</span>              :     TORCH_CHECK(</span>
<span id="L2433"><span class="lineNum">    2433</span>              :         !has_symbolic_sizes_strides_,</span>
<span id="L2434"><span class="lineNum">    2434</span>              :         &quot;SetDims() called on tensor with symbolic shape&quot;)</span>
<span id="L2435"><span class="lineNum">    2435</span>              : </span>
<span id="L2436"><span class="lineNum">    2436</span>              :     auto old_numel = numel_;</span>
<span id="L2437"><span class="lineNum">    2437</span>              :     sizes_and_strides_.resize(src.size());</span>
<span id="L2438"><span class="lineNum">    2438</span>              :     int64_t new_numel = 1;</span>
<span id="L2439"><span class="lineNum">    2439</span>              :     for (const auto i : c10::irange(src.size())) {</span>
<span id="L2440"><span class="lineNum">    2440</span>              :       new_numel *= src[i];</span>
<span id="L2441"><span class="lineNum">    2441</span>              :       sizes_and_strides_.size_at_unchecked(i) = src[i];</span>
<span id="L2442"><span class="lineNum">    2442</span>              :     }</span>
<span id="L2443"><span class="lineNum">    2443</span>              :     numel_ = new_numel;</span>
<span id="L2444"><span class="lineNum">    2444</span>              :     empty_tensor_restride(MemoryFormat::Contiguous);</span>
<span id="L2445"><span class="lineNum">    2445</span>              :     return numel_ != old_numel;</span>
<span id="L2446"><span class="lineNum">    2446</span>              :   }</span>
<span id="L2447"><span class="lineNum">    2447</span>              : </span>
<span id="L2448"><span class="lineNum">    2448</span>              :   bool SetDims(ArrayRef&lt;int64_t&gt; s) {</span>
<span id="L2449"><span class="lineNum">    2449</span>              :     return SetDimsTemplate(s);</span>
<span id="L2450"><span class="lineNum">    2450</span>              :   }</span>
<span id="L2451"><span class="lineNum">    2451</span>              : </span>
<span id="L2452"><span class="lineNum">    2452</span>              :   bool SetDims(ArrayRef&lt;int&gt; s) {</span>
<span id="L2453"><span class="lineNum">    2453</span>              :     return SetDimsTemplate(s);</span>
<span id="L2454"><span class="lineNum">    2454</span>              :   }</span>
<span id="L2455"><span class="lineNum">    2455</span>              : </span>
<span id="L2456"><span class="lineNum">    2456</span>              :   bool SetDims(ArrayRef&lt;size_t&gt; s) {</span>
<span id="L2457"><span class="lineNum">    2457</span>              :     return SetDimsTemplate(s);</span>
<span id="L2458"><span class="lineNum">    2458</span>              :   }</span>
<span id="L2459"><span class="lineNum">    2459</span>              : </span>
<span id="L2460"><span class="lineNum">    2460</span>              :   bool SetDims() {</span>
<span id="L2461"><span class="lineNum">    2461</span>              :     return SetDims(IntArrayRef{});</span>
<span id="L2462"><span class="lineNum">    2462</span>              :   }</span>
<span id="L2463"><span class="lineNum">    2463</span>              : </span>
<span id="L2464"><span class="lineNum">    2464</span>              :   bool SetDims(const int64_t d0) {</span>
<span id="L2465"><span class="lineNum">    2465</span>              :     return SetDims(IntArrayRef{d0});</span>
<span id="L2466"><span class="lineNum">    2466</span>              :   }</span>
<span id="L2467"><span class="lineNum">    2467</span>              : </span>
<span id="L2468"><span class="lineNum">    2468</span>              :   bool SetDims(const int64_t d0, const int64_t d1) {</span>
<span id="L2469"><span class="lineNum">    2469</span>              :     return SetDims(IntArrayRef{d0, d1});</span>
<span id="L2470"><span class="lineNum">    2470</span>              :   }</span>
<span id="L2471"><span class="lineNum">    2471</span>              : </span>
<span id="L2472"><span class="lineNum">    2472</span>              :   bool SetDims(const int64_t d0, const int64_t d1, const int64_t d2) {</span>
<span id="L2473"><span class="lineNum">    2473</span>              :     return SetDims(IntArrayRef{d0, d1, d2});</span>
<span id="L2474"><span class="lineNum">    2474</span>              :   }</span>
<span id="L2475"><span class="lineNum">    2475</span>              : </span>
<span id="L2476"><span class="lineNum">    2476</span>              :   bool SetDims(</span>
<span id="L2477"><span class="lineNum">    2477</span>              :       const int64_t d0,</span>
<span id="L2478"><span class="lineNum">    2478</span>              :       const int64_t d1,</span>
<span id="L2479"><span class="lineNum">    2479</span>              :       const int64_t d2,</span>
<span id="L2480"><span class="lineNum">    2480</span>              :       const int64_t d3) {</span>
<span id="L2481"><span class="lineNum">    2481</span>              :     return SetDims(IntArrayRef{d0, d1, d2, d3});</span>
<span id="L2482"><span class="lineNum">    2482</span>              :   }</span>
<span id="L2483"><span class="lineNum">    2483</span>              : </span>
<span id="L2484"><span class="lineNum">    2484</span>              :   /**</span>
<span id="L2485"><span class="lineNum">    2485</span>              :    * Compute the number of elements based on the sizes of a tensor.</span>
<span id="L2486"><span class="lineNum">    2486</span>              :    */</span>
<span id="L2487"><span class="lineNum">    2487</span>              :   // NB: This is ONLY called when sizes_and_strides_ is used directly; if</span>
<span id="L2488"><span class="lineNum">    2488</span>              :   // we are virtualizing, then numel calls are virtualized as well, and this</span>
<span id="L2489"><span class="lineNum">    2489</span>              :   // should never get called</span>
<span id="L2490"><span class="lineNum">    2490</span>              :   int64_t compute_numel() const {</span>
<span id="L2491"><span class="lineNum">    2491</span>              :     TORCH_INTERNAL_ASSERT_DEBUG_ONLY(!has_symbolic_sizes_strides_);</span>
<span id="L2492"><span class="lineNum">    2492</span>              : #if C10_HAS_BUILTIN_OVERFLOW() &amp;&amp; !defined(C10_MOBILE)</span>
<span id="L2493"><span class="lineNum">    2493</span>              :     // Use overflow checks if supported by the compiler</span>
<span id="L2494"><span class="lineNum">    2494</span>              :     return safe_compute_numel();</span>
<span id="L2495"><span class="lineNum">    2495</span>              : #else</span>
<span id="L2496"><span class="lineNum">    2496</span>              :     return c10::multiply_integers(sizes_and_strides_.sizes_arrayref());</span>
<span id="L2497"><span class="lineNum">    2497</span>              : #endif</span>
<span id="L2498"><span class="lineNum">    2498</span>              :   }</span>
<span id="L2499"><span class="lineNum">    2499</span>              : </span>
<span id="L2500"><span class="lineNum">    2500</span>              :   /**</span>
<span id="L2501"><span class="lineNum">    2501</span>              :    * Compute the number of elements based on the sizes of a</span>
<span id="L2502"><span class="lineNum">    2502</span>              :    * tensor. Catches integer overflow that may occur when a tensor</span>
<span id="L2503"><span class="lineNum">    2503</span>              :    * using a sparse layout has multiple dimensions with large sizes.</span>
<span id="L2504"><span class="lineNum">    2504</span>              :    */</span>
<span id="L2505"><span class="lineNum">    2505</span>              :   int64_t safe_compute_numel() const {</span>
<span id="L2506"><span class="lineNum">    2506</span>              :     TORCH_INTERNAL_ASSERT_DEBUG_ONLY(!has_symbolic_sizes_strides_);</span>
<span id="L2507"><span class="lineNum">    2507</span>              :     uint64_t n = 1;</span>
<span id="L2508"><span class="lineNum">    2508</span>              :     bool overflows =</span>
<span id="L2509"><span class="lineNum">    2509</span>              :         c10::safe_multiplies_u64(sizes_and_strides_.sizes_arrayref(), &amp;n);</span>
<span id="L2510"><span class="lineNum">    2510</span>              :     constexpr auto numel_max = std::min(</span>
<span id="L2511"><span class="lineNum">    2511</span>              :         static_cast&lt;uint64_t&gt;(std::numeric_limits&lt;int64_t&gt;::max()),</span>
<span id="L2512"><span class="lineNum">    2512</span>              :         static_cast&lt;uint64_t&gt;(std::numeric_limits&lt;size_t&gt;::max()));</span>
<span id="L2513"><span class="lineNum">    2513</span>              : </span>
<span id="L2514"><span class="lineNum">    2514</span>              :     overflows |= (n &gt; numel_max);</span>
<span id="L2515"><span class="lineNum">    2515</span>              :     TORCH_CHECK(!overflows, &quot;numel: integer multiplication overflow&quot;);</span>
<span id="L2516"><span class="lineNum">    2516</span>              :     return static_cast&lt;int64_t&gt;(n);</span>
<span id="L2517"><span class="lineNum">    2517</span>              :   }</span>
<span id="L2518"><span class="lineNum">    2518</span>              : </span>
<span id="L2519"><span class="lineNum">    2519</span>              :   SymInt compute_sym_numel() const {</span>
<span id="L2520"><span class="lineNum">    2520</span>              :     TORCH_INTERNAL_ASSERT_DEBUG_ONLY(has_symbolic_sizes_strides_);</span>
<span id="L2521"><span class="lineNum">    2521</span>              :     auto&amp; sym_shape_meta{symbolic_shape_meta()};</span>
<span id="L2522"><span class="lineNum">    2522</span>              :     SymInt numel = 1;</span>
<span id="L2523"><span class="lineNum">    2523</span>              :     for (const auto&amp; s : sym_shape_meta.sizes_) {</span>
<span id="L2524"><span class="lineNum">    2524</span>              :       numel *= s;</span>
<span id="L2525"><span class="lineNum">    2525</span>              :     }</span>
<span id="L2526"><span class="lineNum">    2526</span>              :     return numel;</span>
<span id="L2527"><span class="lineNum">    2527</span>              :   }</span>
<span id="L2528"><span class="lineNum">    2528</span>              : </span>
<span id="L2529"><span class="lineNum">    2529</span>              :   /**</span>
<span id="L2530"><span class="lineNum">    2530</span>              :    * Compute whether or not a tensor is contiguous based on the sizes and</span>
<span id="L2531"><span class="lineNum">    2531</span>              :    * strides of a tensor.</span>
<span id="L2532"><span class="lineNum">    2532</span>              :    */</span>
<span id="L2533"><span class="lineNum">    2533</span>              :   bool compute_contiguous(identity&lt;bool&gt;) const;</span>
<span id="L2534"><span class="lineNum">    2534</span>              : </span>
<span id="L2535"><span class="lineNum">    2535</span>              :   bool compute_channels_last_contiguous_2d(identity&lt;bool&gt;) const;</span>
<span id="L2536"><span class="lineNum">    2536</span>              : </span>
<span id="L2537"><span class="lineNum">    2537</span>              :   bool compute_channels_last_contiguous_3d(identity&lt;bool&gt;) const;</span>
<span id="L2538"><span class="lineNum">    2538</span>              : </span>
<span id="L2539"><span class="lineNum">    2539</span>              :   bool compute_strides_like_channels_last_2d(identity&lt;bool&gt;) const;</span>
<span id="L2540"><span class="lineNum">    2540</span>              : </span>
<span id="L2541"><span class="lineNum">    2541</span>              :   bool compute_strides_like_channels_last_3d(identity&lt;bool&gt;) const;</span>
<span id="L2542"><span class="lineNum">    2542</span>              : </span>
<span id="L2543"><span class="lineNum">    2543</span>              :   bool compute_non_overlapping_and_dense(identity&lt;bool&gt;) const;</span>
<span id="L2544"><span class="lineNum">    2544</span>              : </span>
<span id="L2545"><span class="lineNum">    2545</span>              :   SymBool compute_contiguous(identity&lt;SymBool&gt;) const;</span>
<span id="L2546"><span class="lineNum">    2546</span>              : </span>
<span id="L2547"><span class="lineNum">    2547</span>              :   SymBool compute_channels_last_contiguous_2d(identity&lt;SymBool&gt;) const;</span>
<span id="L2548"><span class="lineNum">    2548</span>              : </span>
<span id="L2549"><span class="lineNum">    2549</span>              :   SymBool compute_channels_last_contiguous_3d(identity&lt;SymBool&gt;) const;</span>
<span id="L2550"><span class="lineNum">    2550</span>              : </span>
<span id="L2551"><span class="lineNum">    2551</span>              :   SymBool compute_strides_like_channels_last_2d(identity&lt;SymBool&gt;) const;</span>
<span id="L2552"><span class="lineNum">    2552</span>              : </span>
<span id="L2553"><span class="lineNum">    2553</span>              :   SymBool compute_strides_like_channels_last_3d(identity&lt;SymBool&gt;) const;</span>
<span id="L2554"><span class="lineNum">    2554</span>              : </span>
<span id="L2555"><span class="lineNum">    2555</span>              :   SymBool compute_non_overlapping_and_dense(identity&lt;SymBool&gt;) const;</span>
<span id="L2556"><span class="lineNum">    2556</span>              : </span>
<span id="L2557"><span class="lineNum">    2557</span>              :  protected:</span>
<span id="L2558"><span class="lineNum">    2558</span>              :   /**</span>
<span id="L2559"><span class="lineNum">    2559</span>              :    * Recompute the cached numel of a tensor.  Call this if you modify</span>
<span id="L2560"><span class="lineNum">    2560</span>              :    * sizes.</span>
<span id="L2561"><span class="lineNum">    2561</span>              :    *</span>
<span id="L2562"><span class="lineNum">    2562</span>              :    * For tensors with sparse layouts, use safe_refresh_numel() instead</span>
<span id="L2563"><span class="lineNum">    2563</span>              :    * because it will catch integer overflow that may occur for tensors</span>
<span id="L2564"><span class="lineNum">    2564</span>              :    * with sparse layouts and large dimensions.</span>
<span id="L2565"><span class="lineNum">    2565</span>              :    *</span>
<span id="L2566"><span class="lineNum">    2566</span>              :    * NB: We may uselessly recompute cached numel even in situations where</span>
<span id="L2567"><span class="lineNum">    2567</span>              :    * it is completely never used (e.g., if CustomSizes for Python).  However,</span>
<span id="L2568"><span class="lineNum">    2568</span>              :    * we still must keep it up to date in case the Python overload</span>
<span id="L2569"><span class="lineNum">    2569</span>              :    * returns None (in which case we will consult the field here).  This also</span>
<span id="L2570"><span class="lineNum">    2570</span>              :    * implies that sizes/strides will never be complete garbage; in the</span>
<span id="L2571"><span class="lineNum">    2571</span>              :    * very worst case scenario, it will reflect a 1-dim zero size tensor.</span>
<span id="L2572"><span class="lineNum">    2572</span>              :    */</span>
<span id="L2573"><span class="lineNum">    2573</span>              :   void refresh_numel() {</span>
<span id="L2574"><span class="lineNum">    2574</span>              :     if (has_symbolic_sizes_strides_) {</span>
<span id="L2575"><span class="lineNum">    2575</span>              :       symbolic_shape_meta().numel_ = compute_sym_numel();</span>
<span id="L2576"><span class="lineNum">    2576</span>              :     } else {</span>
<span id="L2577"><span class="lineNum">    2577</span>              :       numel_ = compute_numel();</span>
<span id="L2578"><span class="lineNum">    2578</span>              :     }</span>
<span id="L2579"><span class="lineNum">    2579</span>              :   }</span>
<span id="L2580"><span class="lineNum">    2580</span>              : </span>
<span id="L2581"><span class="lineNum">    2581</span>              :   /**</span>
<span id="L2582"><span class="lineNum">    2582</span>              :    * Recompute the cached numel of a tensor.  Call this if you modify</span>
<span id="L2583"><span class="lineNum">    2583</span>              :    * sizes. Use only for tensors with sparse layouts because only</span>
<span id="L2584"><span class="lineNum">    2584</span>              :    * sparse tensor are likely to have sizes that may lead to integer</span>
<span id="L2585"><span class="lineNum">    2585</span>              :    * overflow when computing numel.</span>
<span id="L2586"><span class="lineNum">    2586</span>              :    */</span>
<span id="L2587"><span class="lineNum">    2587</span>              :   void safe_refresh_numel() {</span>
<span id="L2588"><span class="lineNum">    2588</span>              :     if (has_symbolic_sizes_strides_) {</span>
<span id="L2589"><span class="lineNum">    2589</span>              :       // NB: sym numel is done with symbolic integers, which handle overflow</span>
<span id="L2590"><span class="lineNum">    2590</span>              :       // checking</span>
<span id="L2591"><span class="lineNum">    2591</span>              :       symbolic_shape_meta().numel_ = compute_sym_numel();</span>
<span id="L2592"><span class="lineNum">    2592</span>              :     } else {</span>
<span id="L2593"><span class="lineNum">    2593</span>              :       numel_ = safe_compute_numel();</span>
<span id="L2594"><span class="lineNum">    2594</span>              :     }</span>
<span id="L2595"><span class="lineNum">    2595</span>              :   }</span>
<span id="L2596"><span class="lineNum">    2596</span>              : </span>
<span id="L2597"><span class="lineNum">    2597</span>              :  private:</span>
<span id="L2598"><span class="lineNum">    2598</span>              :   // NB: the TypeId argument prevents confusion where you pass a true/false</span>
<span id="L2599"><span class="lineNum">    2599</span>              :   // literal and pick the wrong overload</span>
<span id="L2600"><span class="lineNum">    2600</span>              : </span>
<span id="L2601"><span class="lineNum">    2601</span>              :   void _set_is_contiguous(identity&lt;bool&gt;, bool b) {</span>
<span id="L2602"><span class="lineNum">    2602</span>              :     is_contiguous_ = b;</span>
<span id="L2603"><span class="lineNum">    2603</span>              :   }</span>
<span id="L2604"><span class="lineNum">    2604</span>              : </span>
<span id="L2605"><span class="lineNum">    2605</span>              :   void _set_is_contiguous(identity&lt;SymBool&gt;, SymBool b) {</span>
<span id="L2606"><span class="lineNum">    2606</span>              :     symbolic_shape_meta().is_contiguous_ = std::move(b);</span>
<span id="L2607"><span class="lineNum">    2607</span>              :   }</span>
<span id="L2608"><span class="lineNum">    2608</span>              : </span>
<span id="L2609"><span class="lineNum">    2609</span>              :   void _set_is_channels_last_contiguous(identity&lt;bool&gt;, bool b) {</span>
<span id="L2610"><span class="lineNum">    2610</span>              :     is_channels_last_contiguous_ = b;</span>
<span id="L2611"><span class="lineNum">    2611</span>              :   }</span>
<span id="L2612"><span class="lineNum">    2612</span>              : </span>
<span id="L2613"><span class="lineNum">    2613</span>              :   void _set_is_channels_last_contiguous(identity&lt;SymBool&gt;, SymBool b) {</span>
<span id="L2614"><span class="lineNum">    2614</span>              :     symbolic_shape_meta().is_channels_last_contiguous_ = std::move(b);</span>
<span id="L2615"><span class="lineNum">    2615</span>              :   }</span>
<span id="L2616"><span class="lineNum">    2616</span>              : </span>
<span id="L2617"><span class="lineNum">    2617</span>              :   void _set_is_channels_last_3d_contiguous(identity&lt;bool&gt;, bool b) {</span>
<span id="L2618"><span class="lineNum">    2618</span>              :     is_channels_last_3d_contiguous_ = b;</span>
<span id="L2619"><span class="lineNum">    2619</span>              :   }</span>
<span id="L2620"><span class="lineNum">    2620</span>              : </span>
<span id="L2621"><span class="lineNum">    2621</span>              :   void _set_is_channels_last_3d_contiguous(identity&lt;SymBool&gt;, SymBool b) {</span>
<span id="L2622"><span class="lineNum">    2622</span>              :     symbolic_shape_meta().is_channels_last_3d_contiguous_ = std::move(b);</span>
<span id="L2623"><span class="lineNum">    2623</span>              :   }</span>
<span id="L2624"><span class="lineNum">    2624</span>              : </span>
<span id="L2625"><span class="lineNum">    2625</span>              :   void _set_is_channels_last(identity&lt;bool&gt;, bool b) {</span>
<span id="L2626"><span class="lineNum">    2626</span>              :     is_channels_last_ = b;</span>
<span id="L2627"><span class="lineNum">    2627</span>              :   }</span>
<span id="L2628"><span class="lineNum">    2628</span>              : </span>
<span id="L2629"><span class="lineNum">    2629</span>              :   void _set_is_channels_last(identity&lt;SymBool&gt;, SymBool b) {</span>
<span id="L2630"><span class="lineNum">    2630</span>              :     symbolic_shape_meta().is_channels_last_ = std::move(b);</span>
<span id="L2631"><span class="lineNum">    2631</span>              :   }</span>
<span id="L2632"><span class="lineNum">    2632</span>              : </span>
<span id="L2633"><span class="lineNum">    2633</span>              :   void _set_is_channels_last_3d(identity&lt;bool&gt;, bool b) {</span>
<span id="L2634"><span class="lineNum">    2634</span>              :     is_channels_last_3d_ = b;</span>
<span id="L2635"><span class="lineNum">    2635</span>              :   }</span>
<span id="L2636"><span class="lineNum">    2636</span>              : </span>
<span id="L2637"><span class="lineNum">    2637</span>              :   void _set_is_channels_last_3d(identity&lt;SymBool&gt;, SymBool b) {</span>
<span id="L2638"><span class="lineNum">    2638</span>              :     symbolic_shape_meta().is_channels_last_3d_ = std::move(b);</span>
<span id="L2639"><span class="lineNum">    2639</span>              :   }</span>
<span id="L2640"><span class="lineNum">    2640</span>              : </span>
<span id="L2641"><span class="lineNum">    2641</span>              :   void _set_is_non_overlapping_and_dense(identity&lt;bool&gt;, bool b) {</span>
<span id="L2642"><span class="lineNum">    2642</span>              :     is_non_overlapping_and_dense_ = b;</span>
<span id="L2643"><span class="lineNum">    2643</span>              :   }</span>
<span id="L2644"><span class="lineNum">    2644</span>              : </span>
<span id="L2645"><span class="lineNum">    2645</span>              :   void _set_is_non_overlapping_and_dense(identity&lt;SymBool&gt;, SymBool b) {</span>
<span id="L2646"><span class="lineNum">    2646</span>              :     symbolic_shape_meta().is_non_overlapping_and_dense_ = std::move(b);</span>
<span id="L2647"><span class="lineNum">    2647</span>              :   }</span>
<span id="L2648"><span class="lineNum">    2648</span>              : </span>
<span id="L2649"><span class="lineNum">    2649</span>              :   // These are little wrappers over the real compute_ functions that</span>
<span id="L2650"><span class="lineNum">    2650</span>              :   // can make use of other contiguity fields to short circuit.</span>
<span id="L2651"><span class="lineNum">    2651</span>              :   // They need to be implemented separately for SymBool, as SymBool does</span>
<span id="L2652"><span class="lineNum">    2652</span>              :   // not short circuit.</span>
<span id="L2653"><span class="lineNum">    2653</span>              :   // TODO: should the SymBool cases avoid the short circuit?  Need to reason</span>
<span id="L2654"><span class="lineNum">    2654</span>              :   // if its correct, and reason if the simpler expressions are better for</span>
<span id="L2655"><span class="lineNum">    2655</span>              :   // analysis (maybe not!)</span>
<span id="L2656"><span class="lineNum">    2656</span>              : </span>
<span id="L2657"><span class="lineNum">    2657</span>              :   bool compute_is_non_overlapping_and_dense_dim4(identity&lt;bool&gt; type_id) {</span>
<span id="L2658"><span class="lineNum">    2658</span>              :     return is_contiguous_ || is_channels_last_contiguous_ ||</span>
<span id="L2659"><span class="lineNum">    2659</span>              :         compute_non_overlapping_and_dense(type_id);</span>
<span id="L2660"><span class="lineNum">    2660</span>              :   }</span>
<span id="L2661"><span class="lineNum">    2661</span>              : </span>
<span id="L2662"><span class="lineNum">    2662</span>              :   SymBool compute_is_non_overlapping_and_dense_dim4(identity&lt;SymBool&gt; type_id);</span>
<span id="L2663"><span class="lineNum">    2663</span>              : </span>
<span id="L2664"><span class="lineNum">    2664</span>              :   bool compute_channels_last_contiguous_3d_dim5(identity&lt;bool&gt; type_id) {</span>
<span id="L2665"><span class="lineNum">    2665</span>              :     return !is_channels_last_contiguous_ &amp;&amp;</span>
<span id="L2666"><span class="lineNum">    2666</span>              :         compute_channels_last_contiguous_3d(type_id);</span>
<span id="L2667"><span class="lineNum">    2667</span>              :   }</span>
<span id="L2668"><span class="lineNum">    2668</span>              : </span>
<span id="L2669"><span class="lineNum">    2669</span>              :   SymBool compute_channels_last_contiguous_3d_dim5(identity&lt;SymBool&gt; type_id);</span>
<span id="L2670"><span class="lineNum">    2670</span>              : </span>
<span id="L2671"><span class="lineNum">    2671</span>              :   bool compute_channels_last_2d_dim5(identity&lt;bool&gt; type_id) {</span>
<span id="L2672"><span class="lineNum">    2672</span>              :     return !is_channels_last_3d_contiguous_ &amp;&amp;</span>
<span id="L2673"><span class="lineNum">    2673</span>              :         compute_strides_like_channels_last_2d(type_id);</span>
<span id="L2674"><span class="lineNum">    2674</span>              :   }</span>
<span id="L2675"><span class="lineNum">    2675</span>              : </span>
<span id="L2676"><span class="lineNum">    2676</span>              :   SymBool compute_channels_last_2d_dim5(identity&lt;SymBool&gt; type_id);</span>
<span id="L2677"><span class="lineNum">    2677</span>              : </span>
<span id="L2678"><span class="lineNum">    2678</span>              :   bool compute_channels_last_3d_dim5(identity&lt;bool&gt; type_id) {</span>
<span id="L2679"><span class="lineNum">    2679</span>              :     return !is_channels_last_ &amp;&amp; compute_strides_like_channels_last_3d(type_id);</span>
<span id="L2680"><span class="lineNum">    2680</span>              :   }</span>
<span id="L2681"><span class="lineNum">    2681</span>              : </span>
<span id="L2682"><span class="lineNum">    2682</span>              :   SymBool compute_channels_last_3d_dim5(identity&lt;SymBool&gt; type_id);</span>
<span id="L2683"><span class="lineNum">    2683</span>              : </span>
<span id="L2684"><span class="lineNum">    2684</span>              :   bool compute_is_non_overlapping_and_dense_dim5(identity&lt;bool&gt; type_id) {</span>
<span id="L2685"><span class="lineNum">    2685</span>              :     return is_contiguous_ || is_channels_last_contiguous_ ||</span>
<span id="L2686"><span class="lineNum">    2686</span>              :         is_channels_last_3d_contiguous_ ||</span>
<span id="L2687"><span class="lineNum">    2687</span>              :         compute_non_overlapping_and_dense(type_id);</span>
<span id="L2688"><span class="lineNum">    2688</span>              :   }</span>
<span id="L2689"><span class="lineNum">    2689</span>              : </span>
<span id="L2690"><span class="lineNum">    2690</span>              :   SymBool compute_is_non_overlapping_and_dense_dim5(identity&lt;SymBool&gt; type_id);</span>
<span id="L2691"><span class="lineNum">    2691</span>              : </span>
<span id="L2692"><span class="lineNum">    2692</span>              :   bool compute_is_non_overlapping_and_dense_anydim(identity&lt;bool&gt; type_id) {</span>
<span id="L2693"><span class="lineNum">    2693</span>              :     return is_contiguous_ || compute_non_overlapping_and_dense(type_id);</span>
<span id="L2694"><span class="lineNum">    2694</span>              :   }</span>
<span id="L2695"><span class="lineNum">    2695</span>              : </span>
<span id="L2696"><span class="lineNum">    2696</span>              :   SymBool compute_is_non_overlapping_and_dense_anydim(</span>
<span id="L2697"><span class="lineNum">    2697</span>              :       identity&lt;SymBool&gt; type_id);</span>
<span id="L2698"><span class="lineNum">    2698</span>              : </span>
<span id="L2699"><span class="lineNum">    2699</span>              :   template &lt;typename T&gt;</span>
<span id="L2700"><span class="lineNum">    2700</span>              :   void _refresh_contiguous() {</span>
<span id="L2701"><span class="lineNum">    2701</span>              :     auto type_id = identity&lt;T&gt;();</span>
<span id="L2702"><span class="lineNum">    2702</span>              :     // Note:</span>
<span id="L2703"><span class="lineNum">    2703</span>              :     // Dim 0, 1, 2 will never be a channels last 2d/3d format</span>
<span id="L2704"><span class="lineNum">    2704</span>              :     // Dim 3+ is possibly be a channels last 2d format (Dim 4 only at this</span>
<span id="L2705"><span class="lineNum">    2705</span>              :     // point) Dim 4+ is possibly be a channels last 3d format (Dim 5 only at</span>
<span id="L2706"><span class="lineNum">    2706</span>              :     // this point)</span>
<span id="L2707"><span class="lineNum">    2707</span>              :     switch (dim()) {</span>
<span id="L2708"><span class="lineNum">    2708</span>              :       case 4: {</span>
<span id="L2709"><span class="lineNum">    2709</span>              :         _set_is_contiguous(type_id, compute_contiguous(type_id));</span>
<span id="L2710"><span class="lineNum">    2710</span>              :         _set_is_channels_last_contiguous(</span>
<span id="L2711"><span class="lineNum">    2711</span>              :             type_id, compute_channels_last_contiguous_2d(type_id));</span>
<span id="L2712"><span class="lineNum">    2712</span>              :         _set_is_channels_last_3d_contiguous(type_id, false);</span>
<span id="L2713"><span class="lineNum">    2713</span>              :         _set_is_channels_last(</span>
<span id="L2714"><span class="lineNum">    2714</span>              :             type_id, compute_strides_like_channels_last_2d(type_id));</span>
<span id="L2715"><span class="lineNum">    2715</span>              :         _set_is_channels_last_3d(type_id, false);</span>
<span id="L2716"><span class="lineNum">    2716</span>              :         _set_is_non_overlapping_and_dense(</span>
<span id="L2717"><span class="lineNum">    2717</span>              :             type_id, compute_is_non_overlapping_and_dense_dim4(type_id));</span>
<span id="L2718"><span class="lineNum">    2718</span>              :         break;</span>
<span id="L2719"><span class="lineNum">    2719</span>              :       }</span>
<span id="L2720"><span class="lineNum">    2720</span>              :       case 5: {</span>
<span id="L2721"><span class="lineNum">    2721</span>              :         _set_is_contiguous(type_id, compute_contiguous(type_id));</span>
<span id="L2722"><span class="lineNum">    2722</span>              :         _set_is_channels_last_contiguous(</span>
<span id="L2723"><span class="lineNum">    2723</span>              :             type_id, compute_channels_last_contiguous_2d(type_id));</span>
<span id="L2724"><span class="lineNum">    2724</span>              :         _set_is_channels_last_3d_contiguous(</span>
<span id="L2725"><span class="lineNum">    2725</span>              :             type_id, compute_channels_last_contiguous_3d_dim5(type_id));</span>
<span id="L2726"><span class="lineNum">    2726</span>              :         _set_is_channels_last(type_id, compute_channels_last_2d_dim5(type_id));</span>
<span id="L2727"><span class="lineNum">    2727</span>              :         _set_is_channels_last_3d(</span>
<span id="L2728"><span class="lineNum">    2728</span>              :             type_id, compute_channels_last_3d_dim5(type_id));</span>
<span id="L2729"><span class="lineNum">    2729</span>              :         _set_is_non_overlapping_and_dense(</span>
<span id="L2730"><span class="lineNum">    2730</span>              :             type_id, compute_is_non_overlapping_and_dense_dim5(type_id));</span>
<span id="L2731"><span class="lineNum">    2731</span>              :         break;</span>
<span id="L2732"><span class="lineNum">    2732</span>              :       }</span>
<span id="L2733"><span class="lineNum">    2733</span>              :       default:</span>
<span id="L2734"><span class="lineNum">    2734</span>              :         // is_channels_last_ and is_channels_last_3d_ are suggested</span>
<span id="L2735"><span class="lineNum">    2735</span>              :         // memory_format. Being channels_last_contiguous doesn't necessarily</span>
<span id="L2736"><span class="lineNum">    2736</span>              :         // mean the tensor is strided like channels_last: for strides on channel</span>
<span id="L2737"><span class="lineNum">    2737</span>              :         // dimension could suggest desired memory_layout, but it doesn't affect</span>
<span id="L2738"><span class="lineNum">    2738</span>              :         // memory storage</span>
<span id="L2739"><span class="lineNum">    2739</span>              :         _set_is_contiguous(type_id, compute_contiguous(type_id));</span>
<span id="L2740"><span class="lineNum">    2740</span>              :         _set_is_channels_last_contiguous(type_id, false);</span>
<span id="L2741"><span class="lineNum">    2741</span>              :         _set_is_channels_last_3d_contiguous(type_id, false);</span>
<span id="L2742"><span class="lineNum">    2742</span>              :         _set_is_channels_last(type_id, false);</span>
<span id="L2743"><span class="lineNum">    2743</span>              :         _set_is_channels_last_3d(type_id, false);</span>
<span id="L2744"><span class="lineNum">    2744</span>              :         _set_is_non_overlapping_and_dense(</span>
<span id="L2745"><span class="lineNum">    2745</span>              :             type_id, compute_is_non_overlapping_and_dense_anydim(type_id));</span>
<span id="L2746"><span class="lineNum">    2746</span>              :         break;</span>
<span id="L2747"><span class="lineNum">    2747</span>              :     }</span>
<span id="L2748"><span class="lineNum">    2748</span>              :   }</span>
<span id="L2749"><span class="lineNum">    2749</span>              : </span>
<span id="L2750"><span class="lineNum">    2750</span>              :  protected:</span>
<span id="L2751"><span class="lineNum">    2751</span>              :   /**</span>
<span id="L2752"><span class="lineNum">    2752</span>              :    * Recompute the cached contiguity of a tensor.  Call this if you modify sizes</span>
<span id="L2753"><span class="lineNum">    2753</span>              :    * or strides.</span>
<span id="L2754"><span class="lineNum">    2754</span>              :    */</span>
<span id="L2755"><span class="lineNum">    2755</span>              :   void refresh_contiguous() {</span>
<span id="L2756"><span class="lineNum">    2756</span>              :     if (has_symbolic_sizes_strides_) {</span>
<span id="L2757"><span class="lineNum">    2757</span>              :       _refresh_contiguous&lt;SymBool&gt;();</span>
<span id="L2758"><span class="lineNum">    2758</span>              :     } else {</span>
<span id="L2759"><span class="lineNum">    2759</span>              :       _refresh_contiguous&lt;bool&gt;();</span>
<span id="L2760"><span class="lineNum">    2760</span>              :     }</span>
<span id="L2761"><span class="lineNum">    2761</span>              :   }</span>
<span id="L2762"><span class="lineNum">    2762</span>              : </span>
<span id="L2763"><span class="lineNum">    2763</span>              :   /**</span>
<span id="L2764"><span class="lineNum">    2764</span>              :    * Copy the tensor metadata fields (e.g. sizes / strides / storage pointer /</span>
<span id="L2765"><span class="lineNum">    2765</span>              :    * storage_offset) from one TensorImpl to another TensorImpl.</span>
<span id="L2766"><span class="lineNum">    2766</span>              :    *</span>
<span id="L2767"><span class="lineNum">    2767</span>              :    * For usage of `version_counter` and `allow_tensor_metadata_change`, see NOTE</span>
<span id="L2768"><span class="lineNum">    2768</span>              :    * [ TensorImpl Shallow-Copying ].</span>
<span id="L2769"><span class="lineNum">    2769</span>              :    */</span>
<span id="L2770"><span class="lineNum">    2770</span>              :   static void copy_tensor_metadata(</span>
<span id="L2771"><span class="lineNum">    2771</span>              :       const TensorImpl* src_impl,</span>
<span id="L2772"><span class="lineNum">    2772</span>              :       TensorImpl* dest_impl,</span>
<span id="L2773"><span class="lineNum">    2773</span>              :       const c10::VariableVersion&amp; version_counter,</span>
<span id="L2774"><span class="lineNum">    2774</span>              :       bool allow_tensor_metadata_change);</span>
<span id="L2775"><span class="lineNum">    2775</span>              : </span>
<span id="L2776"><span class="lineNum">    2776</span>              :   /**</span>
<span id="L2777"><span class="lineNum">    2777</span>              :    * Copy the tensor metadata fields (e.g. sizes / strides / storage pointer /</span>
<span id="L2778"><span class="lineNum">    2778</span>              :    * storage_offset) from one TensorImpl to another TensorImpl.</span>
<span id="L2779"><span class="lineNum">    2779</span>              :    *</span>
<span id="L2780"><span class="lineNum">    2780</span>              :    * For usage of `version_counter` and `allow_tensor_metadata_change`, see NOTE</span>
<span id="L2781"><span class="lineNum">    2781</span>              :    * [ TensorImpl Shallow-Copying ].</span>
<span id="L2782"><span class="lineNum">    2782</span>              :    */</span>
<span id="L2783"><span class="lineNum">    2783</span>              :   static void copy_tensor_metadata(</span>
<span id="L2784"><span class="lineNum">    2784</span>              :       const TensorImpl* src_impl,</span>
<span id="L2785"><span class="lineNum">    2785</span>              :       TensorImpl* dest_impl,</span>
<span id="L2786"><span class="lineNum">    2786</span>              :       c10::VariableVersion&amp;&amp; version_counter,</span>
<span id="L2787"><span class="lineNum">    2787</span>              :       bool allow_tensor_metadata_change);</span>
<span id="L2788"><span class="lineNum">    2788</span>              : </span>
<span id="L2789"><span class="lineNum">    2789</span>              :  private:</span>
<span id="L2790"><span class="lineNum">    2790</span>              :   static void copy_tensor_metadata_except_version_counter(</span>
<span id="L2791"><span class="lineNum">    2791</span>              :       const TensorImpl* src_impl,</span>
<span id="L2792"><span class="lineNum">    2792</span>              :       TensorImpl* dest_impl,</span>
<span id="L2793"><span class="lineNum">    2793</span>              :       bool allow_tensor_metadata_change);</span>
<span id="L2794"><span class="lineNum">    2794</span>              : </span>
<span id="L2795"><span class="lineNum">    2795</span>              :  protected:</span>
<span id="L2796"><span class="lineNum">    2796</span>              :   // Error message to show when the user tries to change tensor metadata on</span>
<span id="L2797"><span class="lineNum">    2797</span>              :   // Tensor created from .data or .detach().</span>
<span id="L2798"><span class="lineNum">    2798</span>              :   //</span>
<span id="L2799"><span class="lineNum">    2799</span>              :   // See NOTE [ Metadata Change for a Detached Tensor ] for details.</span>
<span id="L2800"><span class="lineNum">    2800</span>              :   static const char* const err_msg_tensor_metadata_change_not_allowed;</span>
<span id="L2801"><span class="lineNum">    2801</span>              : </span>
<span id="L2802"><span class="lineNum">    2802</span>              :   static void copy_generic_tensor_metadata(</span>
<span id="L2803"><span class="lineNum">    2803</span>              :       const TensorImpl* src_impl,</span>
<span id="L2804"><span class="lineNum">    2804</span>              :       TensorImpl* dest_impl);</span>
<span id="L2805"><span class="lineNum">    2805</span>              : </span>
<span id="L2806"><span class="lineNum">    2806</span>              :  public:</span>
<span id="L2807"><span class="lineNum">    2807</span>              :   void set_storage_access_should_throw() {</span>
<span id="L2808"><span class="lineNum">    2808</span>              :     storage_access_should_throw_ = true;</span>
<span id="L2809"><span class="lineNum">    2809</span>              :   }</span>
<span id="L2810"><span class="lineNum">    2810</span>              : </span>
<span id="L2811"><span class="lineNum">    2811</span>              :  public:</span>
<span id="L2812"><span class="lineNum">    2812</span>              :   void set_custom_sizes_strides(SizesStridesPolicy policy) {</span>
<span id="L2813"><span class="lineNum">    2813</span>              :     custom_sizes_strides_ = static_cast&lt;uint8_t&gt;(policy);</span>
<span id="L2814"><span class="lineNum">    2814</span>              :     refresh_sizes_strides_policy();</span>
<span id="L2815"><span class="lineNum">    2815</span>              :   }</span>
<span id="L2816"><span class="lineNum">    2816</span>              : </span>
<span id="L2817"><span class="lineNum">    2817</span>              :   void set_python_custom_sizes_strides(SizesStridesPolicy policy) {</span>
<span id="L2818"><span class="lineNum">    2818</span>              :     python_custom_sizes_strides_ = static_cast&lt;uint8_t&gt;(policy);</span>
<span id="L2819"><span class="lineNum">    2819</span>              :     refresh_sizes_strides_policy();</span>
<span id="L2820"><span class="lineNum">    2820</span>              :   }</span>
<span id="L2821"><span class="lineNum">    2821</span>              : </span>
<span id="L2822"><span class="lineNum">    2822</span>              :   void set_custom_device(bool custom_device) {</span>
<span id="L2823"><span class="lineNum">    2823</span>              :     custom_device_ = custom_device;</span>
<span id="L2824"><span class="lineNum">    2824</span>              :     refresh_device_policy();</span>
<span id="L2825"><span class="lineNum">    2825</span>              :   }</span>
<span id="L2826"><span class="lineNum">    2826</span>              : </span>
<span id="L2827"><span class="lineNum">    2827</span>              :   void set_custom_layout(bool custom_layout) {</span>
<span id="L2828"><span class="lineNum">    2828</span>              :     custom_layout_ = custom_layout;</span>
<span id="L2829"><span class="lineNum">    2829</span>              :     refresh_layout_policy();</span>
<span id="L2830"><span class="lineNum">    2830</span>              :   }</span>
<span id="L2831"><span class="lineNum">    2831</span>              : </span>
<span id="L2832"><span class="lineNum">    2832</span>              :   void set_python_custom_device(bool custom_device) {</span>
<span id="L2833"><span class="lineNum">    2833</span>              :     python_custom_device_ = custom_device;</span>
<span id="L2834"><span class="lineNum">    2834</span>              :     refresh_device_policy();</span>
<span id="L2835"><span class="lineNum">    2835</span>              :   }</span>
<span id="L2836"><span class="lineNum">    2836</span>              : </span>
<span id="L2837"><span class="lineNum">    2837</span>              :   void set_python_custom_layout(bool custom_layout) {</span>
<span id="L2838"><span class="lineNum">    2838</span>              :     python_custom_layout_ = custom_layout;</span>
<span id="L2839"><span class="lineNum">    2839</span>              :     refresh_layout_policy();</span>
<span id="L2840"><span class="lineNum">    2840</span>              :   }</span>
<span id="L2841"><span class="lineNum">    2841</span>              : </span>
<span id="L2842"><span class="lineNum">    2842</span>              :  protected:</span>
<span id="L2843"><span class="lineNum">    2843</span>              :   void refresh_sizes_strides_policy() {</span>
<span id="L2844"><span class="lineNum">    2844</span>              :     if (has_symbolic_sizes_strides_) {</span>
<span id="L2845"><span class="lineNum">    2845</span>              :       sizes_strides_policy_ =</span>
<span id="L2846"><span class="lineNum">    2846</span>              :           static_cast&lt;uint8_t&gt;(SizesStridesPolicy::CustomSizes);</span>
<span id="L2847"><span class="lineNum">    2847</span>              :     } else {</span>
<span id="L2848"><span class="lineNum">    2848</span>              :       sizes_strides_policy_ =</span>
<span id="L2849"><span class="lineNum">    2849</span>              :           std::max(custom_sizes_strides_, python_custom_sizes_strides_);</span>
<span id="L2850"><span class="lineNum">    2850</span>              :     }</span>
<span id="L2851"><span class="lineNum">    2851</span>              :   }</span>
<span id="L2852"><span class="lineNum">    2852</span>              : </span>
<span id="L2853"><span class="lineNum">    2853</span>              :   void refresh_device_policy() {</span>
<span id="L2854"><span class="lineNum">    2854</span>              :     device_policy_ = custom_device_ || python_custom_device_;</span>
<span id="L2855"><span class="lineNum">    2855</span>              :   }</span>
<span id="L2856"><span class="lineNum">    2856</span>              : </span>
<span id="L2857"><span class="lineNum">    2857</span>              :   void refresh_layout_policy() {</span>
<span id="L2858"><span class="lineNum">    2858</span>              :     layout_policy_ = custom_layout_ || python_custom_layout_;</span>
<span id="L2859"><span class="lineNum">    2859</span>              :   }</span>
<span id="L2860"><span class="lineNum">    2860</span>              : </span>
<span id="L2861"><span class="lineNum">    2861</span>              :  protected:</span>
<span id="L2862"><span class="lineNum">    2862</span>              :   Storage storage_;</span>
<span id="L2863"><span class="lineNum">    2863</span>              : </span>
<span id="L2864"><span class="lineNum">    2864</span>              :  private:</span>
<span id="L2865"><span class="lineNum">    2865</span>              :   // This pointer points to an AutogradMeta struct that stores autograd-specific</span>
<span id="L2866"><span class="lineNum">    2866</span>              :   // fields (such as grad_ / grad_fn_ / grad_accumulator_). This pointer always</span>
<span id="L2867"><span class="lineNum">    2867</span>              :   // has unique ownership (meaning only one TensorImpl can own it at a time).</span>
<span id="L2868"><span class="lineNum">    2868</span>              :   //</span>
<span id="L2869"><span class="lineNum">    2869</span>              :   // autograd_meta_ can be nullptr, as an optimization.  When this occurs, it is</span>
<span id="L2870"><span class="lineNum">    2870</span>              :   // equivalent to having an autograd_meta_ pointing to a default constructed</span>
<span id="L2871"><span class="lineNum">    2871</span>              :   // AutogradMeta; intuitively, tensors which don't require grad will have this</span>
<span id="L2872"><span class="lineNum">    2872</span>              :   // field set to null.</span>
<span id="L2873"><span class="lineNum">    2873</span>              :   //</span>
<span id="L2874"><span class="lineNum">    2874</span>              :   // This means accessors on autograd_meta_ have to be careful to test if they</span>
<span id="L2875"><span class="lineNum">    2875</span>              :   // got a nullptr, and handle default behavior appropriately in that case.</span>
<span id="L2876"><span class="lineNum">    2876</span>              :   //</span>
<span id="L2877"><span class="lineNum">    2877</span>              :   // Note that we don't enforce the invariant that if the AutogradMeta is</span>
<span id="L2878"><span class="lineNum">    2878</span>              :   // default constructed, it is nullptr (to do this, we'd have to continuously</span>
<span id="L2879"><span class="lineNum">    2879</span>              :   // check if an AutogradMeta became, by mutation, equal to the default</span>
<span id="L2880"><span class="lineNum">    2880</span>              :   // constructed form.  (This might be useful, but it seems rare enough that</span>
<span id="L2881"><span class="lineNum">    2881</span>              :   // a requires_grad=True variable will turn back into the requires_grad=False</span>
<span id="L2882"><span class="lineNum">    2882</span>              :   // version.)  So there are three representable states:</span>
<span id="L2883"><span class="lineNum">    2883</span>              :   //</span>
<span id="L2884"><span class="lineNum">    2884</span>              :   //    1. autograd_meta_ == nullptr</span>
<span id="L2885"><span class="lineNum">    2885</span>              :   //    2. autograd_meta_ is default constructed (semantically, same as (1))</span>
<span id="L2886"><span class="lineNum">    2886</span>              :   //    3. autograd_meta_ has nontrivial information content</span>
<span id="L2887"><span class="lineNum">    2887</span>              :   //</span>
<span id="L2888"><span class="lineNum">    2888</span>              :   std::unique_ptr&lt;c10::AutogradMetaInterface&gt; autograd_meta_ = nullptr;</span>
<span id="L2889"><span class="lineNum">    2889</span>              : </span>
<span id="L2890"><span class="lineNum">    2890</span>              :  protected:</span>
<span id="L2891"><span class="lineNum">    2891</span>              :   std::unique_ptr&lt;c10::ExtraMeta&gt; extra_meta_ = nullptr;</span>
<span id="L2892"><span class="lineNum">    2892</span>              : </span>
<span id="L2893"><span class="lineNum">    2893</span>              :   c10::VariableVersion version_counter_;</span>
<span id="L2894"><span class="lineNum">    2894</span>              : </span>
<span id="L2895"><span class="lineNum">    2895</span>              :   impl::PyObjectSlot pyobj_slot_;</span>
<span id="L2896"><span class="lineNum">    2896</span>              : </span>
<span id="L2897"><span class="lineNum">    2897</span>              :   c10::impl::SizesAndStrides sizes_and_strides_;</span>
<span id="L2898"><span class="lineNum">    2898</span>              : </span>
<span id="L2899"><span class="lineNum">    2899</span>              :   int64_t storage_offset_ = 0;</span>
<span id="L2900"><span class="lineNum">    2900</span>              :   // If sizes and strides are empty, the numel is 1!!  However, most of the</span>
<span id="L2901"><span class="lineNum">    2901</span>              :   // time, we will immediately set sizes to {0} and reset numel to 0.</span>
<span id="L2902"><span class="lineNum">    2902</span>              :   // (Can't do that in the default initializers, because there's no way to</span>
<span id="L2903"><span class="lineNum">    2903</span>              :   // spell &quot;allocate a one-element array&quot; for strides_).</span>
<span id="L2904"><span class="lineNum">    2904</span>              :   int64_t numel_ = 1;</span>
<span id="L2905"><span class="lineNum">    2905</span>              : </span>
<span id="L2906"><span class="lineNum">    2906</span>              :   // INVARIANT: When storage is non-null, this type meta must</span>
<span id="L2907"><span class="lineNum">    2907</span>              :   // agree with the type meta in storage</span>
<span id="L2908"><span class="lineNum">    2908</span>              :   caffe2::TypeMeta data_type_;</span>
<span id="L2909"><span class="lineNum">    2909</span>              : </span>
<span id="L2910"><span class="lineNum">    2910</span>              :   // NOTE [c10::optional operator usage in CUDA]</span>
<span id="L2911"><span class="lineNum">    2911</span>              :   // Our optional definition doesn't compile in .cu file if `value()` or</span>
<span id="L2912"><span class="lineNum">    2912</span>              :   // `operator-&gt;` are used.  Instead, we always use `operator*`.</span>
<span id="L2913"><span class="lineNum">    2913</span>              :   // See https://github.com/pytorch/pytorch/issues/18496 for more info.</span>
<span id="L2914"><span class="lineNum">    2914</span>              :   // If this is too burdensome to maintain, we can just</span>
<span id="L2915"><span class="lineNum">    2915</span>              :   // manually implement this with an additional bool.</span>
<span id="L2916"><span class="lineNum">    2916</span>              : </span>
<span id="L2917"><span class="lineNum">    2917</span>              :   // INVARIANT: When storage is non-null, this Device must</span>
<span id="L2918"><span class="lineNum">    2918</span>              :   // agree with the type meta in storage.</span>
<span id="L2919"><span class="lineNum">    2919</span>              :   //</span>
<span id="L2920"><span class="lineNum">    2920</span>              :   // INVARIANT: device_opt_ is only nullopt for undefined tensors</span>
<span id="L2921"><span class="lineNum">    2921</span>              :   // (which do not have a device.)</span>
<span id="L2922"><span class="lineNum">    2922</span>              :   c10::optional&lt;c10::Device&gt; device_opt_;</span>
<span id="L2923"><span class="lineNum">    2923</span>              : </span>
<span id="L2924"><span class="lineNum">    2924</span>              :   // default member initializers for bit-fields only available with -std=c++2a</span>
<span id="L2925"><span class="lineNum">    2925</span>              :   // or -std=gnu++2a</span>
<span id="L2926"><span class="lineNum">    2926</span>              :   inline void init_bitfields() {</span>
<span id="L2927"><span class="lineNum">    2927</span>              :     is_contiguous_ = true;</span>
<span id="L2928"><span class="lineNum">    2928</span>              :     is_channels_last_ = false;</span>
<span id="L2929"><span class="lineNum">    2929</span>              :     is_channels_last_contiguous_ = false;</span>
<span id="L2930"><span class="lineNum">    2930</span>              :     is_channels_last_3d_ = false;</span>
<span id="L2931"><span class="lineNum">    2931</span>              :     is_channels_last_3d_contiguous_ = false;</span>
<span id="L2932"><span class="lineNum">    2932</span>              :     is_non_overlapping_and_dense_ = true;</span>
<span id="L2933"><span class="lineNum">    2933</span>              :     is_wrapped_number_ = false;</span>
<span id="L2934"><span class="lineNum">    2934</span>              :     allow_tensor_metadata_change_ = true;</span>
<span id="L2935"><span class="lineNum">    2935</span>              :     reserved_ = false;</span>
<span id="L2936"><span class="lineNum">    2936</span>              :     sizes_strides_policy_ = static_cast&lt;uint8_t&gt;(SizesStridesPolicy::Default);</span>
<span id="L2937"><span class="lineNum">    2937</span>              :     custom_sizes_strides_ = static_cast&lt;uint8_t&gt;(SizesStridesPolicy::Default);</span>
<span id="L2938"><span class="lineNum">    2938</span>              :     python_custom_sizes_strides_ =</span>
<span id="L2939"><span class="lineNum">    2939</span>              :         static_cast&lt;uint8_t&gt;(SizesStridesPolicy::Default);</span>
<span id="L2940"><span class="lineNum">    2940</span>              :     python_custom_device_ = false;</span>
<span id="L2941"><span class="lineNum">    2941</span>              :     python_custom_layout_ = false;</span>
<span id="L2942"><span class="lineNum">    2942</span>              :     custom_device_ = false;</span>
<span id="L2943"><span class="lineNum">    2943</span>              :     custom_layout_ = false;</span>
<span id="L2944"><span class="lineNum">    2944</span>              :     device_policy_ = false;</span>
<span id="L2945"><span class="lineNum">    2945</span>              :     layout_policy_ = false;</span>
<span id="L2946"><span class="lineNum">    2946</span>              :     storage_access_should_throw_ = false;</span>
<span id="L2947"><span class="lineNum">    2947</span>              :     has_symbolic_sizes_strides_ = false;</span>
<span id="L2948"><span class="lineNum">    2948</span>              :   }</span>
<span id="L2949"><span class="lineNum">    2949</span>              : </span>
<span id="L2950"><span class="lineNum">    2950</span>              :   // Tensor is contiguous</span>
<span id="L2951"><span class="lineNum">    2951</span>              :   bool is_contiguous_ : 1;</span>
<span id="L2952"><span class="lineNum">    2952</span>              : </span>
<span id="L2953"><span class="lineNum">    2953</span>              :   // Tensor is a subclass that does not permit storage access.</span>
<span id="L2954"><span class="lineNum">    2954</span>              :   bool storage_access_should_throw_ : 1;</span>
<span id="L2955"><span class="lineNum">    2955</span>              : </span>
<span id="L2956"><span class="lineNum">    2956</span>              :   // Tensor is stored in the channels last 2d memory format, when dimensions</span>
<span id="L2957"><span class="lineNum">    2957</span>              :   // order is (N)CHW and C-strides &lt; W-strides &lt; H-strides (&lt; N-strides)</span>
<span id="L2958"><span class="lineNum">    2958</span>              :   // (If size of any dimension is equal to 1, this dimension strides value</span>
<span id="L2959"><span class="lineNum">    2959</span>              :   // is not taken into account).</span>
<span id="L2960"><span class="lineNum">    2960</span>              :   bool is_channels_last_ : 1;</span>
<span id="L2961"><span class="lineNum">    2961</span>              : </span>
<span id="L2962"><span class="lineNum">    2962</span>              :   // Channels last contiguous tensor is channel last tensor which occupies</span>
<span id="L2963"><span class="lineNum">    2963</span>              :   // contiguous memory block.</span>
<span id="L2964"><span class="lineNum">    2964</span>              :   bool is_channels_last_contiguous_ : 1;</span>
<span id="L2965"><span class="lineNum">    2965</span>              : </span>
<span id="L2966"><span class="lineNum">    2966</span>              :   // Tensor is stored in the channels last 3d memory format, when dimensions</span>
<span id="L2967"><span class="lineNum">    2967</span>              :   // order is (N)CDHW and C-strides &lt; W-strides &lt; H-strides &lt; D - strides (&lt;</span>
<span id="L2968"><span class="lineNum">    2968</span>              :   // N-strides) (If size of any dimension is equal to 1, this dimension strides</span>
<span id="L2969"><span class="lineNum">    2969</span>              :   // value is not taken into account).</span>
<span id="L2970"><span class="lineNum">    2970</span>              :   bool is_channels_last_3d_ : 1;</span>
<span id="L2971"><span class="lineNum">    2971</span>              : </span>
<span id="L2972"><span class="lineNum">    2972</span>              :   // Channels last 3d contiguous tensor is channel last 3d tensor which occupies</span>
<span id="L2973"><span class="lineNum">    2973</span>              :   // contiguous memory block.</span>
<span id="L2974"><span class="lineNum">    2974</span>              :   bool is_channels_last_3d_contiguous_ : 1;</span>
<span id="L2975"><span class="lineNum">    2975</span>              : </span>
<span id="L2976"><span class="lineNum">    2976</span>              :   // Dense tensor is the tensor that store values in a contiguous block of</span>
<span id="L2977"><span class="lineNum">    2977</span>              :   // memory. Non-overlapping tensor is the tensor in which elements occupy</span>
<span id="L2978"><span class="lineNum">    2978</span>              :   // individual non-repetitive memory.</span>
<span id="L2979"><span class="lineNum">    2979</span>              :   bool is_non_overlapping_and_dense_ : 1;</span>
<span id="L2980"><span class="lineNum">    2980</span>              : </span>
<span id="L2981"><span class="lineNum">    2981</span>              :   bool is_wrapped_number_ : 1;</span>
<span id="L2982"><span class="lineNum">    2982</span>              : </span>
<span id="L2983"><span class="lineNum">    2983</span>              :   // NOTE [ Metadata Change for a Detached Tensor ]</span>
<span id="L2984"><span class="lineNum">    2984</span>              :   //</span>
<span id="L2985"><span class="lineNum">    2985</span>              :   // Normally, a user is allowed to change the tensor metadata</span>
<span id="L2986"><span class="lineNum">    2986</span>              :   // (e.g. sizes / strides / storage / storage_offset) of a tensor.</span>
<span id="L2987"><span class="lineNum">    2987</span>              :   // However, if the tensor is created by `t1_detached = t1.data` in Python</span>
<span id="L2988"><span class="lineNum">    2988</span>              :   // or `t1_detached = t1.detach()` in Python/C++, those changes to the</span>
<span id="L2989"><span class="lineNum">    2989</span>              :   // tensor metadata of `t1_detached` will not be propagated back to the</span>
<span id="L2990"><span class="lineNum">    2990</span>              :   // original tensor `t1`. In order to make such changes explicitly illegal,</span>
<span id="L2991"><span class="lineNum">    2991</span>              :   // we created the `allow_tensor_metadata_change_` flag, to prevent users</span>
<span id="L2992"><span class="lineNum">    2992</span>              :   // from changing metadata of the detached tensor and expecting the original</span>
<span id="L2993"><span class="lineNum">    2993</span>              :   // tensor to also be updated.</span>
<span id="L2994"><span class="lineNum">    2994</span>              :   //</span>
<span id="L2995"><span class="lineNum">    2995</span>              :   // NOTE: For a full list of tensor metadata fields, please see</span>
<span id="L2996"><span class="lineNum">    2996</span>              :   // `copy_tensor_metadata()` in TensorImpl and its subclasses to find</span>
<span id="L2997"><span class="lineNum">    2997</span>              :   // which fields are copied by value.</span>
<span id="L2998"><span class="lineNum">    2998</span>              :   bool allow_tensor_metadata_change_ : 1;</span>
<span id="L2999"><span class="lineNum">    2999</span>              : </span>
<span id="L3000"><span class="lineNum">    3000</span>              :   // we decide to keep reserved_ and it will</span>
<span id="L3001"><span class="lineNum">    3001</span>              :   // live in Tensor after the split</span>
<span id="L3002"><span class="lineNum">    3002</span>              :   // The logic is that if Extend() or ReserveSpace() were ever called,</span>
<span id="L3003"><span class="lineNum">    3003</span>              :   // then subsequent Resize()s will not free up Storage.</span>
<span id="L3004"><span class="lineNum">    3004</span>              :   bool reserved_ : 1;</span>
<span id="L3005"><span class="lineNum">    3005</span>              : </span>
<span id="L3006"><span class="lineNum">    3006</span>              :   // Call _custom() virtual methods for</span>
<span id="L3007"><span class="lineNum">    3007</span>              :   // strides()/is_contiguous()/sizes()/dim()/numel()</span>
<span id="L3008"><span class="lineNum">    3008</span>              :   // This is a combination of sizes_strides_custom_dispatch_</span>
<span id="L3009"><span class="lineNum">    3009</span>              :   // and has_symbolic_sizes_strides_</span>
<span id="L3010"><span class="lineNum">    3010</span>              :   uint8_t sizes_strides_policy_ : 2;</span>
<span id="L3011"><span class="lineNum">    3011</span>              : </span>
<span id="L3012"><span class="lineNum">    3012</span>              :   // Whether or not sizes_and_strides_ contains a symbolic value.</span>
<span id="L3013"><span class="lineNum">    3013</span>              :   bool has_symbolic_sizes_strides_ : 1;</span>
<span id="L3014"><span class="lineNum">    3014</span>              : </span>
<span id="L3015"><span class="lineNum">    3015</span>              :   // Call _custom() virtual method for</span>
<span id="L3016"><span class="lineNum">    3016</span>              :   // strides()/is_contiguous()/sizes()/dim()/numel()</span>
<span id="L3017"><span class="lineNum">    3017</span>              :   uint8_t custom_sizes_strides_ : 2;</span>
<span id="L3018"><span class="lineNum">    3018</span>              : </span>
<span id="L3019"><span class="lineNum">    3019</span>              :   // Combo of custom_ and python_custom_</span>
<span id="L3020"><span class="lineNum">    3020</span>              :   bool device_policy_ : 1;</span>
<span id="L3021"><span class="lineNum">    3021</span>              :   bool layout_policy_ : 1;</span>
<span id="L3022"><span class="lineNum">    3022</span>              : </span>
<span id="L3023"><span class="lineNum">    3023</span>              :   // Call _custom() virtual method for device()</span>
<span id="L3024"><span class="lineNum">    3024</span>              :   bool custom_device_ : 1;</span>
<span id="L3025"><span class="lineNum">    3025</span>              : </span>
<span id="L3026"><span class="lineNum">    3026</span>              :   // Call _custom() virtual method for layout()</span>
<span id="L3027"><span class="lineNum">    3027</span>              :   bool custom_layout_ : 1;</span>
<span id="L3028"><span class="lineNum">    3028</span>              : </span>
<span id="L3029"><span class="lineNum">    3029</span>              :   // Call into Python for</span>
<span id="L3030"><span class="lineNum">    3030</span>              :   // strides()/is_contiguous()/sizes()/dim()/numel()</span>
<span id="L3031"><span class="lineNum">    3031</span>              :   uint8_t python_custom_sizes_strides_ : 2;</span>
<span id="L3032"><span class="lineNum">    3032</span>              : </span>
<span id="L3033"><span class="lineNum">    3033</span>              :   // Call into Python for device()</span>
<span id="L3034"><span class="lineNum">    3034</span>              :   bool python_custom_device_ : 1;</span>
<span id="L3035"><span class="lineNum">    3035</span>              : </span>
<span id="L3036"><span class="lineNum">    3036</span>              :   // Call into Python for layout()</span>
<span id="L3037"><span class="lineNum">    3037</span>              :   bool python_custom_layout_ : 1;</span>
<span id="L3038"><span class="lineNum">    3038</span>              : </span>
<span id="L3039"><span class="lineNum">    3039</span>              :   // The set of DispatchKeys which describe this tensor.  NB: this</span>
<span id="L3040"><span class="lineNum">    3040</span>              :   // does NOT include Autograd (historically, it did, but</span>
<span id="L3041"><span class="lineNum">    3041</span>              :   // not anymore!)</span>
<span id="L3042"><span class="lineNum">    3042</span>              :   //</span>
<span id="L3043"><span class="lineNum">    3043</span>              :   // INVARIANT: extra_meta_-&gt;named_tensor_meta_ != nullptr  &lt;==&gt;</span>
<span id="L3044"><span class="lineNum">    3044</span>              :   // key_set_.has(DispatchKey::Named)</span>
<span id="L3045"><span class="lineNum">    3045</span>              :   DispatchKeySet key_set_;</span>
<span id="L3046"><span class="lineNum">    3046</span>              : </span>
<span id="L3047"><span class="lineNum">    3047</span>              :  private:</span>
<span id="L3048"><span class="lineNum">    3048</span>              :   // C10_TensorImpl_Size_Check_Dummy_Class needs to be friends with</span>
<span id="L3049"><span class="lineNum">    3049</span>              :   // TensorImpl so it can inspect the size of private fields</span>
<span id="L3050"><span class="lineNum">    3050</span>              :   template &lt;</span>
<span id="L3051"><span class="lineNum">    3051</span>              :       size_t cplusplus,</span>
<span id="L3052"><span class="lineNum">    3052</span>              :       size_t clang_ver_major,</span>
<span id="L3053"><span class="lineNum">    3053</span>              :       size_t gcc_ver,</span>
<span id="L3054"><span class="lineNum">    3054</span>              :       size_t gcc_ver_minor,</span>
<span id="L3055"><span class="lineNum">    3055</span>              :       size_t nvcc,</span>
<span id="L3056"><span class="lineNum">    3056</span>              :       size_t cuda_version,</span>
<span id="L3057"><span class="lineNum">    3057</span>              :       size_t cuda_version_major,</span>
<span id="L3058"><span class="lineNum">    3058</span>              :       size_t ptr_size&gt;</span>
<span id="L3059"><span class="lineNum">    3059</span>              :   friend class C10_TensorImpl_Size_Check_Dummy_Class;</span>
<span id="L3060"><span class="lineNum">    3060</span>              : };</span>
<span id="L3061"><span class="lineNum">    3061</span>              : </span>
<span id="L3062"><span class="lineNum">    3062</span>              : // Note [TensorImpl size constraints]</span>
<span id="L3063"><span class="lineNum">    3063</span>              : // ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span>
<span id="L3064"><span class="lineNum">    3064</span>              : // Changed the size of TensorImpl?  If the size went down, good for</span>
<span id="L3065"><span class="lineNum">    3065</span>              : // you!  Adjust the documentation below and the expected size.</span>
<span id="L3066"><span class="lineNum">    3066</span>              : // Did it go up?  Read on...</span>
<span id="L3067"><span class="lineNum">    3067</span>              : //</span>
<span id="L3068"><span class="lineNum">    3068</span>              : // Struct size matters.  In some production systems at Facebook, we have</span>
<span id="L3069"><span class="lineNum">    3069</span>              : // 400M live tensors during a training run.  Do the math: every 64-bit</span>
<span id="L3070"><span class="lineNum">    3070</span>              : // word you add to Tensor is an extra 3.2 gigabytes in RAM.</span>
<span id="L3071"><span class="lineNum">    3071</span>              : //</span>
<span id="L3072"><span class="lineNum">    3072</span>              : // If you are a Facebook employee, you can check if the run in question</span>
<span id="L3073"><span class="lineNum">    3073</span>              : // has tipped you over the point using the command here:</span>
<span id="L3074"><span class="lineNum">    3074</span>              : // https://fburl.com/q5enpv98</span>
<span id="L3075"><span class="lineNum">    3075</span>              : //</span>
<span id="L3076"><span class="lineNum">    3076</span>              : // For reference, we OOMed at 160 bytes (20 words) per TensorImpl.</span>
<span id="L3077"><span class="lineNum">    3077</span>              : // This is not counting overhead from strides out-of-line allocation and</span>
<span id="L3078"><span class="lineNum">    3078</span>              : // StorageImpl space and this is from before we inlined sizes and strides</span>
<span id="L3079"><span class="lineNum">    3079</span>              : // directly into TensorImpl as SmallVectors.</span>
<span id="L3080"><span class="lineNum">    3080</span>              : //</span>
<span id="L3081"><span class="lineNum">    3081</span>              : // Our memory usage on 32-bit systems is suboptimal, but we're not checking</span>
<span id="L3082"><span class="lineNum">    3082</span>              : // for it at the moment (to help avoid rage inducing cycles when the</span>
<span id="L3083"><span class="lineNum">    3083</span>              : // 32-bit number is wrong).</span>
<span id="L3084"><span class="lineNum">    3084</span>              : //</span>
<span id="L3085"><span class="lineNum">    3085</span>              : // Current breakdown:</span>
<span id="L3086"><span class="lineNum">    3086</span>              : //</span>
<span id="L3087"><span class="lineNum">    3087</span>              : //    vtable pointer</span>
<span id="L3088"><span class="lineNum">    3088</span>              : //    strong refcount           TODO: pack these into one word</span>
<span id="L3089"><span class="lineNum">    3089</span>              : //    weak refcount</span>
<span id="L3090"><span class="lineNum">    3090</span>              : //    storage pointer</span>
<span id="L3091"><span class="lineNum">    3091</span>              : //    autograd metadata pointer</span>
<span id="L3092"><span class="lineNum">    3092</span>              : //    named tensor metadata pointer</span>
<span id="L3093"><span class="lineNum">    3093</span>              : //    version counter pointer</span>
<span id="L3094"><span class="lineNum">    3094</span>              : //    PyObjectSlot</span>
<span id="L3095"><span class="lineNum">    3095</span>              : //    SizesAndStrides size/pointer</span>
<span id="L3096"><span class="lineNum">    3096</span>              : //    SizesAndStrides sizes (pre-allocated 0)</span>
<span id="L3097"><span class="lineNum">    3097</span>              : //    SizesAndStrides sizes (pre-allocated 1)</span>
<span id="L3098"><span class="lineNum">    3098</span>              : //    SizesAndStrides sizes (pre-allocated 2)</span>
<span id="L3099"><span class="lineNum">    3099</span>              : //    SizesAndStrides sizes (pre-allocated 3)</span>
<span id="L3100"><span class="lineNum">    3100</span>              : //    SizesAndStrides sizes (pre-allocated 4)</span>
<span id="L3101"><span class="lineNum">    3101</span>              : //    SizesAndStrides strides (pre-allocated 0)</span>
<span id="L3102"><span class="lineNum">    3102</span>              : //    SizesAndStrides strides (pre-allocated 1)</span>
<span id="L3103"><span class="lineNum">    3103</span>              : //    SizesAndStrides strides (pre-allocated 2)</span>
<span id="L3104"><span class="lineNum">    3104</span>              : //    SizesAndStrides strides (pre-allocated 3)</span>
<span id="L3105"><span class="lineNum">    3105</span>              : //    SizesAndStrides strides (pre-allocated 4)</span>
<span id="L3106"><span class="lineNum">    3106</span>              : //    storage offset</span>
<span id="L3107"><span class="lineNum">    3107</span>              : //    numel</span>
<span id="L3108"><span class="lineNum">    3108</span>              : //    data type, device, is_contiguous, storage_access_should_throw_, bitfields</span>
<span id="L3109"><span class="lineNum">    3109</span>              : //    DispatchKeySet</span>
<span id="L3110"><span class="lineNum">    3110</span>              : //</span>
<span id="L3111"><span class="lineNum">    3111</span>              : </span>
<span id="L3112"><span class="lineNum">    3112</span>              : // Various preprocessor macros we use to check that the</span>
<span id="L3113"><span class="lineNum">    3113</span>              : // TensorImpl size hasn't changed unexpectedly. We undef</span>
<span id="L3114"><span class="lineNum">    3114</span>              : // these later.</span>
<span id="L3115"><span class="lineNum">    3115</span>              : #ifndef __NVCC__</span>
<span id="L3116"><span class="lineNum">    3116</span>              : #define C10_NVCC 0</span>
<span id="L3117"><span class="lineNum">    3117</span>              : #else</span>
<span id="L3118"><span class="lineNum">    3118</span>              : #define C10_NVCC __NVCC__</span>
<span id="L3119"><span class="lineNum">    3119</span>              : #endif</span>
<span id="L3120"><span class="lineNum">    3120</span>              : </span>
<span id="L3121"><span class="lineNum">    3121</span>              : #ifndef __CUDA_VER_MAJOR__</span>
<span id="L3122"><span class="lineNum">    3122</span>              : #define C10_CUDA_VERSION_MAJOR 0</span>
<span id="L3123"><span class="lineNum">    3123</span>              : #else</span>
<span id="L3124"><span class="lineNum">    3124</span>              : #define C10_CUDA_VERSION_MAJOR __CUDA_VER_MAJOR__</span>
<span id="L3125"><span class="lineNum">    3125</span>              : #endif</span>
<span id="L3126"><span class="lineNum">    3126</span>              : </span>
<span id="L3127"><span class="lineNum">    3127</span>              : #ifndef CUDA_VERSION</span>
<span id="L3128"><span class="lineNum">    3128</span>              : #define C10_CUDA_VERSION 0</span>
<span id="L3129"><span class="lineNum">    3129</span>              : #else</span>
<span id="L3130"><span class="lineNum">    3130</span>              : #define C10_CUDA_VERSION CUDA_VERSION</span>
<span id="L3131"><span class="lineNum">    3131</span>              : #endif</span>
<span id="L3132"><span class="lineNum">    3132</span>              : </span>
<span id="L3133"><span class="lineNum">    3133</span>              : #ifndef __clang_major__</span>
<span id="L3134"><span class="lineNum">    3134</span>              : #define C10_CLANG_MAJOR_VERSION 0</span>
<span id="L3135"><span class="lineNum">    3135</span>              : #else</span>
<span id="L3136"><span class="lineNum">    3136</span>              : #define C10_CLANG_MAJOR_VERSION __clang_major__</span>
<span id="L3137"><span class="lineNum">    3137</span>              : #endif</span>
<span id="L3138"><span class="lineNum">    3138</span>              : </span>
<span id="L3139"><span class="lineNum">    3139</span>              : #ifndef __GNUC__</span>
<span id="L3140"><span class="lineNum">    3140</span>              : #define C10_GCC_VERSION 0</span>
<span id="L3141"><span class="lineNum">    3141</span>              : #else</span>
<span id="L3142"><span class="lineNum">    3142</span>              : #define C10_GCC_VERSION __GNUC__</span>
<span id="L3143"><span class="lineNum">    3143</span>              : #endif</span>
<span id="L3144"><span class="lineNum">    3144</span>              : </span>
<span id="L3145"><span class="lineNum">    3145</span>              : #ifndef __GNUC_MINOR__</span>
<span id="L3146"><span class="lineNum">    3146</span>              : #define C10_GCC_VERSION_MINOR 0</span>
<span id="L3147"><span class="lineNum">    3147</span>              : #else</span>
<span id="L3148"><span class="lineNum">    3148</span>              : #define C10_GCC_VERSION_MINOR __GNUC_MINOR__</span>
<span id="L3149"><span class="lineNum">    3149</span>              : #endif</span>
<span id="L3150"><span class="lineNum">    3150</span>              : </span>
<span id="L3151"><span class="lineNum">    3151</span>              : // We use a templatized class to both contain the logic of checking the sizes</span>
<span id="L3152"><span class="lineNum">    3152</span>              : // as well as to provide compile-time information that might be useful in</span>
<span id="L3153"><span class="lineNum">    3153</span>              : // figuring out why sizes may have changed.</span>
<span id="L3154"><span class="lineNum">    3154</span>              : // All the compile time information is given by the template fields that are</span>
<span id="L3155"><span class="lineNum">    3155</span>              : // always printed by the compiler when the static_assert fails.</span>
<span id="L3156"><span class="lineNum">    3156</span>              : template &lt;</span>
<span id="L3157"><span class="lineNum">    3157</span>              :     size_t cplusplus = __cplusplus,</span>
<span id="L3158"><span class="lineNum">    3158</span>              :     size_t clang_ver_major = C10_CLANG_MAJOR_VERSION,</span>
<span id="L3159"><span class="lineNum">    3159</span>              :     size_t gcc_ver = C10_GCC_VERSION,</span>
<span id="L3160"><span class="lineNum">    3160</span>              :     size_t gcc_ver_minor = C10_GCC_VERSION_MINOR,</span>
<span id="L3161"><span class="lineNum">    3161</span>              :     size_t nvcc = C10_NVCC,</span>
<span id="L3162"><span class="lineNum">    3162</span>              :     size_t cuda_version = C10_CUDA_VERSION,</span>
<span id="L3163"><span class="lineNum">    3163</span>              :     size_t cuda_version_major = C10_CUDA_VERSION_MAJOR,</span>
<span id="L3164"><span class="lineNum">    3164</span>              :     size_t ptr_size = sizeof(void*)&gt;</span>
<span id="L3165"><span class="lineNum">    3165</span>              : class C10_TensorImpl_Size_Check_Dummy_Class : private TensorImpl {</span>
<span id="L3166"><span class="lineNum">    3166</span>              :   // Names of (non-bitfield) fields in TensorImpl; used to provide</span>
<span id="L3167"><span class="lineNum">    3167</span>              :   // compile-time info about fields whose size changes unexpectedly.</span>
<span id="L3168"><span class="lineNum">    3168</span>              :   enum class FieldNameEnum {</span>
<span id="L3169"><span class="lineNum">    3169</span>              :     storage_,</span>
<span id="L3170"><span class="lineNum">    3170</span>              :     autograd_meta_,</span>
<span id="L3171"><span class="lineNum">    3171</span>              :     extra_meta_,</span>
<span id="L3172"><span class="lineNum">    3172</span>              :     version_counter_,</span>
<span id="L3173"><span class="lineNum">    3173</span>              :     pyobj_slot_,</span>
<span id="L3174"><span class="lineNum">    3174</span>              :     sizes_and_strides_,</span>
<span id="L3175"><span class="lineNum">    3175</span>              :     storage_offset_,</span>
<span id="L3176"><span class="lineNum">    3176</span>              :     numel_,</span>
<span id="L3177"><span class="lineNum">    3177</span>              :     data_type_,</span>
<span id="L3178"><span class="lineNum">    3178</span>              :     device_opt_,</span>
<span id="L3179"><span class="lineNum">    3179</span>              :     key_set_,</span>
<span id="L3180"><span class="lineNum">    3180</span>              :     TOTAL_SIZE</span>
<span id="L3181"><span class="lineNum">    3181</span>              :   };</span>
<span id="L3182"><span class="lineNum">    3182</span>              : </span>
<span id="L3183"><span class="lineNum">    3183</span>              :   // Provides compile-time equality check that reveals what numbers</span>
<span id="L3184"><span class="lineNum">    3184</span>              :   // were used and on which quantity</span>
<span id="L3185"><span class="lineNum">    3185</span>              :   template &lt;size_t Actual, size_t Expected, FieldNameEnum FiledName&gt;</span>
<span id="L3186"><span class="lineNum">    3186</span>              :   constexpr static bool are_equal() {</span>
<span id="L3187"><span class="lineNum">    3187</span>              :     static_assert(</span>
<span id="L3188"><span class="lineNum">    3188</span>              :         Actual == Expected,</span>
<span id="L3189"><span class="lineNum">    3189</span>              :         &quot;Actual and Expected sizes of a field did not match!&quot;);</span>
<span id="L3190"><span class="lineNum">    3190</span>              :     return true;</span>
<span id="L3191"><span class="lineNum">    3191</span>              :   }</span>
<span id="L3192"><span class="lineNum">    3192</span>              : </span>
<span id="L3193"><span class="lineNum">    3193</span>              :   // Provides compile-time &lt;= check that reveals what numbers</span>
<span id="L3194"><span class="lineNum">    3194</span>              :   // were used and on which quantity</span>
<span id="L3195"><span class="lineNum">    3195</span>              :   template &lt;size_t Actual, size_t Expected, FieldNameEnum FiledName&gt;</span>
<span id="L3196"><span class="lineNum">    3196</span>              :   constexpr static bool is_le() {</span>
<span id="L3197"><span class="lineNum">    3197</span>              :     static_assert(</span>
<span id="L3198"><span class="lineNum">    3198</span>              :         Actual &lt;= Expected,</span>
<span id="L3199"><span class="lineNum">    3199</span>              :         &quot;Actual and Expected sizes of a field did not match!&quot;);</span>
<span id="L3200"><span class="lineNum">    3200</span>              :     return true;</span>
<span id="L3201"><span class="lineNum">    3201</span>              :   }</span>
<span id="L3202"><span class="lineNum">    3202</span>              : </span>
<span id="L3203"><span class="lineNum">    3203</span>              :  public:</span>
<span id="L3204"><span class="lineNum">    3204</span>              :   // Compile-time check that TensorImpl field sizes are as expected</span>
<span id="L3205"><span class="lineNum">    3205</span>              :   //</span>
<span id="L3206"><span class="lineNum">    3206</span>              :   // Observed total sizes and associated versions</span>
<span id="L3207"><span class="lineNum">    3207</span>              :   // If you find a flag that predicts when unique_ptr has 16 bytes</span>
<span id="L3208"><span class="lineNum">    3208</span>              :   // on 64-bit systems or when sizes_and_strides_ is 84 vs 88 bytes</span>
<span id="L3209"><span class="lineNum">    3209</span>              :   // on 32-bit systems you get a cookie!</span>
<span id="L3210"><span class="lineNum">    3210</span>              :   // Length | LLVM | GCC  |    C++ |  CUDA</span>
<span id="L3211"><span class="lineNum">    3211</span>              :   //    192 |    ? | 11.2 | 201703 | 11040</span>
<span id="L3212"><span class="lineNum">    3212</span>              :   //    208 |    ? | 11.2 | 201703 | 11040</span>
<span id="L3213"><span class="lineNum">    3213</span>              :   //    208 |    ? | 11.2 | 201402 | 11040</span>
<span id="L3214"><span class="lineNum">    3214</span>              :   //    192 |    ? | 11.2 | 201402 | 11040</span>
<span id="L3215"><span class="lineNum">    3215</span>              :   //    160 |   12 |  4.2 | 201703 |     0</span>
<span id="L3216"><span class="lineNum">    3216</span>              :   //</span>
<span id="L3217"><span class="lineNum">    3217</span>              :   // To keep things clean, we split on systems here.</span>
<span id="L3218"><span class="lineNum">    3218</span>              : </span>
<span id="L3219"><span class="lineNum">    3219</span>              : #if UINTPTR_MAX == 0xFFFFFFFF</span>
<span id="L3220"><span class="lineNum">    3220</span>              :   // This is a 32-bit system</span>
<span id="L3221"><span class="lineNum">    3221</span>              :   static constexpr bool check_sizes() {</span>
<span id="L3222"><span class="lineNum">    3222</span>              :     constexpr size_t tsize = 20 * sizeof(int64_t);</span>
<span id="L3223"><span class="lineNum">    3223</span>              : </span>
<span id="L3224"><span class="lineNum">    3224</span>              :     // clang-format off</span>
<span id="L3225"><span class="lineNum">    3225</span>              :     are_equal&lt;sizeof(storage_),            4,  FieldNameEnum::storage_&gt;();</span>
<span id="L3226"><span class="lineNum">    3226</span>              :     are_equal&lt;sizeof(autograd_meta_),      4,  FieldNameEnum::autograd_meta_&gt;();</span>
<span id="L3227"><span class="lineNum">    3227</span>              :     are_equal&lt;sizeof(extra_meta_),         4,  FieldNameEnum::extra_meta_&gt;();</span>
<span id="L3228"><span class="lineNum">    3228</span>              :     are_equal&lt;sizeof(version_counter_),    4,  FieldNameEnum::version_counter_&gt;();</span>
<span id="L3229"><span class="lineNum">    3229</span>              :     are_equal&lt;sizeof(pyobj_slot_),    8,  FieldNameEnum::pyobj_slot_&gt;();</span>
<span id="L3230"><span class="lineNum">    3230</span>              :     is_le&lt;sizeof(sizes_and_strides_),     88, FieldNameEnum::sizes_and_strides_&gt;();</span>
<span id="L3231"><span class="lineNum">    3231</span>              :     are_equal&lt;sizeof(storage_offset_),     8,  FieldNameEnum::storage_offset_&gt;();</span>
<span id="L3232"><span class="lineNum">    3232</span>              :     are_equal&lt;sizeof(numel_),              8,  FieldNameEnum::numel_&gt;();</span>
<span id="L3233"><span class="lineNum">    3233</span>              :     are_equal&lt;sizeof(data_type_),          2,  FieldNameEnum::data_type_&gt;();</span>
<span id="L3234"><span class="lineNum">    3234</span>              :     are_equal&lt;sizeof(device_opt_),         3,  FieldNameEnum::device_opt_&gt;();</span>
<span id="L3235"><span class="lineNum">    3235</span>              :     are_equal&lt;sizeof(key_set_),            8,  FieldNameEnum::key_set_&gt;();</span>
<span id="L3236"><span class="lineNum">    3236</span>              :     is_le&lt;sizeof(TensorImpl),          tsize,  FieldNameEnum::TOTAL_SIZE&gt;();</span>
<span id="L3237"><span class="lineNum">    3237</span>              :     // clang-format on</span>
<span id="L3238"><span class="lineNum">    3238</span>              : </span>
<span id="L3239"><span class="lineNum">    3239</span>              :     return true;</span>
<span id="L3240"><span class="lineNum">    3240</span>              :   }</span>
<span id="L3241"><span class="lineNum">    3241</span>              : #else</span>
<span id="L3242"><span class="lineNum">    3242</span>              :   // This is a 64-bit system</span>
<span id="L3243"><span class="lineNum">    3243</span>              :   static constexpr bool check_sizes() {</span>
<span id="L3244"><span class="lineNum">    3244</span>              :     constexpr size_t tsize = 26 * sizeof(int64_t);</span>
<span id="L3245"><span class="lineNum">    3245</span>              : </span>
<span id="L3246"><span class="lineNum">    3246</span>              :     // clang-format off</span>
<span id="L3247"><span class="lineNum">    3247</span>              :     are_equal&lt;sizeof(storage_),            8,  FieldNameEnum::storage_&gt;();</span>
<span id="L3248"><span class="lineNum">    3248</span>              :     // On some systems involving NVCC the size of unique_ptr is 16 bytes. We haven't</span>
<span id="L3249"><span class="lineNum">    3249</span>              :     // figured out how to detect those via macro preprocessors yet, so we use &lt;=</span>
<span id="L3250"><span class="lineNum">    3250</span>              :     // comparisons for the relevant fields.</span>
<span id="L3251"><span class="lineNum">    3251</span>              :     is_le&lt;sizeof(autograd_meta_),         16,  FieldNameEnum::autograd_meta_&gt;();</span>
<span id="L3252"><span class="lineNum">    3252</span>              :     is_le&lt;sizeof(extra_meta_),            16,  FieldNameEnum::extra_meta_&gt;();</span>
<span id="L3253"><span class="lineNum">    3253</span>              :     are_equal&lt;sizeof(version_counter_),    8,  FieldNameEnum::version_counter_&gt;();</span>
<span id="L3254"><span class="lineNum">    3254</span>              :     are_equal&lt;sizeof(pyobj_slot_),   16,  FieldNameEnum::pyobj_slot_&gt;();</span>
<span id="L3255"><span class="lineNum">    3255</span>              :     are_equal&lt;sizeof(sizes_and_strides_), 88,  FieldNameEnum::sizes_and_strides_&gt;();</span>
<span id="L3256"><span class="lineNum">    3256</span>              :     are_equal&lt;sizeof(storage_offset_),     8,  FieldNameEnum::storage_offset_&gt;();</span>
<span id="L3257"><span class="lineNum">    3257</span>              :     are_equal&lt;sizeof(numel_),              8,  FieldNameEnum::numel_&gt;();</span>
<span id="L3258"><span class="lineNum">    3258</span>              :     are_equal&lt;sizeof(data_type_),          2,  FieldNameEnum::data_type_&gt;();</span>
<span id="L3259"><span class="lineNum">    3259</span>              :     are_equal&lt;sizeof(device_opt_),         3,  FieldNameEnum::device_opt_&gt;();</span>
<span id="L3260"><span class="lineNum">    3260</span>              :     are_equal&lt;sizeof(key_set_),            8,  FieldNameEnum::key_set_&gt;();</span>
<span id="L3261"><span class="lineNum">    3261</span>              :     is_le&lt;sizeof(TensorImpl),          tsize,  FieldNameEnum::TOTAL_SIZE&gt;();</span>
<span id="L3262"><span class="lineNum">    3262</span>              :     // clang-format on</span>
<span id="L3263"><span class="lineNum">    3263</span>              : </span>
<span id="L3264"><span class="lineNum">    3264</span>              :     return true;</span>
<span id="L3265"><span class="lineNum">    3265</span>              :   }</span>
<span id="L3266"><span class="lineNum">    3266</span>              : #endif</span>
<span id="L3267"><span class="lineNum">    3267</span>              : };</span>
<span id="L3268"><span class="lineNum">    3268</span>              : </span>
<span id="L3269"><span class="lineNum">    3269</span>              : // We use a class to encapsulate size-checking logic with</span>
<span id="L3270"><span class="lineNum">    3270</span>              : // templates to capture sizes and flags. We call this within</span>
<span id="L3271"><span class="lineNum">    3271</span>              : // a static assert to prove there is no run-time behaviour.</span>
<span id="L3272"><span class="lineNum">    3272</span>              : // Since the methods we call return either true or fail their</span>
<span id="L3273"><span class="lineNum">    3273</span>              : // own static_asserts, we should never see the error messages</span>
<span id="L3274"><span class="lineNum">    3274</span>              : // below. We have to provide it though for c++ &lt;17.</span>
<span id="L3275"><span class="lineNum">    3275</span>              : static_assert(</span>
<span id="L3276"><span class="lineNum">    3276</span>              :     C10_TensorImpl_Size_Check_Dummy_Class&lt;&gt;::check_sizes(),</span>
<span id="L3277"><span class="lineNum">    3277</span>              :     &quot;You should not see this message.&quot;);</span>
<span id="L3278"><span class="lineNum">    3278</span>              : </span>
<span id="L3279"><span class="lineNum">    3279</span>              : // Clean up after ourselves</span>
<span id="L3280"><span class="lineNum">    3280</span>              : #undef C10_NVCC</span>
<span id="L3281"><span class="lineNum">    3281</span>              : #undef C10_CUDA_VERSION_MAJOR</span>
<span id="L3282"><span class="lineNum">    3282</span>              : #undef C10_CUDA_VERSION</span>
<span id="L3283"><span class="lineNum">    3283</span>              : #undef C10_CLANG_MAJOR_VERSION</span>
<span id="L3284"><span class="lineNum">    3284</span>              : #undef C10_GCC_VERSION</span>
<span id="L3285"><span class="lineNum">    3285</span>              : #undef C10_GCC_VERSION_MINOR</span>
<span id="L3286"><span class="lineNum">    3286</span>              : </span>
<span id="L3287"><span class="lineNum">    3287</span>              : } // namespace c10</span>
<span id="L3288"><span class="lineNum">    3288</span>              : </span>
<span id="L3289"><span class="lineNum">    3289</span>              : C10_CLANG_DIAGNOSTIC_POP()</span>
        </pre>
              </td>
            </tr>
          </table>
          <br>

          <table width="100%" border=0 cellspacing=0 cellpadding=0>
            <tr><td class="ruler"><img src="../../../../glass.png" width=3 height=3 alt=""></td></tr>
            <tr><td class="versionInfo">Generated by: <a href="https://github.com//linux-test-project/lcov" target="_parent">LCOV version 2.0-1</a></td></tr>
          </table>
          <br>

</body>
</html>
